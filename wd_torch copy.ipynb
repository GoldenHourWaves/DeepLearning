{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "ebdf1bf8",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Torch 잘 설치 됐는지 확일할 때 쓰는 명령어\n",
    "\n",
    "import torch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "1653b83d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU 쓸수있어없어 물어보는거. 즉, NVIDIA 그래픽카드 있는지 없는지 물어보는 것\n",
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "f6fd0fb5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'2.10.0+cu126'"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 파이토치 버전확인\n",
    "\n",
    "torch.__version__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "43ff005a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(5)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "86007e7d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = [1,2,3]\n",
    "torch.tensor(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "696b57e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "np_data = np.array([[1,2],[3,4]])\n",
    "torch.tensor(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3b572949",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.from_numpy(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5b05f77a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([0, 2, 4, 6, 8])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.arange(0,10,2)  # 일정 간격으로 데이터를 생성"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "574f1fe9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([ 0.,  5., 10.])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.linspace(0,10,3)  # 3개의 간격  끝점의 보장과 정밀한 분할 때문에"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec1a9520",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[6, 7, 5],\n",
       "        [6, 9, 4]])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 데이터를 무작위로 생성  사이즈는 2행3열짜리\n",
    "\n",
    "torch.randint(0,10,(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "eb90417b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.9467, 0.3010, 0.7552],\n",
       "        [0.1261, 0.0386, 0.8573],\n",
       "        [0.9993, 0.3676, 0.2035]])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((3,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cea6b9fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4696, 0.9515, 0.2264],\n",
       "         [0.3964, 0.4559, 0.4721],\n",
       "         [0.4116, 0.3947, 0.6237],\n",
       "         ...,\n",
       "         [0.4389, 0.9225, 0.9106],\n",
       "         [0.5302, 0.2319, 0.0030],\n",
       "         [0.9018, 0.8794, 0.2478]],\n",
       "\n",
       "        [[0.0237, 0.0936, 0.4216],\n",
       "         [0.1795, 0.9527, 0.6787],\n",
       "         [0.7279, 0.6458, 0.5490],\n",
       "         ...,\n",
       "         [0.9002, 0.0881, 0.7172],\n",
       "         [0.2866, 0.5614, 0.6884],\n",
       "         [0.9293, 0.5939, 0.4900]],\n",
       "\n",
       "        [[0.2272, 0.8692, 0.5268],\n",
       "         [0.5149, 0.0232, 0.7240],\n",
       "         [0.9984, 0.5682, 0.9137],\n",
       "         ...,\n",
       "         [0.4789, 0.3189, 0.2901],\n",
       "         [0.6638, 0.6364, 0.6069],\n",
       "         [0.7767, 0.3488, 0.3276]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0.7198, 0.8989, 0.8548],\n",
       "         [0.5265, 0.9177, 0.7619],\n",
       "         [0.9125, 0.3908, 0.2205],\n",
       "         ...,\n",
       "         [0.2658, 0.4717, 0.5984],\n",
       "         [0.0412, 0.6273, 0.2040],\n",
       "         [0.4773, 0.1095, 0.4967]],\n",
       "\n",
       "        [[0.2225, 0.4623, 0.8784],\n",
       "         [0.5446, 0.8719, 0.7233],\n",
       "         [0.5990, 0.2650, 0.7609],\n",
       "         ...,\n",
       "         [0.2056, 0.5558, 0.9065],\n",
       "         [0.6517, 0.2199, 0.1344],\n",
       "         [0.4879, 0.9998, 0.5098]],\n",
       "\n",
       "        [[0.1627, 0.9258, 0.5607],\n",
       "         [0.6670, 0.2340, 0.0915],\n",
       "         [0.3010, 0.0725, 0.5199],\n",
       "         ...,\n",
       "         [0.8518, 0.9549, 0.3574],\n",
       "         [0.1863, 0.5849, 0.4456],\n",
       "         [0.6424, 0.5091, 0.4616]]])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((128,128,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "b0fab5c0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.8585, 0.0054, 0.3772,  ..., 0.6055, 0.1393, 0.2135],\n",
       "         [0.9819, 0.7372, 0.9762,  ..., 0.6174, 0.8126, 0.4325],\n",
       "         [0.3510, 0.9533, 0.4632,  ..., 0.9237, 0.8125, 0.1078],\n",
       "         ...,\n",
       "         [0.2144, 0.0425, 0.6647,  ..., 0.8013, 0.3443, 0.5452],\n",
       "         [0.6792, 0.9698, 0.8691,  ..., 0.3465, 0.3107, 0.1206],\n",
       "         [0.0109, 0.2177, 0.8131,  ..., 0.2247, 0.3763, 0.5571]],\n",
       "\n",
       "        [[0.0014, 0.1144, 0.8990,  ..., 0.0086, 0.8500, 0.2776],\n",
       "         [0.7623, 0.1093, 0.1506,  ..., 0.0852, 0.2567, 0.7047],\n",
       "         [0.8652, 0.7178, 0.1446,  ..., 0.2231, 0.5553, 0.7648],\n",
       "         ...,\n",
       "         [0.6098, 0.5782, 0.5538,  ..., 0.4163, 0.4203, 0.0257],\n",
       "         [0.4202, 0.0034, 0.7426,  ..., 0.7200, 0.6140, 0.0059],\n",
       "         [0.3157, 0.1711, 0.9902,  ..., 0.5755, 0.7633, 0.0749]],\n",
       "\n",
       "        [[0.6799, 0.9526, 0.6939,  ..., 0.5626, 0.2155, 0.1861],\n",
       "         [0.0444, 0.0853, 0.6687,  ..., 0.3248, 0.6537, 0.5037],\n",
       "         [0.7708, 0.5900, 0.6310,  ..., 0.8664, 0.7281, 0.5831],\n",
       "         ...,\n",
       "         [0.7341, 0.8423, 0.0176,  ..., 0.0028, 0.4021, 0.7913],\n",
       "         [0.7730, 0.1928, 0.7890,  ..., 0.7266, 0.1632, 0.8318],\n",
       "         [0.8962, 0.9158, 0.3383,  ..., 0.1840, 0.9471, 0.8412]]])"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.rand((3,128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "2f7211f2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.zeros(2,3)    # 0으로 가득 채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "178e9046",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 1., 1.],\n",
       "        [1., 1., 1.]])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.ones(2,3)    # 1로 가득채우기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ce230b5c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[255, 255, 255],\n",
       "        [255, 255, 255]])"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.full((2,3) , 255)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "10c1cc52",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1., 0., 0.],\n",
       "        [0., 1., 0.],\n",
       "        [0., 0., 1.],\n",
       "        [0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.eye(5,3)   # 대각선 1로 이루어진 텐서"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "07000412",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[224, 232, 210,  ..., 244,  48, 138],\n",
       "        [ 17,  16,  97,  ..., 104,  47,  22],\n",
       "        [ 66, 233,  70,  ..., 246, 115, 178],\n",
       "        ...,\n",
       "        [201, 126,  59,  ..., 210,  38, 110],\n",
       "        [145, 105,  81,  ...,  16, 144,  50],\n",
       "        [200, 151,  11,  ..., 137, 232, 179]])"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# tensor의 속성\n",
    "\n",
    "tdata = torch.randint(0,255,(128,128))\n",
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "46fa23f0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([128, 128])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "5cfe645b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "80de7d58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "device(type='cpu')"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "3487bd23",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[224,  17,  66,  ..., 201, 145, 200],\n",
       "        [232,  16, 233,  ..., 126, 105, 151],\n",
       "        [210,  97,  70,  ...,  59,  81,  11],\n",
       "        ...,\n",
       "        [244, 104, 246,  ..., 210,  16, 137],\n",
       "        [ 48,  47, 115,  ...,  38, 144, 232],\n",
       "        [138,  22, 178,  ..., 110,  50, 179]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.T  # 행과열의 위치를 바꿔준다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e70785ce",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[224, 232, 210,  ..., 244,  48, 138],\n",
       "        [ 17,  16,  97,  ..., 104,  47,  22],\n",
       "        [ 66, 233,  70,  ..., 246, 115, 178],\n",
       "        ...,\n",
       "        [201, 126,  59,  ..., 210,  38, 110],\n",
       "        [145, 105,  81,  ...,  16, 144,  50],\n",
       "        [200, 151,  11,  ..., 137, 232, 179]], device='cuda:0')"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "699bebd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = tdata.to('cuda')  # GPU에 만든 새 텐서를 다시 tdata라는 이름으로 부르겠다!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "aaf7952a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata = torch.zeros(2,3)\n",
    "tdata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "17566e01",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[10., 10., 10.],\n",
       "        [10., 10., 10.]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata + 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "934c5c28",
   "metadata": {},
   "outputs": [],
   "source": [
    "tdata = torch.zeros(2,3)\n",
    "tdata1 = torch.ones(2,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "5af0dbda",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([[0., 0., 0.],\n",
      "        [0., 0., 0.]])\n",
      "tensor([[1., 1., 1.],\n",
      "        [1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "print(tdata)\n",
    "print(tdata1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "f0764c3a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-1., -1., -1.],\n",
       "        [-1., -1., -1.]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata - tdata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "bc138366",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.],\n",
       "        [0., 0., 0.]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tdata*tdata1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "d8621227",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[22, 28],\n",
       "        [49, 64]])"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mat1 = torch.tensor([[1,2,3],[4,5,6]])\n",
    "mat2 = torch.tensor([[1,2],[3,4],[5,6]])\n",
    "\n",
    "torch.matmul(mat1,mat2)\n",
    "\n",
    "# 행렬의 곱"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "b8cbe879",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[32]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mmat1\u001b[49m\u001b[43m*\u001b[49m\u001b[43mmat2\u001b[49m  \u001b[38;5;66;03m#행렬이 안맞아서 (차원이 맞아서) 오류난다\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: The size of tensor a (3) must match the size of tensor b (2) at non-singleton dimension 1"
     ]
    }
   ],
   "source": [
    "mat1*mat2  #행렬이 안맞아서 (차원이 맞아서) 오류난다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "1d20349b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.zeros(128,128)\n",
    "data.shape\n",
    "data.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "01ce83cf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3, 3])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([[1,2,3],[4,5,6],[7,8,9]])\n",
    "data.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "02f5b80f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "9eced62e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[0]  # 0번째 행을 가져와라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "31c43d85",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4, 5, 6])"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[1]  # 1번째 행을 가져와라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "ca01b86a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([3, 6, 9])"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "443d41fa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3],\n",
       "        [4, 5, 6],\n",
       "        [7, 8, 9]])"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,]  # 모든행"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "cdbe120a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [4, 5],\n",
       "        [7, 8]])"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data[:,0:2]   # 0과1열의 모든 행을 가져와라"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "a478e7a0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.zeros(128,128)\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "774c8d65",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.],\n",
       "        [0., 0., 0.,  ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 사람 이미지   12, 12, 64(가로크기) , 64 (세로크기)\n",
    "# 그럼 이미지는 행은 12행 부터 77행 전까지 가져오고  열은 12열 부터 77열 까지\n",
    "data[12:77, 12:77]\n",
    "\n",
    "# 이걸 png파일로 바꾸기만하면 이미지 가져온다\n",
    "# 이게 인덱싱, 슬라이싱 개념이다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "5fc13acb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(10)"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([[1,2],[3,4]])\n",
    "\n",
    "torch.sum(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "35b7f159",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "07d639c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.int64\n"
     ]
    }
   ],
   "source": [
    "print(data.dtype)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "c7168ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "e5a35116",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[47]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmean\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[31mRuntimeError\u001b[39m: mean(): could not infer output dtype. Input dtype must be either a floating point or complex dtype. Got: Long"
     ]
    }
   ],
   "source": [
    "torch.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a07b624",
   "metadata": {},
   "outputs": [],
   "source": [
    "#float형으로바꿔야함"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "e2a53175",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to(torch.float16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "68fee6c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(2.5000, dtype=torch.float16)"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.mean(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "415b03bb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.6670, dtype=torch.float16)"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.var(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "3ba07546",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(1.2910, dtype=torch.float16)"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.std(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "39a3ad1d",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = torch.randint(0,255,(128,128))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "442333eb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[124, 187, 208, ..., 222, 110,  82],\n",
       "       [ 42, 225, 105, ..., 165, 140, 103],\n",
       "       [179, 201, 166, ...,  31,  34,  41],\n",
       "       ...,\n",
       "       [198, 155, 108, ...,  22,  75,  50],\n",
       "       [ 41,  44, 245, ..., 253, 170,  17],\n",
       "       [146,  73,  22, ...,  70,   2,  78]], shape=(128, 128))"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# numpy로 바꾸려면\n",
    "\n",
    "data.numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6399da8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.tensor(np_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "4ce2420c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([1,2,3])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "348e6f24",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([3])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "13944491",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 57,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dim()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "d6fd509c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data_mat = data.unsqueeze(0)   # 아주 빈번하게 쓴다  차원을 하나 늘려준다\n",
    "\n",
    "data_mat"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "6b6a480d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2, 3]])"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([[1,2,3]])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "cf50f57b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.squeeze(0)  # 차원을 하나 제거해줌"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "a6c99fb8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1, 2],\n",
       "        [3, 4]])"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([[1,2],[3,4]])\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "72ab1ab0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<function Tensor.dim()>"
      ]
     },
     "execution_count": 62,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "data.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "e3657c03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.int64"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.dtype"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "d4632b8a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3, 4])"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 매트릭스를 한 줄로 쫙 펴고 싶어 벡터로 바꿔야함\n",
    "\n",
    "data_view = data.view(-1)\n",
    "data_view"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "a94e5a57",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# GPU가 있는지 없는지 확인하는것\n",
    "\n",
    "torch.cuda.is_available()   #CUDA 사용유무"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "4aa12849",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.device_count()   # 그래픽카드 개수"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "f7d0e4dc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.current_device()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e26bcfdb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([1,2,3])\n",
    "\n",
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "52d648f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.to('cuda')   #바로 gpu로 올라간다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "76e43018",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3])"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "5ff946ba",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.to('cuda')   #'cuda:1'  1번 그래픽카드에 올리겠다, 여러개 있을때"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "a6e2d5af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1, 2, 3], device='cuda:0')"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "8cd15a29",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "16b2c2b9",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[74]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m data1 = torch.tensor([\u001b[32m10\u001b[39m,\u001b[32m20\u001b[39m,\u001b[32m30\u001b[39m])\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m \u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata1\u001b[49m\n\u001b[32m      5\u001b[39m \u001b[38;5;66;03m# 같은 device에 없다고 오류남. 같은 devicced에 있어야 연산이 가능하다\u001b[39;00m\n",
      "\u001b[31mRuntimeError\u001b[39m: Expected all tensors to be on the same device, but found at least two devices, cuda:0 and cpu!"
     ]
    }
   ],
   "source": [
    "data1 = torch.tensor([10,20,30])\n",
    "\n",
    "data + data1\n",
    "\n",
    "# 같은 device에 없다고 오류남. 같은 devicced에 있어야 연산이 가능하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "c62960d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 = data1.to('cuda')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "a6e38f09",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11, 22, 33], device='cuda:0')"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data + data1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "ec09af37",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([1., 2., 3.], requires_grad=True)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = torch.tensor([1.,2.,3.], requires_grad=True)\n",
    "\n",
    "data\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "e1be092e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([2., 3., 4.], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = data + 1\n",
    "\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "46c8487b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([4., 6., 8.], grad_fn=<MulBackward0>)"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = a * 2\n",
    "b\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "e7e275cb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([16., 36., 64.], grad_fn=<PowBackward0>)"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "c = b**2\n",
    "c"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "448a5de6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n",
      "None\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_51448\\2179822287.py:1: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:497.)\n",
      "  print(a.grad)\n",
      "C:\\Users\\user\\AppData\\Local\\Temp\\ipykernel_51448\\2179822287.py:2: UserWarning: The .grad attribute of a Tensor that is not a leaf Tensor is being accessed. Its .grad attribute won't be populated during autograd.backward(). If you indeed want the .grad field to be populated for a non-leaf Tensor, use .retain_grad() on the non-leaf Tensor. If you access the non-leaf Tensor by mistake, make sure you access the leaf Tensor instead. See github.com/pytorch/pytorch/pull/30531 for more information. (Triggered internally at C:\\actions-runner\\_work\\pytorch\\pytorch\\pytorch\\build\\aten\\src\\ATen/core/TensorBody.h:497.)\n",
      "  print(b.grad)\n"
     ]
    }
   ],
   "source": [
    "print(a.grad)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "id": "b1d05886",
   "metadata": {},
   "outputs": [],
   "source": [
    "loss = c.sum()\n",
    "\n",
    "loss.backward()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "bf08e6db",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "grad can be implicitly created only for scalar outputs",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mRuntimeError\u001b[39m                              Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[83]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mb\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m      2\u001b[39m \u001b[38;5;28mprint\u001b[39m(a)\n\u001b[32m      3\u001b[39m \u001b[38;5;28mprint\u001b[39m(a.grad)\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\jwdeep\\.venv\\Lib\\site-packages\\torch\\_tensor.py:630\u001b[39m, in \u001b[36mTensor.backward\u001b[39m\u001b[34m(self, gradient, retain_graph, create_graph, inputs)\u001b[39m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m has_torch_function_unary(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m    621\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m handle_torch_function(\n\u001b[32m    622\u001b[39m         Tensor.backward,\n\u001b[32m    623\u001b[39m         (\u001b[38;5;28mself\u001b[39m,),\n\u001b[32m   (...)\u001b[39m\u001b[32m    628\u001b[39m         inputs=inputs,\n\u001b[32m    629\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m630\u001b[39m \u001b[43mtorch\u001b[49m\u001b[43m.\u001b[49m\u001b[43mautograd\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbackward\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    631\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgradient\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretain_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcreate_graph\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minputs\u001b[49m\u001b[43m=\u001b[49m\u001b[43minputs\u001b[49m\n\u001b[32m    632\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\jwdeep\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:357\u001b[39m, in \u001b[36mbackward\u001b[39m\u001b[34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[39m\n\u001b[32m    354\u001b[39m     tensors = \u001b[38;5;28mtuple\u001b[39m(tensors)\n\u001b[32m    356\u001b[39m grad_tensors_ = _tensor_or_tensors_to_tuple(grad_tensors, \u001b[38;5;28mlen\u001b[39m(tensors))\n\u001b[32m--> \u001b[39m\u001b[32m357\u001b[39m grad_tensors_ = \u001b[43m_make_grads\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtensors\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgrad_tensors_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_grads_batched\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    358\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m retain_graph \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    359\u001b[39m     retain_graph = create_graph\n",
      "\u001b[36mFile \u001b[39m\u001b[32mc:\\jwdeep\\.venv\\Lib\\site-packages\\torch\\autograd\\__init__.py:205\u001b[39m, in \u001b[36m_make_grads\u001b[39m\u001b[34m(outputs, grads, is_grads_batched)\u001b[39m\n\u001b[32m    203\u001b[39m     out_numel_is_1 = out.numel() == \u001b[32m1\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_numel_is_1:\n\u001b[32m--> \u001b[39m\u001b[32m205\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\n\u001b[32m    206\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgrad can be implicitly created only for scalar outputs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    207\u001b[39m     )\n\u001b[32m    208\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m out_dtype.is_floating_point:\n\u001b[32m    209\u001b[39m     msg = (\n\u001b[32m    210\u001b[39m         \u001b[33m\"\u001b[39m\u001b[33mgrad can be implicitly created only for real scalar outputs\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    211\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m but got \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mout_dtype\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    212\u001b[39m     )\n",
      "\u001b[31mRuntimeError\u001b[39m: grad can be implicitly created only for scalar outputs"
     ]
    }
   ],
   "source": [
    "b.backward()\n",
    "print(a)\n",
    "print(a.grad)\n",
    "print(b)\n",
    "print(b.grad)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "63c3b1c6",
   "metadata": {},
   "source": [
    "# Neural Network (nn) class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "0d2f4680",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Net(\n",
       "  (fc1): Linear(in_features=3, out_features=4, bias=True)\n",
       "  (fc1_act): ReLU()\n",
       "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc2_act): ReLU()\n",
       "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 신경망 만들어보자\n",
    "\n",
    "\n",
    "import torch.nn as nn\n",
    "\n",
    "# 클래스로 만들어서 사용한다\n",
    "# nn.Mudule이라는 신경망을 상속받는다\n",
    "\n",
    "class Net(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Net, self).__init__()\n",
    "        self.fc1 = nn.Linear(in_features=3, out_features=4, bias=True)\n",
    "        self.fc1_act = nn.ReLU()\n",
    "        self.fc2 = nn.Linear(in_features=4, out_features=3, bias=True)\n",
    "        self.fc2_act = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(in_features=3, out_features=1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        out = self.fc1(x)\n",
    "        out = self.fc1_act(out)\n",
    "        out = self.fc2(out)\n",
    "        out = self.fc2_act(out)\n",
    "        out = self.fc3(out)\n",
    "        return out\n",
    "    \n",
    "\n",
    "\n",
    "model1 = Net()\n",
    "model1\n",
    "\n",
    "# model1은 클래스를 갖고 만든 하나의 복사본이다\n",
    "# 수백개 만들수있다\n",
    "\n",
    "# 복사본인지 아닌지 구분하기위해서 self가 붙는다\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "id": "2f723375",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[-0.1012, -0.4628,  0.5446],\n",
       "         [-0.2322, -0.1823, -0.1069],\n",
       "         [-0.5332,  0.0542,  0.5712],\n",
       "         [ 0.5462,  0.4220,  0.3459]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.2193, -0.2810,  0.5200,  0.1818], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.4883,  0.1532,  0.1794, -0.4351],\n",
       "         [-0.3927,  0.2097, -0.4630,  0.1381],\n",
       "         [-0.1656, -0.3470, -0.2661,  0.0355]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3072,  0.1696, -0.4924], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[ 0.0619,  0.1506, -0.1820]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([0.0137], requires_grad=True)]"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "\n",
    "list(model1.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "19bdd698",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 이 모델이 학습해야하는 파라미터의 개수를 세어보면\n",
    "\n",
    "len(list(model1.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "id": "5bc9c071",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "6"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(list(model1.parameters()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "02fc8bf1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1913],\n",
       "        [-0.6155],\n",
       "        [ 1.5214],\n",
       "        [-0.2125],\n",
       "        [-2.0928],\n",
       "        [ 0.1705],\n",
       "        [ 0.4929],\n",
       "        [ 0.8783],\n",
       "        [ 0.3467],\n",
       "        [ 0.8863],\n",
       "        [ 0.4708],\n",
       "        [ 0.3659],\n",
       "        [ 0.8778],\n",
       "        [ 1.7926],\n",
       "        [ 0.5086],\n",
       "        [-1.0334],\n",
       "        [-0.7467],\n",
       "        [-0.2994],\n",
       "        [-2.2131],\n",
       "        [ 0.9326],\n",
       "        [-0.8678],\n",
       "        [ 1.2280],\n",
       "        [ 0.8022],\n",
       "        [ 1.9912],\n",
       "        [-1.1096],\n",
       "        [-0.0076],\n",
       "        [ 0.2130],\n",
       "        [-0.3927],\n",
       "        [ 0.0281],\n",
       "        [ 0.9067],\n",
       "        [-0.7028],\n",
       "        [-1.2091],\n",
       "        [ 0.0112],\n",
       "        [-0.0963],\n",
       "        [-1.6338],\n",
       "        [-0.0148],\n",
       "        [ 0.2553],\n",
       "        [ 0.2657],\n",
       "        [ 0.1155],\n",
       "        [ 1.0235],\n",
       "        [ 1.5374],\n",
       "        [-2.8581],\n",
       "        [-0.4479],\n",
       "        [ 1.1171],\n",
       "        [-0.1499],\n",
       "        [ 1.5621],\n",
       "        [-0.1227],\n",
       "        [-1.1497],\n",
       "        [ 2.4400],\n",
       "        [-0.0922],\n",
       "        [-0.8216],\n",
       "        [-1.2351],\n",
       "        [-1.2218],\n",
       "        [ 0.3552],\n",
       "        [-1.0478],\n",
       "        [ 0.5787],\n",
       "        [-0.1610],\n",
       "        [-0.9350],\n",
       "        [-0.2315],\n",
       "        [-0.2910],\n",
       "        [ 0.0839],\n",
       "        [ 0.1302],\n",
       "        [ 0.3486],\n",
       "        [-0.1218],\n",
       "        [ 1.3041],\n",
       "        [-0.2362],\n",
       "        [ 0.1072],\n",
       "        [ 0.1087],\n",
       "        [-0.5572],\n",
       "        [ 0.8585],\n",
       "        [ 2.7636],\n",
       "        [-0.0932],\n",
       "        [ 0.5467],\n",
       "        [ 0.7072],\n",
       "        [ 0.5313],\n",
       "        [ 1.0151],\n",
       "        [-0.8913],\n",
       "        [ 0.5096],\n",
       "        [-0.0165],\n",
       "        [ 0.4098],\n",
       "        [ 0.9037],\n",
       "        [-1.0488],\n",
       "        [ 1.0955],\n",
       "        [-2.2713],\n",
       "        [ 0.7201],\n",
       "        [ 0.1220],\n",
       "        [ 0.4067],\n",
       "        [-0.6341],\n",
       "        [-0.3178],\n",
       "        [-1.0550],\n",
       "        [ 0.4799],\n",
       "        [-1.3043],\n",
       "        [-0.1027],\n",
       "        [-0.8804],\n",
       "        [ 0.7007],\n",
       "        [-0.7029],\n",
       "        [ 0.5305],\n",
       "        [ 0.0072],\n",
       "        [ 0.7611],\n",
       "        [ 0.7588]])"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = torch.randn(100,1)\n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "id": "e763361c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = X*10\n",
    "X.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "id": "82aeb7e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([100, 1])"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "id": "11ebd0c0",
   "metadata": {},
   "outputs": [],
   "source": [
    "noise = torch.randn(100, 1) * 5 \n",
    "y = 3 * X + 2 + noise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "id": "79a54643",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "plt.scatter(X,y)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "id": "9e8e42a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LRModel(\n",
       "  (fc1): Linear(in_features=1, out_features=4, bias=True)\n",
       "  (fc1_act): ReLU()\n",
       "  (fc2): Linear(in_features=4, out_features=3, bias=True)\n",
       "  (fc2_act): ReLU()\n",
       "  (fc3): Linear(in_features=3, out_features=1, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class LRModel(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(LRModel,self).__init__()\n",
    "        self.fc1 = nn.Linear(1,4)  # fully connected\n",
    "        self.fc1_act = nn.ReLU()   # 딥러닝은 무조건 레이어 통과할 때 활성함수(렐루) 필요함\n",
    "        self.fc2 = nn.Linear(4,3)\n",
    "        self.fc2_act = nn.ReLU()\n",
    "        self.fc3 = nn.Linear(3,1)\n",
    "\n",
    "    def forward(self,x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.fc1_act(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.fc2_act(x)\n",
    "        x = self.fc3(x)\n",
    "\n",
    "        return x\n",
    "    \n",
    "\n",
    "model = LRModel()\n",
    "model\n",
    "    # 선형회기 모델 간단히 만들었다\n",
    "    \n",
    "    \n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "bec66911",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[ 0.9903],\n",
       "         [-0.0347],\n",
       "         [ 0.4371],\n",
       "         [-0.0870]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4999,  0.6170,  0.7680, -0.9765], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0536, -0.0208,  0.3117, -0.4913],\n",
       "         [ 0.0479,  0.3678, -0.2331, -0.2898],\n",
       "         [ 0.4303, -0.1468, -0.1237, -0.3374]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.3259, -0.1053,  0.1634], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.4920, -0.0033,  0.3688]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.4124], requires_grad=True)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(model.parameters())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "ffa525d4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor(819.9436, grad_fn=<MseLossBackward0>)\n",
      "tensor(819.3184, grad_fn=<MseLossBackward0>)\n",
      "tensor(818.7059, grad_fn=<MseLossBackward0>)\n",
      "tensor(818.1028, grad_fn=<MseLossBackward0>)\n",
      "tensor(817.5014, grad_fn=<MseLossBackward0>)\n",
      "tensor(816.9120, grad_fn=<MseLossBackward0>)\n",
      "tensor(816.3445, grad_fn=<MseLossBackward0>)\n",
      "tensor(815.7757, grad_fn=<MseLossBackward0>)\n",
      "tensor(815.2078, grad_fn=<MseLossBackward0>)\n",
      "tensor(814.6470, grad_fn=<MseLossBackward0>)\n",
      "tensor(814.0907, grad_fn=<MseLossBackward0>)\n",
      "tensor(813.5341, grad_fn=<MseLossBackward0>)\n",
      "tensor(812.9779, grad_fn=<MseLossBackward0>)\n",
      "tensor(812.4266, grad_fn=<MseLossBackward0>)\n",
      "tensor(811.8736, grad_fn=<MseLossBackward0>)\n",
      "tensor(811.3248, grad_fn=<MseLossBackward0>)\n",
      "tensor(810.7756, grad_fn=<MseLossBackward0>)\n",
      "tensor(810.2244, grad_fn=<MseLossBackward0>)\n",
      "tensor(809.6738, grad_fn=<MseLossBackward0>)\n",
      "tensor(809.1272, grad_fn=<MseLossBackward0>)\n",
      "tensor(808.5847, grad_fn=<MseLossBackward0>)\n",
      "tensor(808.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(807.5034, grad_fn=<MseLossBackward0>)\n",
      "tensor(806.9608, grad_fn=<MseLossBackward0>)\n",
      "tensor(806.4180, grad_fn=<MseLossBackward0>)\n",
      "tensor(805.8739, grad_fn=<MseLossBackward0>)\n",
      "tensor(805.3278, grad_fn=<MseLossBackward0>)\n",
      "tensor(804.7834, grad_fn=<MseLossBackward0>)\n",
      "tensor(804.2375, grad_fn=<MseLossBackward0>)\n",
      "tensor(803.6893, grad_fn=<MseLossBackward0>)\n",
      "tensor(803.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(802.5891, grad_fn=<MseLossBackward0>)\n",
      "tensor(802.0383, grad_fn=<MseLossBackward0>)\n",
      "tensor(801.4857, grad_fn=<MseLossBackward0>)\n",
      "tensor(800.9307, grad_fn=<MseLossBackward0>)\n",
      "tensor(800.3731, grad_fn=<MseLossBackward0>)\n",
      "tensor(799.8129, grad_fn=<MseLossBackward0>)\n",
      "tensor(799.2499, grad_fn=<MseLossBackward0>)\n",
      "tensor(798.6841, grad_fn=<MseLossBackward0>)\n",
      "tensor(798.1155, grad_fn=<MseLossBackward0>)\n",
      "tensor(797.5439, grad_fn=<MseLossBackward0>)\n",
      "tensor(796.9693, grad_fn=<MseLossBackward0>)\n",
      "tensor(796.3914, grad_fn=<MseLossBackward0>)\n",
      "tensor(795.8105, grad_fn=<MseLossBackward0>)\n",
      "tensor(795.2264, grad_fn=<MseLossBackward0>)\n",
      "tensor(794.6390, grad_fn=<MseLossBackward0>)\n",
      "tensor(794.0483, grad_fn=<MseLossBackward0>)\n",
      "tensor(793.4543, grad_fn=<MseLossBackward0>)\n",
      "tensor(792.8569, grad_fn=<MseLossBackward0>)\n",
      "tensor(792.2560, grad_fn=<MseLossBackward0>)\n",
      "tensor(791.6516, grad_fn=<MseLossBackward0>)\n",
      "tensor(791.0439, grad_fn=<MseLossBackward0>)\n",
      "tensor(790.4327, grad_fn=<MseLossBackward0>)\n",
      "tensor(789.8186, grad_fn=<MseLossBackward0>)\n",
      "tensor(789.2011, grad_fn=<MseLossBackward0>)\n",
      "tensor(788.5799, grad_fn=<MseLossBackward0>)\n",
      "tensor(787.9553, grad_fn=<MseLossBackward0>)\n",
      "tensor(787.3267, grad_fn=<MseLossBackward0>)\n",
      "tensor(786.6948, grad_fn=<MseLossBackward0>)\n",
      "tensor(786.0591, grad_fn=<MseLossBackward0>)\n",
      "tensor(785.4197, grad_fn=<MseLossBackward0>)\n",
      "tensor(784.7771, grad_fn=<MseLossBackward0>)\n",
      "tensor(784.1312, grad_fn=<MseLossBackward0>)\n",
      "tensor(783.4814, grad_fn=<MseLossBackward0>)\n",
      "tensor(782.8278, grad_fn=<MseLossBackward0>)\n",
      "tensor(782.1703, grad_fn=<MseLossBackward0>)\n",
      "tensor(781.5100, grad_fn=<MseLossBackward0>)\n",
      "tensor(780.8459, grad_fn=<MseLossBackward0>)\n",
      "tensor(780.1780, grad_fn=<MseLossBackward0>)\n",
      "tensor(779.5062, grad_fn=<MseLossBackward0>)\n",
      "tensor(778.8304, grad_fn=<MseLossBackward0>)\n",
      "tensor(778.1506, grad_fn=<MseLossBackward0>)\n",
      "tensor(777.4667, grad_fn=<MseLossBackward0>)\n",
      "tensor(776.7788, grad_fn=<MseLossBackward0>)\n",
      "tensor(776.0873, grad_fn=<MseLossBackward0>)\n",
      "tensor(775.3917, grad_fn=<MseLossBackward0>)\n",
      "tensor(774.6917, grad_fn=<MseLossBackward0>)\n",
      "tensor(773.9879, grad_fn=<MseLossBackward0>)\n",
      "tensor(773.2796, grad_fn=<MseLossBackward0>)\n",
      "tensor(772.5673, grad_fn=<MseLossBackward0>)\n",
      "tensor(771.8505, grad_fn=<MseLossBackward0>)\n",
      "tensor(771.1296, grad_fn=<MseLossBackward0>)\n",
      "tensor(770.4047, grad_fn=<MseLossBackward0>)\n",
      "tensor(769.6755, grad_fn=<MseLossBackward0>)\n",
      "tensor(768.9418, grad_fn=<MseLossBackward0>)\n",
      "tensor(768.2036, grad_fn=<MseLossBackward0>)\n",
      "tensor(767.4611, grad_fn=<MseLossBackward0>)\n",
      "tensor(766.7138, grad_fn=<MseLossBackward0>)\n",
      "tensor(765.9623, grad_fn=<MseLossBackward0>)\n",
      "tensor(765.2065, grad_fn=<MseLossBackward0>)\n",
      "tensor(764.4464, grad_fn=<MseLossBackward0>)\n",
      "tensor(763.6816, grad_fn=<MseLossBackward0>)\n",
      "tensor(762.9122, grad_fn=<MseLossBackward0>)\n",
      "tensor(762.1384, grad_fn=<MseLossBackward0>)\n",
      "tensor(761.3599, grad_fn=<MseLossBackward0>)\n",
      "tensor(760.5767, grad_fn=<MseLossBackward0>)\n",
      "tensor(759.7889, grad_fn=<MseLossBackward0>)\n",
      "tensor(758.9963, grad_fn=<MseLossBackward0>)\n",
      "tensor(758.1989, grad_fn=<MseLossBackward0>)\n",
      "tensor(757.3965, grad_fn=<MseLossBackward0>)\n",
      "tensor(756.5893, grad_fn=<MseLossBackward0>)\n",
      "tensor(755.7772, grad_fn=<MseLossBackward0>)\n",
      "tensor(754.9601, grad_fn=<MseLossBackward0>)\n",
      "tensor(754.1379, grad_fn=<MseLossBackward0>)\n",
      "tensor(753.3108, grad_fn=<MseLossBackward0>)\n",
      "tensor(752.4786, grad_fn=<MseLossBackward0>)\n",
      "tensor(751.6414, grad_fn=<MseLossBackward0>)\n",
      "tensor(750.7986, grad_fn=<MseLossBackward0>)\n",
      "tensor(749.9509, grad_fn=<MseLossBackward0>)\n",
      "tensor(749.0980, grad_fn=<MseLossBackward0>)\n",
      "tensor(748.2397, grad_fn=<MseLossBackward0>)\n",
      "tensor(747.3762, grad_fn=<MseLossBackward0>)\n",
      "tensor(746.5073, grad_fn=<MseLossBackward0>)\n",
      "tensor(745.6331, grad_fn=<MseLossBackward0>)\n",
      "tensor(744.7534, grad_fn=<MseLossBackward0>)\n",
      "tensor(743.8684, grad_fn=<MseLossBackward0>)\n",
      "tensor(742.9779, grad_fn=<MseLossBackward0>)\n",
      "tensor(742.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(741.1802, grad_fn=<MseLossBackward0>)\n",
      "tensor(740.2733, grad_fn=<MseLossBackward0>)\n",
      "tensor(739.3605, grad_fn=<MseLossBackward0>)\n",
      "tensor(738.4423, grad_fn=<MseLossBackward0>)\n",
      "tensor(737.5182, grad_fn=<MseLossBackward0>)\n",
      "tensor(736.5885, grad_fn=<MseLossBackward0>)\n",
      "tensor(735.6532, grad_fn=<MseLossBackward0>)\n",
      "tensor(734.7120, grad_fn=<MseLossBackward0>)\n",
      "tensor(733.7651, grad_fn=<MseLossBackward0>)\n",
      "tensor(732.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(731.8538, grad_fn=<MseLossBackward0>)\n",
      "tensor(730.8895, grad_fn=<MseLossBackward0>)\n",
      "tensor(729.9191, grad_fn=<MseLossBackward0>)\n",
      "tensor(728.9429, grad_fn=<MseLossBackward0>)\n",
      "tensor(727.9606, grad_fn=<MseLossBackward0>)\n",
      "tensor(726.9724, grad_fn=<MseLossBackward0>)\n",
      "tensor(725.9781, grad_fn=<MseLossBackward0>)\n",
      "tensor(724.9778, grad_fn=<MseLossBackward0>)\n",
      "tensor(723.9714, grad_fn=<MseLossBackward0>)\n",
      "tensor(722.9590, grad_fn=<MseLossBackward0>)\n",
      "tensor(721.9404, grad_fn=<MseLossBackward0>)\n",
      "tensor(720.9156, grad_fn=<MseLossBackward0>)\n",
      "tensor(719.8845, grad_fn=<MseLossBackward0>)\n",
      "tensor(718.8474, grad_fn=<MseLossBackward0>)\n",
      "tensor(717.8040, grad_fn=<MseLossBackward0>)\n",
      "tensor(716.7542, grad_fn=<MseLossBackward0>)\n",
      "tensor(715.6982, grad_fn=<MseLossBackward0>)\n",
      "tensor(714.6359, grad_fn=<MseLossBackward0>)\n",
      "tensor(713.5671, grad_fn=<MseLossBackward0>)\n",
      "tensor(712.4921, grad_fn=<MseLossBackward0>)\n",
      "tensor(711.4105, grad_fn=<MseLossBackward0>)\n",
      "tensor(710.3226, grad_fn=<MseLossBackward0>)\n",
      "tensor(709.2283, grad_fn=<MseLossBackward0>)\n",
      "tensor(708.1275, grad_fn=<MseLossBackward0>)\n",
      "tensor(707.0201, grad_fn=<MseLossBackward0>)\n",
      "tensor(705.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(704.7859, grad_fn=<MseLossBackward0>)\n",
      "tensor(703.6589, grad_fn=<MseLossBackward0>)\n",
      "tensor(702.5255, grad_fn=<MseLossBackward0>)\n",
      "tensor(701.3853, grad_fn=<MseLossBackward0>)\n",
      "tensor(700.2385, grad_fn=<MseLossBackward0>)\n",
      "tensor(699.0850, grad_fn=<MseLossBackward0>)\n",
      "tensor(697.9250, grad_fn=<MseLossBackward0>)\n",
      "tensor(696.7582, grad_fn=<MseLossBackward0>)\n",
      "tensor(695.5850, grad_fn=<MseLossBackward0>)\n",
      "tensor(694.4051, grad_fn=<MseLossBackward0>)\n",
      "tensor(693.2184, grad_fn=<MseLossBackward0>)\n",
      "tensor(692.0250, grad_fn=<MseLossBackward0>)\n",
      "tensor(690.8248, grad_fn=<MseLossBackward0>)\n",
      "tensor(689.6179, grad_fn=<MseLossBackward0>)\n",
      "tensor(688.4043, grad_fn=<MseLossBackward0>)\n",
      "tensor(687.1838, grad_fn=<MseLossBackward0>)\n",
      "tensor(685.9564, grad_fn=<MseLossBackward0>)\n",
      "tensor(684.7223, grad_fn=<MseLossBackward0>)\n",
      "tensor(683.4813, grad_fn=<MseLossBackward0>)\n",
      "tensor(682.2335, grad_fn=<MseLossBackward0>)\n",
      "tensor(680.9789, grad_fn=<MseLossBackward0>)\n",
      "tensor(679.7177, grad_fn=<MseLossBackward0>)\n",
      "tensor(678.4495, grad_fn=<MseLossBackward0>)\n",
      "tensor(677.1744, grad_fn=<MseLossBackward0>)\n",
      "tensor(675.8925, grad_fn=<MseLossBackward0>)\n",
      "tensor(674.6037, grad_fn=<MseLossBackward0>)\n",
      "tensor(673.3078, grad_fn=<MseLossBackward0>)\n",
      "tensor(672.0051, grad_fn=<MseLossBackward0>)\n",
      "tensor(670.6956, grad_fn=<MseLossBackward0>)\n",
      "tensor(669.3793, grad_fn=<MseLossBackward0>)\n",
      "tensor(668.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(666.7258, grad_fn=<MseLossBackward0>)\n",
      "tensor(665.3890, grad_fn=<MseLossBackward0>)\n",
      "tensor(664.0452, grad_fn=<MseLossBackward0>)\n",
      "tensor(662.6945, grad_fn=<MseLossBackward0>)\n",
      "tensor(661.3368, grad_fn=<MseLossBackward0>)\n",
      "tensor(659.9721, grad_fn=<MseLossBackward0>)\n",
      "tensor(658.6005, grad_fn=<MseLossBackward0>)\n",
      "tensor(657.2219, grad_fn=<MseLossBackward0>)\n",
      "tensor(655.8364, grad_fn=<MseLossBackward0>)\n",
      "tensor(654.4440, grad_fn=<MseLossBackward0>)\n",
      "tensor(653.0446, grad_fn=<MseLossBackward0>)\n",
      "tensor(651.6381, grad_fn=<MseLossBackward0>)\n",
      "tensor(650.2248, grad_fn=<MseLossBackward0>)\n",
      "tensor(648.8045, grad_fn=<MseLossBackward0>)\n",
      "tensor(647.3773, grad_fn=<MseLossBackward0>)\n",
      "tensor(645.9431, grad_fn=<MseLossBackward0>)\n",
      "tensor(644.5020, grad_fn=<MseLossBackward0>)\n",
      "tensor(643.0538, grad_fn=<MseLossBackward0>)\n",
      "tensor(641.5988, grad_fn=<MseLossBackward0>)\n",
      "tensor(640.1368, grad_fn=<MseLossBackward0>)\n",
      "tensor(638.6680, grad_fn=<MseLossBackward0>)\n",
      "tensor(637.1923, grad_fn=<MseLossBackward0>)\n",
      "tensor(635.7096, grad_fn=<MseLossBackward0>)\n",
      "tensor(634.2200, grad_fn=<MseLossBackward0>)\n",
      "tensor(632.7234, grad_fn=<MseLossBackward0>)\n",
      "tensor(631.2202, grad_fn=<MseLossBackward0>)\n",
      "tensor(629.7100, grad_fn=<MseLossBackward0>)\n",
      "tensor(628.1929, grad_fn=<MseLossBackward0>)\n",
      "tensor(626.6690, grad_fn=<MseLossBackward0>)\n",
      "tensor(625.1382, grad_fn=<MseLossBackward0>)\n",
      "tensor(623.6006, grad_fn=<MseLossBackward0>)\n",
      "tensor(622.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(620.5051, grad_fn=<MseLossBackward0>)\n",
      "tensor(618.9471, grad_fn=<MseLossBackward0>)\n",
      "tensor(617.3823, grad_fn=<MseLossBackward0>)\n",
      "tensor(615.8107, grad_fn=<MseLossBackward0>)\n",
      "tensor(614.2325, grad_fn=<MseLossBackward0>)\n",
      "tensor(612.6476, grad_fn=<MseLossBackward0>)\n",
      "tensor(611.0559, grad_fn=<MseLossBackward0>)\n",
      "tensor(609.4576, grad_fn=<MseLossBackward0>)\n",
      "tensor(607.8527, grad_fn=<MseLossBackward0>)\n",
      "tensor(606.2410, grad_fn=<MseLossBackward0>)\n",
      "tensor(604.6227, grad_fn=<MseLossBackward0>)\n",
      "tensor(602.9979, grad_fn=<MseLossBackward0>)\n",
      "tensor(601.3665, grad_fn=<MseLossBackward0>)\n",
      "tensor(599.7284, grad_fn=<MseLossBackward0>)\n",
      "tensor(598.0839, grad_fn=<MseLossBackward0>)\n",
      "tensor(596.4329, grad_fn=<MseLossBackward0>)\n",
      "tensor(594.7753, grad_fn=<MseLossBackward0>)\n",
      "tensor(593.1114, grad_fn=<MseLossBackward0>)\n",
      "tensor(591.4409, grad_fn=<MseLossBackward0>)\n",
      "tensor(589.7642, grad_fn=<MseLossBackward0>)\n",
      "tensor(588.0810, grad_fn=<MseLossBackward0>)\n",
      "tensor(586.3914, grad_fn=<MseLossBackward0>)\n",
      "tensor(584.6956, grad_fn=<MseLossBackward0>)\n",
      "tensor(582.9933, grad_fn=<MseLossBackward0>)\n",
      "tensor(581.2850, grad_fn=<MseLossBackward0>)\n",
      "tensor(579.5703, grad_fn=<MseLossBackward0>)\n",
      "tensor(577.8494, grad_fn=<MseLossBackward0>)\n",
      "tensor(576.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(574.3893, grad_fn=<MseLossBackward0>)\n",
      "tensor(572.6500, grad_fn=<MseLossBackward0>)\n",
      "tensor(570.9047, grad_fn=<MseLossBackward0>)\n",
      "tensor(569.1533, grad_fn=<MseLossBackward0>)\n",
      "tensor(567.3959, grad_fn=<MseLossBackward0>)\n",
      "tensor(565.6327, grad_fn=<MseLossBackward0>)\n",
      "tensor(563.8635, grad_fn=<MseLossBackward0>)\n",
      "tensor(562.0884, grad_fn=<MseLossBackward0>)\n",
      "tensor(560.3074, grad_fn=<MseLossBackward0>)\n",
      "tensor(558.5208, grad_fn=<MseLossBackward0>)\n",
      "tensor(556.7283, grad_fn=<MseLossBackward0>)\n",
      "tensor(554.9299, grad_fn=<MseLossBackward0>)\n",
      "tensor(553.1258, grad_fn=<MseLossBackward0>)\n",
      "tensor(551.3162, grad_fn=<MseLossBackward0>)\n",
      "tensor(549.5009, grad_fn=<MseLossBackward0>)\n",
      "tensor(547.6801, grad_fn=<MseLossBackward0>)\n",
      "tensor(545.8538, grad_fn=<MseLossBackward0>)\n",
      "tensor(544.0220, grad_fn=<MseLossBackward0>)\n",
      "tensor(542.1848, grad_fn=<MseLossBackward0>)\n",
      "tensor(540.3421, grad_fn=<MseLossBackward0>)\n",
      "tensor(538.4941, grad_fn=<MseLossBackward0>)\n",
      "tensor(536.6408, grad_fn=<MseLossBackward0>)\n",
      "tensor(534.7823, grad_fn=<MseLossBackward0>)\n",
      "tensor(532.9186, grad_fn=<MseLossBackward0>)\n",
      "tensor(531.0497, grad_fn=<MseLossBackward0>)\n",
      "tensor(529.1759, grad_fn=<MseLossBackward0>)\n",
      "tensor(527.2972, grad_fn=<MseLossBackward0>)\n",
      "tensor(525.4136, grad_fn=<MseLossBackward0>)\n",
      "tensor(523.5251, grad_fn=<MseLossBackward0>)\n",
      "tensor(521.6316, grad_fn=<MseLossBackward0>)\n",
      "tensor(519.7334, grad_fn=<MseLossBackward0>)\n",
      "tensor(517.8303, grad_fn=<MseLossBackward0>)\n",
      "tensor(515.9227, grad_fn=<MseLossBackward0>)\n",
      "tensor(514.0102, grad_fn=<MseLossBackward0>)\n",
      "tensor(512.0934, grad_fn=<MseLossBackward0>)\n",
      "tensor(510.1721, grad_fn=<MseLossBackward0>)\n",
      "tensor(508.2464, grad_fn=<MseLossBackward0>)\n",
      "tensor(506.3164, grad_fn=<MseLossBackward0>)\n",
      "tensor(504.3820, grad_fn=<MseLossBackward0>)\n",
      "tensor(502.4435, grad_fn=<MseLossBackward0>)\n",
      "tensor(500.5005, grad_fn=<MseLossBackward0>)\n",
      "tensor(498.5535, grad_fn=<MseLossBackward0>)\n",
      "tensor(496.6023, grad_fn=<MseLossBackward0>)\n",
      "tensor(494.6469, grad_fn=<MseLossBackward0>)\n",
      "tensor(492.6877, grad_fn=<MseLossBackward0>)\n",
      "tensor(490.7244, grad_fn=<MseLossBackward0>)\n",
      "tensor(488.7573, grad_fn=<MseLossBackward0>)\n",
      "tensor(486.7863, grad_fn=<MseLossBackward0>)\n",
      "tensor(484.8114, grad_fn=<MseLossBackward0>)\n",
      "tensor(482.8330, grad_fn=<MseLossBackward0>)\n",
      "tensor(480.8508, grad_fn=<MseLossBackward0>)\n",
      "tensor(478.8651, grad_fn=<MseLossBackward0>)\n",
      "tensor(476.8759, grad_fn=<MseLossBackward0>)\n",
      "tensor(474.8832, grad_fn=<MseLossBackward0>)\n",
      "tensor(472.8871, grad_fn=<MseLossBackward0>)\n",
      "tensor(470.8877, grad_fn=<MseLossBackward0>)\n",
      "tensor(468.8850, grad_fn=<MseLossBackward0>)\n",
      "tensor(466.8792, grad_fn=<MseLossBackward0>)\n",
      "tensor(464.8702, grad_fn=<MseLossBackward0>)\n",
      "tensor(462.8582, grad_fn=<MseLossBackward0>)\n",
      "tensor(460.8432, grad_fn=<MseLossBackward0>)\n",
      "tensor(458.8254, grad_fn=<MseLossBackward0>)\n",
      "tensor(456.8047, grad_fn=<MseLossBackward0>)\n",
      "tensor(454.7816, grad_fn=<MseLossBackward0>)\n",
      "tensor(452.7559, grad_fn=<MseLossBackward0>)\n",
      "tensor(450.7274, grad_fn=<MseLossBackward0>)\n",
      "tensor(448.6964, grad_fn=<MseLossBackward0>)\n",
      "tensor(446.6629, grad_fn=<MseLossBackward0>)\n",
      "tensor(444.6268, grad_fn=<MseLossBackward0>)\n",
      "tensor(442.5885, grad_fn=<MseLossBackward0>)\n",
      "tensor(440.5478, grad_fn=<MseLossBackward0>)\n",
      "tensor(438.5054, grad_fn=<MseLossBackward0>)\n",
      "tensor(436.4609, grad_fn=<MseLossBackward0>)\n",
      "tensor(434.4144, grad_fn=<MseLossBackward0>)\n",
      "tensor(432.3659, grad_fn=<MseLossBackward0>)\n",
      "tensor(430.3156, grad_fn=<MseLossBackward0>)\n",
      "tensor(428.2633, grad_fn=<MseLossBackward0>)\n",
      "tensor(426.2094, grad_fn=<MseLossBackward0>)\n",
      "tensor(424.1538, grad_fn=<MseLossBackward0>)\n",
      "tensor(422.0967, grad_fn=<MseLossBackward0>)\n",
      "tensor(420.0385, grad_fn=<MseLossBackward0>)\n",
      "tensor(417.9789, grad_fn=<MseLossBackward0>)\n",
      "tensor(415.9179, grad_fn=<MseLossBackward0>)\n",
      "tensor(413.8556, grad_fn=<MseLossBackward0>)\n",
      "tensor(411.7923, grad_fn=<MseLossBackward0>)\n",
      "tensor(409.7278, grad_fn=<MseLossBackward0>)\n",
      "tensor(407.6624, grad_fn=<MseLossBackward0>)\n",
      "tensor(405.5961, grad_fn=<MseLossBackward0>)\n",
      "tensor(403.5289, grad_fn=<MseLossBackward0>)\n",
      "tensor(401.4614, grad_fn=<MseLossBackward0>)\n",
      "tensor(399.3932, grad_fn=<MseLossBackward0>)\n",
      "tensor(397.3244, grad_fn=<MseLossBackward0>)\n",
      "tensor(395.2550, grad_fn=<MseLossBackward0>)\n",
      "tensor(393.1852, grad_fn=<MseLossBackward0>)\n",
      "tensor(391.1153, grad_fn=<MseLossBackward0>)\n",
      "tensor(389.0452, grad_fn=<MseLossBackward0>)\n",
      "tensor(386.9750, grad_fn=<MseLossBackward0>)\n",
      "tensor(384.9047, grad_fn=<MseLossBackward0>)\n",
      "tensor(382.8346, grad_fn=<MseLossBackward0>)\n",
      "tensor(380.7645, grad_fn=<MseLossBackward0>)\n",
      "tensor(378.6947, grad_fn=<MseLossBackward0>)\n",
      "tensor(376.6252, grad_fn=<MseLossBackward0>)\n",
      "tensor(374.5561, grad_fn=<MseLossBackward0>)\n",
      "tensor(372.4876, grad_fn=<MseLossBackward0>)\n",
      "tensor(370.4196, grad_fn=<MseLossBackward0>)\n",
      "tensor(368.3523, grad_fn=<MseLossBackward0>)\n",
      "tensor(366.2857, grad_fn=<MseLossBackward0>)\n",
      "tensor(364.2201, grad_fn=<MseLossBackward0>)\n",
      "tensor(362.1555, grad_fn=<MseLossBackward0>)\n",
      "tensor(360.0918, grad_fn=<MseLossBackward0>)\n",
      "tensor(358.0292, grad_fn=<MseLossBackward0>)\n",
      "tensor(355.9679, grad_fn=<MseLossBackward0>)\n",
      "tensor(353.9079, grad_fn=<MseLossBackward0>)\n",
      "tensor(351.8492, grad_fn=<MseLossBackward0>)\n",
      "tensor(349.7921, grad_fn=<MseLossBackward0>)\n",
      "tensor(347.7365, grad_fn=<MseLossBackward0>)\n",
      "tensor(345.6826, grad_fn=<MseLossBackward0>)\n",
      "tensor(343.6304, grad_fn=<MseLossBackward0>)\n",
      "tensor(341.5801, grad_fn=<MseLossBackward0>)\n",
      "tensor(339.5317, grad_fn=<MseLossBackward0>)\n",
      "tensor(337.4854, grad_fn=<MseLossBackward0>)\n",
      "tensor(335.4411, grad_fn=<MseLossBackward0>)\n",
      "tensor(333.3991, grad_fn=<MseLossBackward0>)\n",
      "tensor(331.3593, grad_fn=<MseLossBackward0>)\n",
      "tensor(329.3220, grad_fn=<MseLossBackward0>)\n",
      "tensor(327.2870, grad_fn=<MseLossBackward0>)\n",
      "tensor(325.2548, grad_fn=<MseLossBackward0>)\n",
      "tensor(323.2251, grad_fn=<MseLossBackward0>)\n",
      "tensor(321.1982, grad_fn=<MseLossBackward0>)\n",
      "tensor(319.1741, grad_fn=<MseLossBackward0>)\n",
      "tensor(317.1530, grad_fn=<MseLossBackward0>)\n",
      "tensor(315.1349, grad_fn=<MseLossBackward0>)\n",
      "tensor(313.1198, grad_fn=<MseLossBackward0>)\n",
      "tensor(311.1080, grad_fn=<MseLossBackward0>)\n",
      "tensor(309.0995, grad_fn=<MseLossBackward0>)\n",
      "tensor(307.0944, grad_fn=<MseLossBackward0>)\n",
      "tensor(305.0929, grad_fn=<MseLossBackward0>)\n",
      "tensor(303.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(301.1003, grad_fn=<MseLossBackward0>)\n",
      "tensor(299.1096, grad_fn=<MseLossBackward0>)\n",
      "tensor(297.1227, grad_fn=<MseLossBackward0>)\n",
      "tensor(295.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(293.1609, grad_fn=<MseLossBackward0>)\n",
      "tensor(291.1862, grad_fn=<MseLossBackward0>)\n",
      "tensor(289.2155, grad_fn=<MseLossBackward0>)\n",
      "tensor(287.2490, grad_fn=<MseLossBackward0>)\n",
      "tensor(285.2869, grad_fn=<MseLossBackward0>)\n",
      "tensor(283.3293, grad_fn=<MseLossBackward0>)\n",
      "tensor(281.3763, grad_fn=<MseLossBackward0>)\n",
      "tensor(279.4279, grad_fn=<MseLossBackward0>)\n",
      "tensor(277.4841, grad_fn=<MseLossBackward0>)\n",
      "tensor(275.5452, grad_fn=<MseLossBackward0>)\n",
      "tensor(273.6112, grad_fn=<MseLossBackward0>)\n",
      "tensor(271.6822, grad_fn=<MseLossBackward0>)\n",
      "tensor(269.7581, grad_fn=<MseLossBackward0>)\n",
      "tensor(267.8392, grad_fn=<MseLossBackward0>)\n",
      "tensor(265.9256, grad_fn=<MseLossBackward0>)\n",
      "tensor(264.0173, grad_fn=<MseLossBackward0>)\n",
      "tensor(262.1143, grad_fn=<MseLossBackward0>)\n",
      "tensor(260.2169, grad_fn=<MseLossBackward0>)\n",
      "tensor(258.3250, grad_fn=<MseLossBackward0>)\n",
      "tensor(256.4387, grad_fn=<MseLossBackward0>)\n",
      "tensor(254.5581, grad_fn=<MseLossBackward0>)\n",
      "tensor(252.6834, grad_fn=<MseLossBackward0>)\n",
      "tensor(250.8145, grad_fn=<MseLossBackward0>)\n",
      "tensor(248.9516, grad_fn=<MseLossBackward0>)\n",
      "tensor(247.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(245.2440, grad_fn=<MseLossBackward0>)\n",
      "tensor(243.3995, grad_fn=<MseLossBackward0>)\n",
      "tensor(241.5612, grad_fn=<MseLossBackward0>)\n",
      "tensor(239.7293, grad_fn=<MseLossBackward0>)\n",
      "tensor(237.9038, grad_fn=<MseLossBackward0>)\n",
      "tensor(236.0848, grad_fn=<MseLossBackward0>)\n",
      "tensor(234.2724, grad_fn=<MseLossBackward0>)\n",
      "tensor(232.4667, grad_fn=<MseLossBackward0>)\n",
      "tensor(230.6680, grad_fn=<MseLossBackward0>)\n",
      "tensor(228.8763, grad_fn=<MseLossBackward0>)\n",
      "tensor(227.0914, grad_fn=<MseLossBackward0>)\n",
      "tensor(225.3136, grad_fn=<MseLossBackward0>)\n",
      "tensor(223.5428, grad_fn=<MseLossBackward0>)\n",
      "tensor(221.7791, grad_fn=<MseLossBackward0>)\n",
      "tensor(220.0226, grad_fn=<MseLossBackward0>)\n",
      "tensor(218.2733, grad_fn=<MseLossBackward0>)\n",
      "tensor(216.5313, grad_fn=<MseLossBackward0>)\n",
      "tensor(214.7966, grad_fn=<MseLossBackward0>)\n",
      "tensor(213.0693, grad_fn=<MseLossBackward0>)\n",
      "tensor(211.3494, grad_fn=<MseLossBackward0>)\n",
      "tensor(209.6370, grad_fn=<MseLossBackward0>)\n",
      "tensor(207.9323, grad_fn=<MseLossBackward0>)\n",
      "tensor(206.2351, grad_fn=<MseLossBackward0>)\n",
      "tensor(204.5456, grad_fn=<MseLossBackward0>)\n",
      "tensor(202.8638, grad_fn=<MseLossBackward0>)\n",
      "tensor(201.1902, grad_fn=<MseLossBackward0>)\n",
      "tensor(199.5246, grad_fn=<MseLossBackward0>)\n",
      "tensor(197.8670, grad_fn=<MseLossBackward0>)\n",
      "tensor(196.2173, grad_fn=<MseLossBackward0>)\n",
      "tensor(194.5756, grad_fn=<MseLossBackward0>)\n",
      "tensor(192.9421, grad_fn=<MseLossBackward0>)\n",
      "tensor(191.3167, grad_fn=<MseLossBackward0>)\n",
      "tensor(189.6995, grad_fn=<MseLossBackward0>)\n",
      "tensor(188.0906, grad_fn=<MseLossBackward0>)\n",
      "tensor(186.4901, grad_fn=<MseLossBackward0>)\n",
      "tensor(184.8979, grad_fn=<MseLossBackward0>)\n",
      "tensor(183.3141, grad_fn=<MseLossBackward0>)\n",
      "tensor(181.7387, grad_fn=<MseLossBackward0>)\n",
      "tensor(180.1722, grad_fn=<MseLossBackward0>)\n",
      "tensor(178.6153, grad_fn=<MseLossBackward0>)\n",
      "tensor(177.0670, grad_fn=<MseLossBackward0>)\n",
      "tensor(175.5274, grad_fn=<MseLossBackward0>)\n",
      "tensor(173.9965, grad_fn=<MseLossBackward0>)\n",
      "tensor(172.4743, grad_fn=<MseLossBackward0>)\n",
      "tensor(170.9611, grad_fn=<MseLossBackward0>)\n",
      "tensor(169.4566, grad_fn=<MseLossBackward0>)\n",
      "tensor(167.9611, grad_fn=<MseLossBackward0>)\n",
      "tensor(166.4746, grad_fn=<MseLossBackward0>)\n",
      "tensor(164.9970, grad_fn=<MseLossBackward0>)\n",
      "tensor(163.5285, grad_fn=<MseLossBackward0>)\n",
      "tensor(162.0690, grad_fn=<MseLossBackward0>)\n",
      "tensor(160.6186, grad_fn=<MseLossBackward0>)\n",
      "tensor(159.1785, grad_fn=<MseLossBackward0>)\n",
      "tensor(157.7474, grad_fn=<MseLossBackward0>)\n",
      "tensor(156.3252, grad_fn=<MseLossBackward0>)\n",
      "tensor(154.9121, grad_fn=<MseLossBackward0>)\n",
      "tensor(153.5082, grad_fn=<MseLossBackward0>)\n",
      "tensor(152.1135, grad_fn=<MseLossBackward0>)\n",
      "tensor(150.7281, grad_fn=<MseLossBackward0>)\n",
      "tensor(149.3521, grad_fn=<MseLossBackward0>)\n",
      "tensor(147.9865, grad_fn=<MseLossBackward0>)\n",
      "tensor(146.6305, grad_fn=<MseLossBackward0>)\n",
      "tensor(145.2838, grad_fn=<MseLossBackward0>)\n",
      "tensor(143.9465, grad_fn=<MseLossBackward0>)\n",
      "tensor(142.6186, grad_fn=<MseLossBackward0>)\n",
      "tensor(141.3001, grad_fn=<MseLossBackward0>)\n",
      "tensor(139.9911, grad_fn=<MseLossBackward0>)\n",
      "tensor(138.6919, grad_fn=<MseLossBackward0>)\n",
      "tensor(137.4028, grad_fn=<MseLossBackward0>)\n",
      "tensor(136.1232, grad_fn=<MseLossBackward0>)\n",
      "tensor(134.8532, grad_fn=<MseLossBackward0>)\n",
      "tensor(133.5929, grad_fn=<MseLossBackward0>)\n",
      "tensor(132.3423, grad_fn=<MseLossBackward0>)\n",
      "tensor(131.1013, grad_fn=<MseLossBackward0>)\n",
      "tensor(129.8701, grad_fn=<MseLossBackward0>)\n",
      "tensor(128.6486, grad_fn=<MseLossBackward0>)\n",
      "tensor(127.4368, grad_fn=<MseLossBackward0>)\n",
      "tensor(126.2347, grad_fn=<MseLossBackward0>)\n",
      "tensor(125.0424, grad_fn=<MseLossBackward0>)\n",
      "tensor(123.8599, grad_fn=<MseLossBackward0>)\n",
      "tensor(122.6871, grad_fn=<MseLossBackward0>)\n",
      "tensor(121.5241, grad_fn=<MseLossBackward0>)\n",
      "tensor(120.3706, grad_fn=<MseLossBackward0>)\n",
      "tensor(119.2269, grad_fn=<MseLossBackward0>)\n",
      "tensor(118.0929, grad_fn=<MseLossBackward0>)\n",
      "tensor(116.9686, grad_fn=<MseLossBackward0>)\n",
      "tensor(115.8540, grad_fn=<MseLossBackward0>)\n",
      "tensor(114.7492, grad_fn=<MseLossBackward0>)\n",
      "tensor(113.6539, grad_fn=<MseLossBackward0>)\n",
      "tensor(112.5684, grad_fn=<MseLossBackward0>)\n",
      "tensor(111.4925, grad_fn=<MseLossBackward0>)\n",
      "tensor(110.4262, grad_fn=<MseLossBackward0>)\n",
      "tensor(109.3689, grad_fn=<MseLossBackward0>)\n",
      "tensor(108.3206, grad_fn=<MseLossBackward0>)\n",
      "tensor(107.2821, grad_fn=<MseLossBackward0>)\n",
      "tensor(106.2530, grad_fn=<MseLossBackward0>)\n",
      "tensor(105.2333, grad_fn=<MseLossBackward0>)\n",
      "tensor(104.2229, grad_fn=<MseLossBackward0>)\n",
      "tensor(103.2223, grad_fn=<MseLossBackward0>)\n",
      "tensor(102.2312, grad_fn=<MseLossBackward0>)\n",
      "tensor(101.2495, grad_fn=<MseLossBackward0>)\n",
      "tensor(100.2768, grad_fn=<MseLossBackward0>)\n",
      "tensor(99.3133, grad_fn=<MseLossBackward0>)\n",
      "tensor(98.3593, grad_fn=<MseLossBackward0>)\n",
      "tensor(97.4147, grad_fn=<MseLossBackward0>)\n",
      "tensor(96.4808, grad_fn=<MseLossBackward0>)\n",
      "tensor(95.5572, grad_fn=<MseLossBackward0>)\n",
      "tensor(94.6442, grad_fn=<MseLossBackward0>)\n",
      "tensor(93.7394, grad_fn=<MseLossBackward0>)\n",
      "tensor(92.8423, grad_fn=<MseLossBackward0>)\n",
      "tensor(91.9536, grad_fn=<MseLossBackward0>)\n",
      "tensor(91.0735, grad_fn=<MseLossBackward0>)\n",
      "tensor(90.2043, grad_fn=<MseLossBackward0>)\n",
      "tensor(89.3449, grad_fn=<MseLossBackward0>)\n",
      "tensor(88.4949, grad_fn=<MseLossBackward0>)\n",
      "tensor(87.6544, grad_fn=<MseLossBackward0>)\n",
      "tensor(86.8228, grad_fn=<MseLossBackward0>)\n",
      "tensor(85.9998, grad_fn=<MseLossBackward0>)\n",
      "tensor(85.1854, grad_fn=<MseLossBackward0>)\n",
      "tensor(84.3797, grad_fn=<MseLossBackward0>)\n",
      "tensor(83.5827, grad_fn=<MseLossBackward0>)\n",
      "tensor(82.7943, grad_fn=<MseLossBackward0>)\n",
      "tensor(82.0154, grad_fn=<MseLossBackward0>)\n",
      "tensor(81.2460, grad_fn=<MseLossBackward0>)\n",
      "tensor(80.4852, grad_fn=<MseLossBackward0>)\n",
      "tensor(79.7329, grad_fn=<MseLossBackward0>)\n",
      "tensor(78.9892, grad_fn=<MseLossBackward0>)\n",
      "tensor(78.2540, grad_fn=<MseLossBackward0>)\n",
      "tensor(77.5272, grad_fn=<MseLossBackward0>)\n",
      "tensor(76.8096, grad_fn=<MseLossBackward0>)\n",
      "tensor(76.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(75.3984, grad_fn=<MseLossBackward0>)\n",
      "tensor(74.7061, grad_fn=<MseLossBackward0>)\n",
      "tensor(74.0220, grad_fn=<MseLossBackward0>)\n",
      "tensor(73.3460, grad_fn=<MseLossBackward0>)\n",
      "tensor(72.6782, grad_fn=<MseLossBackward0>)\n",
      "tensor(72.0189, grad_fn=<MseLossBackward0>)\n",
      "tensor(71.3680, grad_fn=<MseLossBackward0>)\n",
      "tensor(70.7247, grad_fn=<MseLossBackward0>)\n",
      "tensor(70.0899, grad_fn=<MseLossBackward0>)\n",
      "tensor(69.4633, grad_fn=<MseLossBackward0>)\n",
      "tensor(68.8439, grad_fn=<MseLossBackward0>)\n",
      "tensor(68.2334, grad_fn=<MseLossBackward0>)\n",
      "tensor(67.6311, grad_fn=<MseLossBackward0>)\n",
      "tensor(67.0351, grad_fn=<MseLossBackward0>)\n",
      "tensor(66.4474, grad_fn=<MseLossBackward0>)\n",
      "tensor(65.8685, grad_fn=<MseLossBackward0>)\n",
      "tensor(65.2965, grad_fn=<MseLossBackward0>)\n",
      "tensor(64.7315, grad_fn=<MseLossBackward0>)\n",
      "tensor(64.1747, grad_fn=<MseLossBackward0>)\n",
      "tensor(63.6257, grad_fn=<MseLossBackward0>)\n",
      "tensor(63.0835, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.5490, grad_fn=<MseLossBackward0>)\n",
      "tensor(62.0220, grad_fn=<MseLossBackward0>)\n",
      "tensor(61.5021, grad_fn=<MseLossBackward0>)\n",
      "tensor(60.9894, grad_fn=<MseLossBackward0>)\n",
      "tensor(60.4838, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.9855, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.4940, grad_fn=<MseLossBackward0>)\n",
      "tensor(59.0094, grad_fn=<MseLossBackward0>)\n",
      "tensor(58.5319, grad_fn=<MseLossBackward0>)\n",
      "tensor(58.0613, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.5974, grad_fn=<MseLossBackward0>)\n",
      "tensor(57.1400, grad_fn=<MseLossBackward0>)\n",
      "tensor(56.6899, grad_fn=<MseLossBackward0>)\n",
      "tensor(56.2458, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.8083, grad_fn=<MseLossBackward0>)\n",
      "tensor(55.3779, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.9528, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.5351, grad_fn=<MseLossBackward0>)\n",
      "tensor(54.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.7173, grad_fn=<MseLossBackward0>)\n",
      "tensor(53.3179, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.9249, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.5374, grad_fn=<MseLossBackward0>)\n",
      "tensor(52.1554, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.7798, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.4109, grad_fn=<MseLossBackward0>)\n",
      "tensor(51.0463, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.6877, grad_fn=<MseLossBackward0>)\n",
      "tensor(50.3352, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.9882, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.6467, grad_fn=<MseLossBackward0>)\n",
      "tensor(49.3105, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.9798, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.6549, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.3345, grad_fn=<MseLossBackward0>)\n",
      "tensor(48.0195, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.7097, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.4048, grad_fn=<MseLossBackward0>)\n",
      "tensor(47.1047, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.8096, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.5191, grad_fn=<MseLossBackward0>)\n",
      "tensor(46.2340, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.9537, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.6776, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.4059, grad_fn=<MseLossBackward0>)\n",
      "tensor(45.1391, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.8772, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.6195, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.3657, grad_fn=<MseLossBackward0>)\n",
      "tensor(44.1166, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.8720, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.6315, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.3951, grad_fn=<MseLossBackward0>)\n",
      "tensor(43.1628, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.9345, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.7101, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.4898, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.2733, grad_fn=<MseLossBackward0>)\n",
      "tensor(42.0606, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.8517, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.6465, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.4448, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.2466, grad_fn=<MseLossBackward0>)\n",
      "tensor(41.0518, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.8603, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.6721, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.4870, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.3049, grad_fn=<MseLossBackward0>)\n",
      "tensor(40.1265, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.9527, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.7815, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.6126, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.4466, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.2841, grad_fn=<MseLossBackward0>)\n",
      "tensor(39.1252, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.9689, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.8150, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.6641, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.5170, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.3727, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.2311, grad_fn=<MseLossBackward0>)\n",
      "tensor(38.0920, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.9556, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.8219, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.6908, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.5622, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.4360, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.3122, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.1908, grad_fn=<MseLossBackward0>)\n",
      "tensor(37.0717, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.9548, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.8401, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.7275, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.6169, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.5083, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.4015, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.2968, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.1939, grad_fn=<MseLossBackward0>)\n",
      "tensor(36.0927, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.9932, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.8953, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7990, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.7043, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.6108, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.5187, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.4280, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.3389, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.2527, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.1678, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0843, grad_fn=<MseLossBackward0>)\n",
      "tensor(35.0021, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.9213, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.8417, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.7634, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6863, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.6104, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.5385, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.4670, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3951, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.3234, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.2543, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1878, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.1224, grad_fn=<MseLossBackward0>)\n",
      "tensor(34.0578, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9940, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.9310, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8686, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.8088, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.7506, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6931, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.6362, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5801, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.5249, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4708, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.4196, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.3685, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.3173, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.2668, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.2184, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.1707, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.1239, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.0779, grad_fn=<MseLossBackward0>)\n",
      "tensor(33.0327, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.9883, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.9448, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.9019, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.8601, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.8191, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.7788, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.7393, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.7004, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.6622, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.6246, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.5875, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.5509, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.5157, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.4810, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.4460, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.4129, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.3803, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.3480, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.3159, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.2840, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.2526, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.2227, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.1928, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.1630, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.1351, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.1071, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.0789, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.0508, grad_fn=<MseLossBackward0>)\n",
      "tensor(32.0241, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9977, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9715, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9456, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.9209, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.8959, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.8711, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.8472, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.8236, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.8002, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.7771, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.7544, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.7320, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.7100, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6882, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6668, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6459, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6250, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.6045, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5842, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5643, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5446, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5252, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.5060, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4870, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4682, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4497, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4314, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.4133, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3954, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3777, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3602, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3428, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3256, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.3086, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2917, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2749, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2583, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2418, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2254, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.2091, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1929, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1767, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1607, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1448, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1290, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1161, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0695, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0553, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0410, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0268, grad_fn=<MseLossBackward0>)\n",
      "tensor(31.0125, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9981, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9837, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9692, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9546, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9408, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9271, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9137, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.9008, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8877, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8744, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8610, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8473, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8352, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8223, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.8089, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7967, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7843, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7716, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7585, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7483, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7361, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7223, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7113, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.7005, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6891, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6772, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6649, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6522, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6397, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6290, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6169, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.6058, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5950, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5837, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5718, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5608, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5501, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5382, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5280, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5177, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.5066, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4950, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4843, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4741, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4630, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4518, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4416, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4306, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4208, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.4106, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3996, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3892, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3793, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3685, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3583, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3484, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3379, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3277, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3178, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.3071, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2982, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2887, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2786, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2679, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2577, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2484, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2380, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2283, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2189, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.2090, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1989, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1907, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1818, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1719, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1622, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1536, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1445, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1350, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1260, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1172, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.1078, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0990, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0899, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0819, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0730, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0636, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0550, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0462, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0375, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0288, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0205, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0123, grad_fn=<MseLossBackward0>)\n",
      "tensor(30.0040, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9955, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9875, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9791, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9709, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9630, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9548, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9464, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9379, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9297, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9137, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.9057, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8975, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8901, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8817, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8739, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8663, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8584, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8504, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8421, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8340, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8261, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8185, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8109, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.8030, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7950, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7869, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7799, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7721, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7635, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7560, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7483, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7405, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7326, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7249, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7171, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7093, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.7017, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6940, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6862, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6783, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6712, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6632, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6553, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6479, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6404, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6326, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6248, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6168, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6091, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.6013, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5939, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5865, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5790, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5713, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5635, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5556, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5482, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5405, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5330, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5257, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5183, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5107, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.5030, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4953, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4876, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4800, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4726, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4653, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4580, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4506, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4431, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4355, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4279, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4214, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4138, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.4058, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3987, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3915, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3841, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3767, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3692, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3616, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3551, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3476, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3398, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3328, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3256, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3184, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3111, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.3037, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2962, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2895, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2821, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2748, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2682, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2617, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2550, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2483, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2415, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2347, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2279, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2224, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2158, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2083, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.2021, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1957, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1893, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1828, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1763, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1697, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1639, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1571, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1505, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1443, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1380, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1317, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1252, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1187, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1121, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.1058, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0996, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0948, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0888, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0819, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0762, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0705, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0647, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0589, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0471, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0416, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0356, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0299, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0242, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0188, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0130, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0075, grad_fn=<MseLossBackward0>)\n",
      "tensor(29.0019, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9962, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9905, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9848, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9797, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9736, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9683, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9631, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9577, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9523, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9467, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9412, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9356, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9299, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9242, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9185, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9128, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9085, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.9030, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8964, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8912, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8858, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8804, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8750, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8696, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8641, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8585, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8533, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8477, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8423, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8369, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8315, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8265, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8209, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8156, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8103, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.8050, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7996, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7942, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7890, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7836, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7783, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7730, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7677, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7623, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7571, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7518, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7466, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7413, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7360, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7307, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7254, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7202, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7149, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7097, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.7045, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6993, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6940, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6887, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6841, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6783, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6732, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6680, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6629, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6576, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6528, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6474, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6423, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6372, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6321, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6270, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6218, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6166, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6121, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6064, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.6016, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5967, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5918, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5869, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5819, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5769, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5718, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5667, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5616, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5564, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5513, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5461, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5409, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5367, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5316, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5260, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5212, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5164, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5115, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5066, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.5016, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4966, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4916, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4866, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4816, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4766, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4726, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4673, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4621, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4574, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4527, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4479, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4431, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4383, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4334, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4285, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4236, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4187, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4137, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4088, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.4044, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3993, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3946, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3900, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3854, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3807, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3760, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3713, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3665, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3617, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3569, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3521, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3473, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3424, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3378, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3330, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3283, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3236, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3190, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3144, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3099, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3053, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.3007, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2961, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2915, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2868, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2821, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2775, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2728, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2683, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2637, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2592, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2546, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2454, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2412, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2364, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2320, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2275, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2230, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2185, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2139, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2094, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2051, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.2005, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1961, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1917, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1872, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1828, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1783, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1738, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1695, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1650, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1606, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1563, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1519, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1475, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1431, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1386, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1345, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1299, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1256, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1213, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1170, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1083, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.1039, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0999, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0952, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0908, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0864, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0820, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0775, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0730, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0685, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0644, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0597, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0553, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0509, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0465, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0420, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0376, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0331, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0290, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0243, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0199, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0156, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0112, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0068, grad_fn=<MseLossBackward0>)\n",
      "tensor(28.0024, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9979, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9938, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9892, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9849, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9806, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9762, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9719, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9675, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9631, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9590, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9545, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9502, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9460, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9417, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9374, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9330, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9287, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9246, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9202, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9160, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9118, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9075, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.9033, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8990, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8948, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8907, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8864, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8823, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8782, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8740, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8698, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8657, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8615, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8574, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8532, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8492, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8451, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8410, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8369, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8328, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8286, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8246, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8205, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8165, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8085, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8044, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.8004, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7963, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7922, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7883, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7843, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7804, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7764, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7724, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7684, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7644, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7604, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7569, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7525, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7486, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7447, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7407, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7368, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7329, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7292, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7251, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7213, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7174, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7136, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7097, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7058, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.7019, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6980, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6942, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6903, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6866, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6828, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6790, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6751, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6713, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6675, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6638, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6599, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6562, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6525, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6487, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6449, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6412, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6374, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6336, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6303, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6262, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6225, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6188, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6151, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6114, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6077, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6040, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.6004, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5968, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5932, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5895, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5859, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5822, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5786, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5749, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5712, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5678, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5640, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5604, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5568, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5532, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5496, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5460, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5425, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5389, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5355, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5320, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5284, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5249, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5213, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5178, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5142, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5107, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5074, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5036, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.5002, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4967, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4933, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4898, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4863, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4828, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4797, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4759, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4725, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4691, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4657, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4623, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4589, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4554, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4520, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4489, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4452, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4419, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4386, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4352, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4318, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4285, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4251, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4217, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4188, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4150, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4117, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4085, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4052, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.4018, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3985, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3952, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3919, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3887, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3855, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3822, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3790, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3757, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3725, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3692, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3659, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3626, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3597, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3562, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3530, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3498, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3466, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3434, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3402, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3370, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3340, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3307, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3276, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3245, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3213, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3182, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3150, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3119, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3087, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3055, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.3027, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2993, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2962, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2932, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2901, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2870, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2839, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2808, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2778, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2747, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2717, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2687, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2657, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2626, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2596, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2565, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2535, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2504, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2475, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2444, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2414, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2385, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2355, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2325, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2295, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2265, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2235, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2208, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2176, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2147, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2118, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2089, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2060, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2030, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.2001, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1972, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1943, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1914, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1885, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1857, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1828, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1799, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1771, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1742, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1713, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1684, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1657, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1627, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1599, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1571, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1543, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1515, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1486, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1458, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1430, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1403, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1374, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1347, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1319, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1291, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1264, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1236, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1208, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1180, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1152, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1127, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1098, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1071, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1044, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.1017, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0990, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0962, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0935, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0908, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0880, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0858, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0827, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0800, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0774, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0748, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0721, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0694, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0667, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0641, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0615, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0588, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0562, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0537, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0511, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0484, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0458, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0432, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0406, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0379, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0353, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0331, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0302, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0276, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0251, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0225, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0200, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0174, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0148, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0123, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0099, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0072, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0047, grad_fn=<MseLossBackward0>)\n",
      "tensor(27.0023, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9998, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9973, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9947, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9922, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9897, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9872, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9846, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9825, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9797, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9773, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9748, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9724, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9699, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9675, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9650, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9625, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9601, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9577, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9553, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9529, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9505, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9481, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9457, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9433, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9409, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9384, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9360, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9337, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9312, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9289, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9266, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9242, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9219, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9195, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9171, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9148, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9124, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9102, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9077, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9055, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9032, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.9009, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8986, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8962, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8939, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8916, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8893, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8869, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8850, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8824, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8802, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8779, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8757, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8734, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8711, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8689, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8666, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8643, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8623, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8599, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8577, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8555, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8533, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8511, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8489, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8467, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8444, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8422, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8400, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8379, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8356, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8335, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8313, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8292, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8270, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8248, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8227, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8205, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8183, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8161, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8143, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8119, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8098, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8077, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8056, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8034, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.8013, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7992, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7971, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7949, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7928, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7908, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7887, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7867, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7846, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7825, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7805, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7784, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7763, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7742, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7721, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7700, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7682, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7659, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7639, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7619, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7599, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7579, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7558, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7538, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7518, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7497, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7477, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7458, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7438, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7418, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7399, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7379, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7359, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7339, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7319, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7299, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7279, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7259, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7241, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7220, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7201, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7182, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7162, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7143, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7124, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7104, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7085, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7065, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7046, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7028, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.7008, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6989, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6970, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6951, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6932, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6913, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6894, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6856, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6837, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6818, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6802, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6781, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6763, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6744, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6726, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6707, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6689, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6670, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6652, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6633, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6614, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6596, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6578, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6560, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6542, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6524, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6506, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6488, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6470, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6452, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6434, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6415, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6397, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6379, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6361, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6344, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6326, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6309, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6291, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6273, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6256, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6238, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6220, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6202, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6185, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6168, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6150, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6133, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6116, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6098, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6081, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6064, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6047, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6029, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.6012, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5995, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5977, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5961, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5943, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5926, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5910, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5893, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5876, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5859, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5842, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5825, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5808, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5792, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5775, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5758, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5741, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5725, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5709, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5692, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5676, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5659, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5643, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5626, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5610, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5593, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5576, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5560, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5546, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5528, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5512, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5496, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5480, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5464, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5448, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5431, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5415, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5399, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5383, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5367, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5351, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5335, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5320, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5304, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5288, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5273, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5257, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5241, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5226, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5210, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5194, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5178, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5162, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5147, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5131, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5116, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5101, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5086, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5070, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5055, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5040, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5024, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.5009, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4993, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4978, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4962, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4949, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4932, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4917, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4903, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4888, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4873, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4858, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4843, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4828, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4813, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4797, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4782, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4767, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4754, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4738, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4723, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4709, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4694, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4680, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4665, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4650, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4636, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4621, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4606, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4592, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4577, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4562, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4548, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4534, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4520, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4506, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4491, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4477, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4463, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4448, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4434, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4419, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4405, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4391, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4376, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4365, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4348, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4334, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4321, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4307, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4293, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4279, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4265, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4251, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4237, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4223, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4209, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4195, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4181, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4167, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4154, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4140, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4127, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4113, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4100, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4086, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4072, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4058, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4045, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4031, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4017, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.4004, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3991, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3977, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3964, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3950, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3937, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3924, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3911, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3897, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3884, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3870, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3857, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3843, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3829, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3815, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3803, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3787, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3774, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3760, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3747, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3733, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3719, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3706, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3692, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3678, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3664, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3650, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3636, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3622, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3609, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3595, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3581, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3568, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3555, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3541, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3527, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3514, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3500, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3487, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3473, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3459, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3445, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3432, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3419, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3405, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3392, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3379, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3365, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3352, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3339, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3326, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3312, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3299, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3285, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3272, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3258, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3245, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3232, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3219, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3206, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3193, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3180, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3167, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3154, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3141, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3128, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3115, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3102, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3089, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3075, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3062, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3049, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3037, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3024, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.3011, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2999, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2986, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2973, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2960, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2948, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2935, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2922, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2909, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2896, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2883, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2870, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2860, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2845, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2833, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2821, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2808, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2796, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2783, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2771, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2758, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2746, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2733, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2720, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2708, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2695, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2683, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2671, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2659, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2647, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2634, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2622, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2610, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2598, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2586, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2573, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2561, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2549, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2536, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2524, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2512, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2500, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2487, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2476, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2464, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2452, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2440, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2428, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2416, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2404, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2392, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2380, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2368, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2356, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2344, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2331, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2321, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2308, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2296, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2285, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2273, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2261, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2250, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2238, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2226, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2214, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2202, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2191, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2179, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2167, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2155, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2144, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2132, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2121, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2109, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2098, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2086, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2075, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2063, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2052, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2040, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2029, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2017, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.2006, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1994, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1982, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1971, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1962, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1948, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1937, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1926, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1915, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1903, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1892, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1881, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1870, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1858, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1847, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1836, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1824, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1813, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1802, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1791, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1779, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1768, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1758, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1747, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1736, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1725, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1714, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1702, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1691, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1680, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1669, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1658, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1647, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1636, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1624, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1614, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1603, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1592, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1581, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1570, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1560, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1549, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1538, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1527, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1516, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1505, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1494, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1483, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1473, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1462, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1451, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1441, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1429, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1419, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1408, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1398, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1387, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1377, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1366, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1355, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1345, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1334, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1323, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1313, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1302, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1291, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1280, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1270, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1261, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1249, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1238, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1228, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1218, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1207, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1197, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1187, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1176, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1166, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1155, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1145, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1134, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1124, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1113, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1103, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1092, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1084, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1072, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1061, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1051, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1041, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1031, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1021, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1011, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.1000, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0990, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0980, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0969, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0959, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0949, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0938, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0928, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0918, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0909, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0898, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0888, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0878, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0868, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0858, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0848, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0838, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0828, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0818, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0808, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0798, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0787, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0777, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0767, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0757, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0747, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0737, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0727, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0717, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0708, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0698, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0688, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0678, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0668, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0658, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0649, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0639, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0629, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0619, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0609, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0599, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0589, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0579, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0569, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0561, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0550, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0540, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0530, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0521, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0511, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0501, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0492, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0482, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0472, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0463, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0453, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0443, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0433, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0423, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0414, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0404, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0394, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0386, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0375, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0366, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0356, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0347, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0338, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0328, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0318, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0309, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0299, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0290, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0280, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0271, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0261, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0251, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0242, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0233, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0224, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0216, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0208, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0200, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0193, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0186, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0179, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0171, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0164, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0157, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0150, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0143, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0136, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0129, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0122, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0115, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0108, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0101, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0094, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0087, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0080, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0074, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0067, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0060, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0054, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0047, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0041, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0034, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0028, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0021, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0014, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0008, grad_fn=<MseLossBackward0>)\n",
      "tensor(26.0001, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9994, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9988, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9981, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9974, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9968, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9961, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9955, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9948, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9942, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9937, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9929, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9922, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9916, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9910, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9904, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9897, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9891, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9885, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9878, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9872, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9865, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9859, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9852, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9846, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9840, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9833, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9827, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9820, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9814, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9808, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9801, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9795, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9788, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9784, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9776, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9770, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9764, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9758, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9752, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9745, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9739, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9733, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9727, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9721, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9714, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9708, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9702, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9696, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9689, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9683, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9677, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9671, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9664, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9658, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9652, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9646, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9640, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9633, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9628, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9621, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9615, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9609, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9603, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9598, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9592, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9586, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9580, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9573, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9568, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9561, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9555, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9549, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9543, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9537, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9531, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9525, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9519, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9513, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9507, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9501, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9495, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9489, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9483, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9477, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9471, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9465, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9459, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9453, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9447, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9442, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9436, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9430, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9424, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9418, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9412, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9407, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9401, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9395, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9389, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9382, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9376, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9369, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9363, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9356, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9349, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9343, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9336, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9329, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9322, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9316, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9309, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9302, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9296, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9288, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9281, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9275, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9268, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9261, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9255, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9248, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9241, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9234, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9227, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9220, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9213, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9206, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9200, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9193, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9186, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9179, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9172, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9165, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9158, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9151, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9144, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9137, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9130, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9123, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9117, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9110, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9103, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9097, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9090, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9083, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9077, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9070, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9063, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9056, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9050, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9043, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9036, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9029, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9023, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9016, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9009, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.9002, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8995, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8989, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8982, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8975, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8968, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8962, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8955, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8950, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8942, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8935, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8929, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8922, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8916, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8909, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8903, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8896, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8890, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8883, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8877, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8870, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8863, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8857, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8850, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8843, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8837, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8830, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8824, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8817, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8811, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8804, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8797, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8791, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8785, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8778, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8772, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8766, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8759, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8753, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8746, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8740, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8734, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8727, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8721, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8714, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8708, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8701, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8695, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8688, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8682, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8676, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8669, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8663, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8656, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8650, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8643, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8637, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8632, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8625, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8618, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8612, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8606, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8600, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8594, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8587, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8581, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8575, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8569, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8562, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8556, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8550, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8543, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8537, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8531, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8524, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8518, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8512, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8506, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8499, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8493, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8487, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8481, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8474, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8469, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8462, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8456, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8450, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8444, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8438, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8432, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8426, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8420, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8414, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8408, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8401, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8395, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8389, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8383, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8377, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8371, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8364, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8358, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8352, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8346, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8340, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8334, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8328, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8322, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8316, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8309, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8304, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8297, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8292, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8286, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8280, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8274, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8268, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8262, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8256, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8250, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8244, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8238, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8232, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8226, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8220, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8214, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8208, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8202, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8196, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8190, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8184, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8178, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8172, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8166, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8160, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8154, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8148, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8142, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8137, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8131, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8125, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8119, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8113, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8108, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8102, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8096, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8090, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8085, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8079, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8073, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8067, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8061, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8055, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8049, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8043, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8038, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8032, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8026, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8020, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8014, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8008, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.8002, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7997, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7991, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7985, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7979, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7974, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7968, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7962, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7956, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7951, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7945, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7940, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7934, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7928, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7923, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7917, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7911, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7906, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7900, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7894, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7888, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7883, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7877, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7871, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7865, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7860, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7854, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7848, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7842, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7837, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7831, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7825, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7820, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7814, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7808, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7803, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7797, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7792, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7786, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7780, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7775, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7770, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7764, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7759, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7753, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7748, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7742, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7736, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7731, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7725, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7720, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7714, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7709, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7703, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7698, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7693, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7689, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7684, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7679, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7675, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7670, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7666, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7661, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7657, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7652, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7648, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7643, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7639, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7634, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7630, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7626, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7621, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7617, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7613, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7609, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7605, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7600, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7596, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7592, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7588, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7584, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7579, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7575, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7571, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7567, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7562, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7558, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7554, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7550, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7545, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7541, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7537, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7533, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7529, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7524, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7520, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7516, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7512, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7508, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7504, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7500, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7496, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7492, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7487, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7484, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7479, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7475, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7471, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7468, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7464, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7460, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7456, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7452, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7448, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7444, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7440, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7436, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7432, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7428, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7424, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7420, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7416, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7412, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7408, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7404, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7400, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7396, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7392, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7388, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7384, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7380, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7376, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7373, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7369, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7365, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7361, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7357, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7353, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7349, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7346, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7342, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7338, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7334, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7330, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7327, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7323, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7319, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7316, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7312, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7309, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7305, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7301, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7297, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7294, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7290, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7286, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7282, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7278, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7275, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7271, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7267, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7263, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7259, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7256, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7252, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7248, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7245, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7241, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7237, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7234, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7230, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7226, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7223, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7219, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7215, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7212, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7208, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7205, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7201, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7197, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7194, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7190, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7187, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7183, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7179, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7176, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7172, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7169, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7165, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7161, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7158, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7154, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7151, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7147, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7144, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7140, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7137, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7133, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7130, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7126, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7123, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7119, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7116, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7113, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7110, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7106, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7103, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7100, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7096, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7093, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7089, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7086, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7082, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7079, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7075, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7071, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7068, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7064, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7061, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7057, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7054, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7050, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7047, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7043, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7039, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7036, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7032, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7029, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7025, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7022, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7018, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7015, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7011, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7008, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7004, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.7001, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6997, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6994, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6990, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6987, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6983, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6980, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6976, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6973, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6969, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6965, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6962, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6958, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6955, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6951, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6948, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6944, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6941, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6937, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6934, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6930, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6927, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6923, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6920, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6916, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6913, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6909, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6906, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6902, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6899, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6896, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6892, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6889, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6885, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6882, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6878, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6875, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6871, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6868, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6865, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6861, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6858, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6854, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6851, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6848, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6844, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6841, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6837, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6834, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6831, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6827, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6824, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6821, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6817, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6814, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6811, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6807, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6804, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6801, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6797, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6794, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6791, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6787, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6784, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6781, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6778, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6774, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6771, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6768, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6765, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6762, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6759, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6755, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6752, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6749, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6745, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6742, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6738, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6735, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6732, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6728, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6725, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6722, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6719, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6715, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6712, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6709, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6706, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6702, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6699, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6696, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6693, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6690, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6686, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6683, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6680, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6677, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6673, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6670, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6667, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6664, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6661, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6657, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6654, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6651, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6648, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6645, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6642, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6638, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6635, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6632, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6629, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6626, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6623, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6619, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6616, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6613, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6610, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6607, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6604, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6601, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6598, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6594, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6591, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6588, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6585, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6582, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6579, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6576, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6573, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6570, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6567, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6564, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6561, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6558, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6555, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6552, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6549, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6546, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6543, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6540, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6536, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6533, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6530, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6527, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6524, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6521, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6518, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6515, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6512, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6509, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6505, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6502, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6499, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6496, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6493, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6490, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6487, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6484, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6481, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6478, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6475, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6472, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6469, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6466, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6463, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6460, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6457, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6454, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6451, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6448, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6445, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6442, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6439, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6436, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6433, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6431, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6428, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6425, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6422, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6419, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6416, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6413, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6410, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6407, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6404, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6401, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6398, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6395, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6392, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6389, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6386, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6383, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6380, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6378, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6375, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6372, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6369, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6366, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6363, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6360, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6357, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6354, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6351, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6348, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6346, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6343, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6340, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6337, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6334, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6331, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6328, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6326, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6323, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6320, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6318, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6315, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6312, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6309, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6306, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6303, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6301, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6298, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6295, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6292, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6289, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6286, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6283, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6280, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6277, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6275, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6272, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6270, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6268, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6266, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6264, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6261, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6259, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6257, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6255, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6253, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6251, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6249, grad_fn=<MseLossBackward0>)\n",
      "tensor(25.6247, grad_fn=<MseLossBackward0>)\n"
     ]
    }
   ],
   "source": [
    "import torch.optim as optim  # 최적화함수\n",
    "\n",
    "criterion = nn.MSELoss()  # 회기니까 여기서는 MSE Loss를 써야한다(평균오차제곱)\n",
    "optimizer = optim.Adam(model.parameters(),lr=0.001) # learning late = 얼마나가는지\n",
    "                                             #1e-3\n",
    "# 학습을 30번 시킨다\n",
    "epochs = 3000\n",
    "\n",
    "loss_list = []\n",
    "\n",
    "\n",
    "for epoch in range(epochs):\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    pred = model(X)\n",
    "    loss = criterion(pred,y)\n",
    "    print(loss)\n",
    "    loss_list.append(loss.item())\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "    \n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "06a9aec3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.plot(range(epochs),loss_list)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab1cbac",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fe02d66b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwdeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "854d626b",
   "metadata": {},
   "source": [
    "# [1단계] 딥러닝 준비물 챙기기 (Import)\n",
    "가장 먼저 딥러닝을 하기 위해 필요한 파이썬의 '도구 상자(라이브러리)'들을 꺼내오는 과정입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "faed07bd",
   "metadata": {},
   "outputs": [],
   "source": [
    "# torch: '파이토치'라는 딥러닝 핵심 도구 상자 전체를 불러옵니다.\n",
    "import torch\n",
    "\n",
    "# torch.nn: 인공신경망(Neural Network)을 만들 때 쓰는 부품들(기억력이 있는 층)을 'nn'이라고 짧게 부릅니다.\n",
    "import torch.nn as nn\n",
    "\n",
    "# torch.nn.functional: 활성화 함수 등 계산만 하는 순수 함수들을 'F'라고 짧게 부릅니다.\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# Adam: 모델이 틀린 문제를 복습해서 똑똑해지게 만들어주는 '최적화 도구(학생의 과외선생님)' 중 하나입니다.\n",
    "from torch.optim import Adam\n",
    "\n",
    "# datasets: 파이토치에서 기본으로 제공하는 유명한 데이터(예: MNIST 숫자 이미지)들을 다운받는 도구입니다.\n",
    "from torchvision import datasets\n",
    "\n",
    "# transforms: 이미지를 로봇이 먹기 좋게 자르고, 색깔을 바꾸는 등 '전처리(요리)'를 해주는 도구입니다.\n",
    "from torchvision.transforms import transforms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "d0aa2f36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 연속해서 이미지를 전처리해주는 함수 Compose\n",
    "\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "    ]\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "998b108f",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = datasets.MNIST(root='./',train=True,download=True,transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "785b5859",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 60000\n",
       "    Root location: ./\n",
       "    Split: Train\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "           )"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "54d2c8e2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "2e3dc4a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([60000, 28, 28])"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "68fd1da5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transforms.Compose: 여러 개의 변환 작업(요리법)을 묶어서 하나의 세트로 만들어줍니다.\n",
    "data_transform = transforms.Compose(\n",
    "    [\n",
    "        # ToTensor(): 사람이 보는 이미지를 파이토치가 계산할 수 있는 숫자 행렬(텐서)로 바꾸고, \n",
    "        # 0~255이던 픽셀 값을 0.0~1.0 사이로 작게 줄여줍니다.\n",
    "        transforms.ToTensor(),\n",
    "\n",
    "        # Resize(32): 원래 28x28 크기인 MNIST 이미지를 LeNet 로봇이 좋아하는 32x32 크기로 늘립니다.\n",
    "        transforms.Resize(32),\n",
    "\n",
    "        # Normalize: 이미지의 평균과 표준편차를 맞춰서 데이터가 한쪽으로 치우치지 않게(정규화) 예쁘게 다듬어 줍니다.\n",
    "        transforms.Normalize((0.5),(1.0))   # 평균 0.5 = 전체 이미지의 색상값을 다더해서 평균내서 0.5 . 간이정규화\n",
    "    ]\n",
    ")\n",
    "# 학습용(Train) 데이터 다운로드: train=True면 모의고사용 문제집을 가져옵니다.\n",
    "train_data = datasets.MNIST(root='./',train=True,download=True,transform=data_transform)\n",
    "# 테스트용(Test) 데이터 다운로드: train=False면 수능(실전)용 문제집을 가져옵니다.\n",
    "test_data = datasets.MNIST(root='./', train=False, download=True,transform=data_transform)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "067bd5d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset MNIST\n",
       "    Number of datapoints: 10000\n",
       "    Root location: ./\n",
       "    Split: Test\n",
       "    StandardTransform\n",
       "Transform: Compose(\n",
       "               ToTensor()\n",
       "               Resize(size=32, interpolation=bilinear, max_size=None, antialias=True)\n",
       "               Normalize(mean=0.5, std=1.0)\n",
       "           )"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "ae9f3250",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        ...,\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]],\n",
       "\n",
       "        [[0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         ...,\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0],\n",
       "         [0, 0, 0,  ..., 0, 0, 0]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "88980f1e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([10000, 28, 28])"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_data.data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "52840146",
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import DataLoader\n",
    "\n",
    "# DataLoader: 데이터를 '배치(Batch)' 단위로 묶어서 로봇에게 던져주는 기계입니다.\n",
    "# batch_size=32: 한 번에 32장씩 묶어서 로봇에게 줍니다.\n",
    "# shuffle=True: 로봇이 순서를 외우지 못하게 문제집을 마구 섞어서(셔플) 줍니다.\n",
    "\n",
    "train_loader = DataLoader(train_data,batch_size=32,shuffle=True)\n",
    "test_loader = DataLoader(test_data,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "be8c083f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 1, 32, 32])"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_loader: 아까 만든 데이터 컨베이어 벨트입니다.\n",
    "# iter(): 컨베이어 벨트를 '작동 준비' 상태(반복자)로 만듭니다.\n",
    "# next(): 버튼을 눌러서 컨베이어 벨트에서 데이터를 '딱 한 묶음(32장)'만 앞으로 꺼냅니다.\n",
    "# [0]: 꺼낸 한 묶음은 [이미지들, 정답지들] 두 칸으로 나뉘어 있습니다. 그중 0번째 칸, 즉 '이미지들'만 가져옵니다.\n",
    "# .shape: 그 이미지들의 형태(크기)를 확인합니다.\n",
    "next(iter(train_loader))[0].shape\n",
    "\n",
    "# 결과: torch.Size([32, 1, 32, 32]) \n",
    "# 의미: 32장(배치 크기), 1겹(흑백), 32x32 픽셀 크기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5df77d93",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Lenet(\n",
       "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))\n",
       "  (fc1): Linear(in_features=120, out_features=84, bias=True)\n",
       "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class Lenet(nn.Module):\n",
    "\n",
    "# class: 파이썬에서 **'설계도(붕어빵 틀)'**를 만들겠다고 선언하는 명령어입니다.\n",
    "# Lenet: 우리가 지금부터 만들 설계도의 **'이름'**입니다. (얀 르쿤 교수가 만든 모델이라 LeNet입니다).\n",
    "# (nn.Module): 파이토치(PyTorch)에서 제공하는 **'인공신경망의 기본 뼈대'**입니다. 이걸 괄호 안에 넣으면,\n",
    "# \"파이토치가 이미 만들어둔 딥러닝 기본 기능들을 내가 그릴 Lenet 설계도에 그대로 물려받아서(상속받아서) 쓰겠다\"는 뜻입니다.\n",
    "\n",
    "    def __init__(self):\n",
    "    # def: 파이썬에서 **'함수(어떤 기능을 하는 동작)'**를 만들 때 쓰는 명령어입니다.\n",
    "    # __init__: 파이썬의 특수한 약속입니다. 이 설계도를 바탕으로 로봇이 처음 '태어날 때(초기화될 때)' 가장 먼저 무조건 실행되는 준비 과정을 뜻합니다.\n",
    "    # (self): **'나 자신'**을 뜻합니다. 설계도로 만들어질 '실제 로봇 그 자체'를 가리킵니다.\n",
    "        super(Lenet,self).__init__()\n",
    "        # super(): **'부모님(아까 물려받은 nn.Module)'**을 부르는 명령어입니다.\n",
    "        # 이 줄의 전체 의미: \"부모님(파이토치 기본 뼈대)의 초기 세팅(__init__)도 내 로봇에 똑같이 적용해 주세요!\"라는 뜻입니다.\n",
    "        # 이게 없으면 딥러닝 모델로 작동하지 않습니다.\n",
    "\n",
    "        self.conv1 = nn.Conv2d(in_channels=1, out_channels= 6, kernel_size=5, stride=1)\n",
    "        # self.conv1: 내 몸(self)에 conv1이라는 이름표를 붙여서 부품을 장착합니다.\n",
    "        # nn.Conv2d: 2차원(가로x세로) 이미지를 훑어보며 특징을 찾는 '첫 번째 돋보기' 부품입니다.\n",
    "        # in_channels=1: 들어오는 이미지의 색상 겹이 1개(흑백)라는 뜻입니다.\n",
    "        # out_channels=6: 돋보기로 이미지를 훑어서 **총 6가지의 특징(선, 곡선 등)**을 뽑아내라는 뜻입니다.\n",
    "        # kernel_size=5: 돋보기 유리의 크기를 5x5 픽셀 정사각형으로 하겠다는 뜻입니다.\n",
    "        # stride=1: 돋보기를 옆으로 이동할 때 1칸씩 촘촘하게 이동하라는 뜻입니다.\n",
    "\n",
    "        self.conv2 = nn.Conv2d(in_channels=6, out_channels=16, kernel_size=5, stride=1)\n",
    "        # self.conv2: 두 번째 돋보기 부품입니다.\n",
    "        # in_channels=6: 앞서 conv1에서 6개의 특징을 뽑아냈으니, 여기서는 그 6개를 입력으로 받아들입니다.\n",
    "        # out_channels=16: 그 6개를 조합해서 더 복잡한 특징 16가지를 새롭게 뽑아냅니다.\n",
    "        # 크기와 보폭은 conv1과 같습니다.\n",
    "\n",
    "        self.conv3 = nn.Conv2d(in_channels=16, out_channels=120, kernel_size=5, stride=1)\n",
    "        # self.conv3: 세 번째 돋보기 부품입니다.\n",
    "        # in_channels=16: conv2에서 나온 16개를 입력으로 받습니다.\n",
    "        # out_channels=120: 최종적으로 120개의 아주 복잡한 특징을 뽑아냅니다.\n",
    "\n",
    "        self.fc1 = nn.Linear(in_features=120, out_features=84)\n",
    "        # self.fc1: fc는 Fully Connected(완전 연결)의 약자입니다. 저는 이걸 **'회의실'**이라고 부릅니다.\n",
    "        # nn.Linear: 일렬로 세워진 데이터들을 모아서 결론을 내는 부품입니다.\n",
    "        # in_features=120: conv3에서 나온 120개의 특징 데이터를 한 줄로 쫙 펴서 회의실로 들여보냅니다.\n",
    "        # out_features=84: 120개의 정보를 종합해서 84개로 압축해 결론을 냅니다.\n",
    "\n",
    "        self.fc2 = nn.Linear(in_features=84, out_features=10)\n",
    "        # self.fc2: 마지막 두 번째 회의실(최종 결론방)입니다.\n",
    "        # in_features=84: 방금 압축된 84개의 데이터를 가져옵니다.\n",
    "        # out_features=10: (매주 중요!) 우리가 맞출 숫자는 0부터 9까지 총 10개입니다.\n",
    "        # 따라서 최종 결론으로 10개의 점수(각 숫자일 확률)를 뱉어내게 만듭니다.\n",
    "\n",
    "\n",
    "    def forward(self,x):\n",
    "        # forward: 인공지능에서 데이터가 앞으로 나아간다는 뜻입니다. forward라는 함수 정의.\n",
    "        # 실제로 데이터가 들어와서 계산되는 순서를 적는 공간입니다.\n",
    "        # (self, x): 내 몸(self)에 데이터 x(이미지)가 들어왔다는 뜻입니다.\n",
    "\n",
    "        x = self.conv1(x)   # 신경망 통과\n",
    "        \n",
    "        x = F.tanh(x) # 활성화함수통과할차례\n",
    "        #F.tanh(x): 순수 계산기 F에 있는 하이퍼볼릭 탄젠트(tanh) 함수에 x를 통과시킵니다.\n",
    "        # 이유: 값을 -1에서 1 사이로 예쁘게 찌그러뜨려서, 단순한 산수가 아니라 '복잡한 곡선이나 패턴'을 인식할 수 있는 능력(비선형성)을 부여합니다.\n",
    "       \n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        # F.max_pool2d: 풀링(압축) 작업입니다.\n",
    "        # x, 2, 2: 데이터 x를 2x2 픽셀 단위로 잘라서,\n",
    "        # 그중 가장 수치가 높은(특징이 강한) 1개만 남깁니다.\n",
    "        # 결과적으로 사진의 해상도가 절반으로 확 줄어들어 컴퓨터가 계산하기 편해집니다.\n",
    "\n",
    "        x = self.conv2(x)\n",
    "        # 방금 절반으로 줄어든 x를 두 번째 돋보기(conv2)에 통과시킵니다.\n",
    "\n",
    "        x = F.max_pool2d(x,2,2)\n",
    "        # 다시 2x2 크기로 한 번 더 압축(max_pool2d)하여 사진 크기를 또 절반으로 줄입니다.\n",
    "\n",
    "        x = F.tanh(x)\n",
    "        # 그 결과를 다시 tanh 활성화 함수에 넣어 -1~1 사이로 다듬어줍니다.\n",
    "\n",
    "        x = self.conv3(x)\n",
    "        #엄청 작아진 x를 세 번째 돋보기(conv3)에 통과시킵니다.\n",
    "        # (크기가 1x1로 작아져서 더 이상 압축은 안 합니다).\n",
    "\n",
    "        x = F.tanh(x)\n",
    "        # 활성화 함수 tanh를 통과시킵니다.\n",
    "\n",
    "        x = x.view(-1,120)\n",
    "        # x.view: 데이터의 **모양을 변형(쫙 펴기)**하는 파이토치 명령어입니다.\n",
    "        # (-1, 120): -1은 '배치 크기(32장)는 컴퓨터 네가 알아서 계산해'라는 뜻이고,\n",
    "        # 120은 '뒤에 붙은 입체적인 덩어리들을 120개짜리 1차원(일렬) 줄로 쫙 펴라'는 뜻입니다.\n",
    "        # 회의실(fc1)에 넣으려면 일렬로 서야 하기 때문입니다.\n",
    "\n",
    "        x = self.fc1(x)     # F6 통과 84개로 통과\n",
    "        # 일렬로 펴진 x를 첫 번째 회의실(fc1)에 넣어 84개로 정보를 요약합니다.\n",
    "\n",
    "        x = F.tanh(x)   # 활성화함수\n",
    "        # 역시 tanh 활성화 함수를 통과시켜 뇌신경망을 자극합니다.\n",
    "\n",
    "        x = self.fc2(x)\n",
    "        # 마지막 회의실(fc2)에 통과시켜 **10개의 점수(0~9일 확률)**로 최종 결론을 냅니다.\n",
    "\n",
    "        x = F.tanh(x)\n",
    "        # 마지막으로 tanh를 통과시킵니다.\n",
    "        \n",
    "        return x\n",
    "        # return x: 이 모든 험난한 과정을 거쳐 나온 최종 결과물 x(10개의 점수)를 밖으로 **반환(배출)**합니다.\n",
    "        # 이로써 설계도가 모두 완성되었습니다!\n",
    "\n",
    "model = Lenet()\n",
    "model\n",
    "#드디어! 위에서 만든 길고 긴 Lenet 설계도를 바탕으로,\n",
    "# 메모리(컴퓨터) 상에 model이라는 이름의 '진짜 로봇'을 한 대 만들어 냅니다.\n",
    "# (이것을 객체 생성이라고 합니다.)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "63b924fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "💡 질문 3. model 출력 결과 완벽 해석하기\n",
    "설계도대로 조립된 로봇(model)의 상태를 출력했을 때 나온 결과물입니다.\n",
    "파이토치가 **\"네가 주문한 대로 로봇 조립 잘 끝났어.\n",
    "부품 명세서 확인해 봐!\"**라고 보여주는 영수증입니다.\n",
    "\n",
    "Lenet(  \n",
    "  (conv1): Conv2d(1, 6, kernel_size=(5, 5), stride=(1, 1))  \n",
    "  (conv2): Conv2d(6, 16, kernel_size=(5, 5), stride=(1, 1))  \n",
    "  (conv3): Conv2d(16, 120, kernel_size=(5, 5), stride=(1, 1))  \n",
    "  (fc1): Linear(in_features=120, out_features=84, bias=True)  \n",
    "  (fc2): Linear(in_features=84, out_features=10, bias=True)\n",
    ")\n",
    "\n",
    "[해석 및 차이점 분석]\n",
    "Lenet(...): 네가 만든 'Lenet'이라는 이름의 모델 껍데기야.\n",
    "kernel_size=(5, 5), stride=(1, 1): 분명 우리는 코드에서 kernel_size=5라고 숫자 하나만 적었는데,\n",
    "영수증에는 (5, 5)로 두 개가 적혀있죠? 이미지는 가로, 세로가 있는 2차원 평면이기 때문에,\n",
    "파이토치가 알아서 \"아, 가로 5, 세로 5 크기의 돋보기를 말하는 거구나!\n",
    "보폭도 가로 1칸, 세로 1칸이구나!\" 하고 똑똑하게 2개로 나누어 적용한 것입니다.\n",
    "\n",
    "bias=True: 우리는 코드에서 nn.Linear(...) 안에 bias라는 걸 적은 적이 없는데 튀어나왔죠?\n",
    "\n",
    "bias는 한국어로 **'편향'**이라고 부릅니다.\n",
    "수학의 일차함수 식 $y = ax + b$에서 기울기 $a$ 말고,\n",
    "영점 조절을 해주는 $b$(y절편)가 필요하듯,\n",
    "딥러닝 모델도 데이터를 더 유연하게 맞추기 위해 **'기본적으로 더해주는 보너스 점수(bias)'**를 자동으로 활성화(True) 시켜둔 것입니다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15550cbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "\n",
    "💡 질문 1. in_channels, out_channels, kernel_size, in_features 값들은 임의로 설정한 걸까?\n",
    "정답부터 말씀드리면: 절대 임의로 적은 것이 아닙니다!\n",
    "얀 르쿤(Yann LeCun) 교수가 수많은 실험 끝에 찾아낸 '가장 최적화된 황금 비율'입니다.\n",
    "\n",
    "LeNet-5의 오리지널 레시피: 우리가 지금 짜고 있는 이 코드는 1998년에 발표된\n",
    "'LeNet-5'라는 전설적인 논문의 구조를 토씨 하나 틀리지 않고 그대로 코드로 옮긴 것입니다.\n",
    "마치 코카콜라의 비밀 레시피처럼, 32x32 크기의 숫자 이미지를 인식하는 데에는 6 -> 16 -> 120 -> 84 -> 10으로 이어지는 부품의 개수와\n",
    "5x5 크기의 돋보기가 가장 성능이 좋았기 때문에 이 숫자를 고정해서 쓰는 것입니다.\n",
    "\n",
    "만약 숫자를 내 마음대로 바꾼다면?: 예를 들어 out_channels=6을 100으로 바꾼다고 해서 에러가 나지는 않습니다.\n",
    "(파이토치 문법상으로는 문제없음) 하지만 로봇의 뇌가 너무 무거워져서 학습 속도가 엄청나게 느려지거나, 오히려 오답을 낼 확률이 높아집니다.\n",
    "요약: 이 숫자들은 아무렇게나 넣은 것이 아니라, **해당 모델(LeNet)을 발명한 천재 학자가 정해둔 '가장 완벽한 설계 도면의 치수'**입니다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ff2a459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "💡 질문 2. 근본적으로 '활성화 함수(Activation Function)'란 무엇이고, tanh는 왜 쓰는 걸까?\n",
    " 활성화 함수는 인공지능의 **'지능'**을 만들어내는 가장 핵심적인 부품입니다.\n",
    " 1. 활성화 함수란 근본적으로 무엇인가?인간의 뇌 신경망(뉴런)을 생각해 보세요.\n",
    " 우리 뇌의 뉴런은 자극이 들어오면 그 자극을 다음 뉴런으로 보낼지 말지 결정합니다.\n",
    " 약한 자극은 무시하고, 일정 기준치를 넘는 강한 자극만 \"찌릿!\" 하고 다음으로 전달(활성화)합니다.\n",
    " \n",
    " 인공지능도 마찬가지입니다. 돋보기(Conv2d)나 회의실(Linear)에서 계산된 결과값을 그대로 다음 층으로 넘기는 게 아니라,\n",
    " **\"이 데이터가 진짜 중요한 특징이야? 다음 층으로 신호를 보낼까 말까?\"**를\n",
    " 결정해 주는 필터가 바로 '활성화 함수'입니다.\n",
    " \n",
    " 2. 왜 쓰는가? (비선형성의 마법)만약 활성화 함수가 없다면?\n",
    " 아무리 회의실(Linear)을 100개, 1000개 이어 붙여도\n",
    " 결국 수학적으로는 그냥 하나의 단순한 직선 방정식($y = wx + b$)이 되어버립니다.\n",
    " \n",
    " 선만으로는 복잡하게 구부러진 숫자 '8'이나 '3'의 모양을 컴퓨터가 이해할 수 없습니다.\n",
    " 활성화 함수를 중간중간 끼워 넣으면, 직선이 구부러지고 휘어지면서\n",
    " '복잡한 곡선과 패턴(비선형성)'을 학습할 수 있는 똑똑한 뇌가 됩니다.\n",
    " \n",
    " 3. 왜 하필 tanh(-1부터 1까지)를 쓰는가?\n",
    " 로봇이 돋보기로 계산을 하다 보면 어떤 특징값은 10000처럼 엄청 커지고,\n",
    " 어떤 건 -500처럼 제멋대로 튈 수 있습니다.\n",
    " 숫자가 너무 커지면 로봇의 뇌(컴퓨터 메모리)가 과부하가 걸리고 폭주합니다.\n",
    " 그래서 tanh를 통과시켜 아무리 큰 숫자가 들어와도 1로 깎아내리고,\n",
    " 아무리 작은 숫자가 들어와도 -1로 올려서 **\"-1부터 1 사이의\n",
    " 안전하고 다루기 쉬운 숫자\"**로 예쁘게 포장해 주는 것입니다. (안정적인 학습을 위해!)\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d76af686",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "와, 정말 핵심을 찌르는 훌륭한 질문입니다! \"찌그러뜨리면 왜곡(정보 손실)이 생기지 않을까?\"\n",
    "라고 의심해 보신 건 딥러닝의 본질을 꿰뚫어 보신 겁니다.\n",
    "\n",
    "먼저 작은 오해 하나를 바로잡고, 왜 -1에서 1 사이로 나오는지,\n",
    "그리고 왜곡이 생기는 게 왜 오히려 좋은 건지 아주 쉽게 설명해 드릴게요.\n",
    "\n",
    "1. tanh는 우리가 알던 그 '탄젠트'가 아닙니다!중학교 수학 시간에 배운 삼각함수 '탄젠트(tan)' 그래프를 떠올려보면,\n",
    "하늘 끝까지 치솟고 땅끝까지 떨어지는 무한한 그래프죠.\n",
    "\n",
    "하지만 여기서 쓰는 tanh는 끝에 'h'가 붙어 있습니다.\n",
    "이것은 **'하이퍼볼릭 탄젠트(Hyperbolic Tangent)'**라고 부르는 전혀 다른 종류의 함수입니다.\n",
    "💡 어떻게 -1에서 1 사이에 갇히게 될까? (수학적 원리)이 함수의 실제 수학 공식은 이렇습니다.\n",
    "\n",
    "$$\\tanh(x) = \\frac{e^x - e^{-x}}{e^x + e^{-x}}$$여기서 $e$는 엄청나게 빨리 커지는 마법의 숫자(자연상수)라고 생각하시면 됩니다.\n",
    "\n",
    "줄다리기로 비유해 볼게요.$x$가 엄청나게 큰 양수(예: 100)일 때: $e^x$는 우주만큼 커지지만,\n",
    "$e^{-x}$는 거의 0이 되어 사라집니다. 결국 우주만큼 큰 수 나누기 우주만큼 큰 수가 되어서,\n",
    "결과는 딱 **$1$**에 수렴하게 됩니다.$x$가 엄청나게 작은 음수(예: -100)일 때: 반대로 $e^{-x}$ 쪽이 우주만큼 커져서,\n",
    "결과는 딱 **$-1$**에 수렴하게 됩니다.그래서 아무리 큰 숫자가 들어와도 절대 1을 넘지 못하고,\n",
    "아무리 작은 숫자가 들어와도 -1 밑으로 떨어지지 않는 튼튼한 울타리가 생기는 것입니다.\n",
    "\n",
    "2. 엄청나게 찌그러뜨리는데, 왜곡(손실)이 안 생길까?결론부터 말씀드리면,\n",
    "\"네, 엄청난 왜곡이 생깁니다! 그리고 그 왜곡이 바로 인공지능이 똑똑해지는 핵심 비결입니다.\n",
    "\"숫자들을 -1에서 1 사이의 좁은 방에 강제로 쑤셔 넣는 이 '의도적인 왜곡'이 왜 필수적인지 3가지 이유를 알려드릴게요.\n",
    "\n",
    "① \"쓸데없는 호들갑(노이즈)\" 무시하기어떤 이미지 특징을 찾았을 때, 숫자가 10이 나온 것과 1000이 나온 것은 무슨 차이일까요?\n",
    "\n",
    "인공지능 입장에서는 둘 다 **\"여기에 특징이 확실하게 있다!\"**라는 뜻일 뿐,\n",
    "1000이라고 해서 100배 더 중요한 게 아닐 수 있습니다.tanh를 통과하면 10은 0.999가 되고, 1000은 0.9999가 됩니다.\n",
    "즉, \"그래, 둘 다 확실히 정답(1)에 가깝네. 쓸데없이 숫자 큰 거에 현혹되지 마!\" 하고 튀는 값(노이즈)을 진정시켜 주는 역할을 합니다.\n",
    "\n",
    "② 로봇의 뇌(메모리) 폭주 방지로봇의 뇌 안에서는 수만 개의 숫자가 계속 더해지고 곱해집니다. 만약 울타리가 없다면 어떻게 될까요?\n",
    "10층, 20층을 통과할 즈음에는 숫자가 1억, 100경처럼 컴퓨터가 계산할 수도 없을 만큼 폭발해버립니다.\n",
    "tanh는 숫자가 폭주하지 않게 꽉 잡아주는 '댐' 역할을 합니다.\n",
    "\n",
    "③ 중요한 건 '대소 관계(순서)'의 유지숫자가 찌그러지긴 하지만, 크기의 순서는 절대 뒤바뀌지 않습니다.\n",
    "(3보다 5가 컸다면, 찌그러진 후에도 5쪽이 더 큽니다.) 인공지능이 판단을 내릴 때는\n",
    "\n",
    "\"정확히 수치가 몇이냐?\"보다 \"어느 특징이 상대적으로 더 강하냐?\"가 훨씬 중요하기 때문에 정보의 핵심은 전혀 손실되지 않습니다.\n",
    "요약하자면: tanh는 숫자가 너무 커져서 로봇이 당황하지 않게 막아주고, \"이 특징이 확실히 있어(1에 가까움)\",\n",
    "\"이 특징은 절대 아니야(-1에 가까움)\" 하고 로봇이 결단력 있게 판단하도록 돕는 아주 훌륭한 필터입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2ff4c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Parameter containing:\n",
       " tensor([[[[-3.4677e-02, -5.7389e-02, -7.9077e-02,  1.6511e-01,  1.3325e-01],\n",
       "           [-5.7697e-02, -1.8562e-01, -8.1130e-02, -7.0518e-02,  1.7123e-02],\n",
       "           [ 7.6575e-02,  3.1316e-02, -1.2606e-01,  7.9986e-02,  1.6090e-01],\n",
       "           [-2.4853e-02, -1.8313e-01,  1.0323e-01, -1.8194e-01, -1.4848e-01],\n",
       "           [ 1.2256e-01, -4.9148e-02, -1.1064e-01,  1.7497e-01, -2.9649e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.0484e-02,  5.3685e-02, -8.0012e-02, -1.1985e-01, -1.2275e-01],\n",
       "           [-1.0904e-01,  7.1912e-02, -1.0750e-02, -3.3331e-02, -8.3103e-02],\n",
       "           [-7.1748e-03, -4.0937e-02, -1.9739e-01,  1.7337e-01, -1.3262e-01],\n",
       "           [-5.6813e-02,  1.4074e-01, -3.6005e-02, -7.4675e-02, -1.5745e-01],\n",
       "           [ 1.4918e-01, -6.9945e-02, -1.6330e-02, -7.9407e-02,  1.8162e-01]]],\n",
       " \n",
       " \n",
       "         [[[-2.3694e-02, -7.6849e-02,  1.6276e-01, -9.3725e-02,  4.3563e-02],\n",
       "           [-4.8616e-02, -1.8030e-01, -1.3649e-01, -7.7450e-02,  1.2848e-01],\n",
       "           [ 1.9886e-01,  9.6632e-02,  3.3327e-02, -7.2041e-02,  1.5704e-04],\n",
       "           [ 8.2562e-02,  1.9095e-01, -1.5600e-01,  1.4199e-01,  1.5458e-01],\n",
       "           [ 1.1369e-01, -1.9999e-01,  1.1820e-01, -7.2109e-02, -1.9798e-01]]],\n",
       " \n",
       " \n",
       "         [[[-1.1961e-01, -8.5403e-02,  1.7764e-01, -1.8760e-01,  1.9917e-01],\n",
       "           [-7.2832e-04,  9.8315e-02, -6.1283e-02,  1.7465e-01,  8.4596e-02],\n",
       "           [ 6.6281e-02, -1.7214e-01,  1.4150e-03, -5.0695e-02,  9.3818e-02],\n",
       "           [ 1.1963e-01, -5.8829e-02,  1.8223e-02, -4.5793e-02, -1.4733e-01],\n",
       "           [ 4.4505e-03, -1.6768e-01,  1.1137e-01, -1.2978e-01, -7.6712e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.4526e-02, -1.4755e-02,  1.2427e-01,  6.5575e-02, -3.0246e-02],\n",
       "           [-1.0344e-01,  1.6746e-01, -8.7979e-02,  9.1636e-02, -1.1611e-01],\n",
       "           [-1.6103e-01, -7.2452e-03, -8.5808e-02, -1.2435e-01,  8.0325e-02],\n",
       "           [ 1.4429e-01,  1.0713e-01, -1.1854e-01, -1.8173e-01, -2.4098e-02],\n",
       "           [ 1.9221e-01,  1.0768e-01,  1.4669e-01,  1.2548e-01,  1.2191e-01]]],\n",
       " \n",
       " \n",
       "         [[[ 7.6433e-02, -1.0253e-01,  1.9879e-03, -2.0836e-02,  2.0211e-02],\n",
       "           [ 9.2934e-02, -7.6227e-04,  7.8847e-03, -1.1310e-01,  1.4115e-01],\n",
       "           [ 1.2968e-02,  4.9622e-02, -1.7457e-01, -1.9417e-01,  1.6439e-01],\n",
       "           [-1.0981e-01,  1.0810e-01,  3.2682e-02, -1.8019e-01,  1.1854e-01],\n",
       "           [ 5.4311e-02,  1.6603e-01, -1.3765e-01,  2.6466e-03,  1.8366e-01]]]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0496, -0.0096, -0.1099, -0.0584,  0.0926, -0.1047],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 7.6077e-02,  8.1935e-03,  2.3704e-02,  3.9477e-03, -1.9928e-02],\n",
       "           [ 4.0806e-02, -5.3209e-02, -7.5151e-03, -9.0780e-03, -1.0713e-02],\n",
       "           [-7.1160e-02,  2.4278e-02,  2.5787e-02,  5.5939e-03, -1.3654e-02],\n",
       "           [-3.2973e-02,  1.3893e-02,  4.1502e-02, -5.5035e-02, -5.5581e-02],\n",
       "           [ 6.2949e-02,  4.7600e-02, -6.2540e-02,  8.1033e-02,  7.2623e-02]],\n",
       " \n",
       "          [[ 6.0919e-02, -5.9824e-03,  2.5257e-02,  6.2307e-02,  7.2470e-02],\n",
       "           [ 3.1137e-02, -7.8997e-02,  1.5212e-02,  5.7156e-02,  2.6573e-02],\n",
       "           [-3.0530e-02, -7.0088e-02, -2.9390e-02, -7.1096e-02,  6.5356e-02],\n",
       "           [-4.9245e-02,  7.5241e-02, -7.3717e-02, -5.3395e-02, -6.2319e-02],\n",
       "           [ 9.4350e-03, -2.8422e-02, -4.5973e-02, -1.8041e-02, -5.8184e-03]],\n",
       " \n",
       "          [[-2.4937e-02,  3.6125e-02, -2.1221e-02,  5.9987e-02,  9.0022e-03],\n",
       "           [ 6.3273e-02,  5.3392e-02, -6.5151e-02,  6.7882e-02, -2.0088e-02],\n",
       "           [-5.9358e-02, -6.7810e-02, -5.5195e-02, -1.2092e-02,  4.8402e-02],\n",
       "           [-7.6045e-02, -7.5291e-02,  5.4367e-02,  2.2921e-02,  9.6384e-03],\n",
       "           [-7.3429e-02, -3.5092e-02, -3.2427e-02, -6.7149e-02, -3.7194e-02]],\n",
       " \n",
       "          [[-7.1813e-02, -6.0831e-02,  3.0786e-02, -2.3496e-02,  6.3645e-02],\n",
       "           [-7.1974e-02, -1.3523e-02, -1.0921e-02,  6.4632e-02,  1.7756e-02],\n",
       "           [ 5.9221e-02, -1.0265e-02,  2.2017e-03,  8.2238e-03, -4.3183e-02],\n",
       "           [ 3.1728e-02,  6.6541e-03, -3.8672e-03, -1.7612e-02, -7.8017e-02],\n",
       "           [-4.3689e-02, -4.6736e-02, -3.7006e-03, -3.6266e-02, -4.8346e-02]],\n",
       " \n",
       "          [[ 3.6201e-02,  1.5789e-02, -6.9708e-02,  6.6457e-02, -7.5420e-02],\n",
       "           [-1.1858e-02,  1.9712e-02,  2.4858e-03,  2.2205e-02, -7.2098e-02],\n",
       "           [-5.7512e-02,  3.4912e-04,  3.2448e-02,  3.3830e-02,  1.6731e-02],\n",
       "           [ 5.0411e-02,  2.3187e-02,  2.7959e-02,  2.2236e-02,  3.7817e-04],\n",
       "           [ 1.6159e-02, -1.6939e-02,  6.2814e-02, -1.3347e-02, -7.6315e-04]],\n",
       " \n",
       "          [[-3.3690e-02,  3.4162e-03,  5.3836e-03, -5.7981e-02, -3.6457e-02],\n",
       "           [ 1.6473e-02, -2.9865e-02,  4.5701e-02, -3.7578e-02,  7.4772e-02],\n",
       "           [ 7.4144e-02, -1.9874e-02,  2.8985e-04,  8.1174e-02, -2.4705e-02],\n",
       "           [ 6.5459e-02, -6.7046e-02, -5.3794e-02,  3.4277e-02, -7.7744e-02],\n",
       "           [-5.0789e-02,  7.5372e-03, -3.2919e-02, -4.9847e-02,  4.2044e-02]]],\n",
       " \n",
       " \n",
       "         [[[-2.4951e-02, -3.9079e-02, -6.2807e-02,  2.0428e-02, -2.4785e-02],\n",
       "           [-3.8794e-02, -1.2020e-03,  3.8441e-02, -1.9693e-02,  1.7354e-02],\n",
       "           [ 6.8269e-02, -7.7493e-02, -1.9359e-02, -5.9895e-02, -4.0564e-02],\n",
       "           [ 5.5624e-03,  1.7256e-02, -1.6534e-02, -4.9912e-02,  3.6646e-02],\n",
       "           [ 8.0766e-02, -6.1392e-02, -6.4425e-03, -7.0356e-02,  8.1589e-02]],\n",
       " \n",
       "          [[ 2.5552e-02, -2.6721e-02,  1.0432e-02, -2.0648e-02, -7.3502e-02],\n",
       "           [ 6.0778e-02, -4.3451e-02,  2.2496e-02,  4.2991e-02,  2.1321e-02],\n",
       "           [ 2.3452e-02,  1.1775e-02,  6.7718e-03, -7.6057e-02, -2.9952e-02],\n",
       "           [ 2.5918e-02,  7.5980e-02,  6.7288e-04,  3.2914e-02,  2.3496e-02],\n",
       "           [-1.8494e-02, -7.2353e-02,  1.4915e-02, -7.6643e-02, -9.5681e-03]],\n",
       " \n",
       "          [[-5.8669e-02, -6.1634e-02, -5.8555e-02,  1.7319e-03, -5.2052e-02],\n",
       "           [ 4.7705e-02,  6.4166e-02,  6.7288e-02,  6.2813e-02, -4.6936e-02],\n",
       "           [ 1.2402e-02, -2.8420e-02,  5.1725e-02, -7.2205e-02, -4.1617e-02],\n",
       "           [ 2.3206e-02, -6.8900e-02, -3.0082e-02, -6.6306e-02,  1.7903e-02],\n",
       "           [-8.1134e-02,  1.9196e-02, -7.6840e-02,  7.3970e-02, -4.1522e-02]],\n",
       " \n",
       "          [[-4.3091e-02, -7.7090e-02, -4.0386e-02, -2.3110e-02,  5.9016e-02],\n",
       "           [ 6.8925e-02,  5.7507e-02, -6.7493e-02,  1.8903e-02, -2.1659e-02],\n",
       "           [-8.0816e-02,  5.3867e-02,  2.4574e-02, -3.6039e-02,  4.8780e-02],\n",
       "           [-5.3980e-02,  2.8217e-02,  6.5130e-02,  5.2713e-02, -9.3051e-03],\n",
       "           [ 5.1731e-02,  3.3828e-02, -7.4893e-02,  6.7919e-02, -5.4965e-02]],\n",
       " \n",
       "          [[-4.6445e-02,  8.1285e-02, -1.4154e-02,  7.3427e-02,  7.2804e-02],\n",
       "           [-3.8659e-02,  5.2254e-02, -5.0473e-02, -4.4695e-02,  1.4569e-02],\n",
       "           [-1.1836e-02,  7.1463e-02, -5.6429e-02, -3.9599e-02,  4.6770e-02],\n",
       "           [ 4.0225e-03,  6.6437e-02,  5.4416e-02,  1.3456e-02,  7.2538e-02],\n",
       "           [-1.4587e-02,  4.5967e-02, -6.8413e-02,  4.2342e-02,  2.6957e-02]],\n",
       " \n",
       "          [[ 6.0888e-02, -2.1218e-02, -7.3704e-03,  5.4025e-02, -6.1982e-03],\n",
       "           [-5.0950e-03,  1.8331e-02, -4.3999e-02, -3.5614e-02, -7.4222e-02],\n",
       "           [ 6.8660e-02,  6.4607e-02,  4.3259e-02, -6.9584e-02, -2.0068e-03],\n",
       "           [-6.9033e-02,  2.4125e-02,  1.4893e-02, -1.6641e-02,  5.6982e-02],\n",
       "           [ 7.3275e-02,  6.1772e-02,  6.6517e-02, -5.7192e-02,  5.2663e-02]]],\n",
       " \n",
       " \n",
       "         [[[-4.5984e-03, -9.7676e-03,  6.3242e-03, -9.2990e-04, -2.4753e-02],\n",
       "           [-2.7544e-02, -4.7467e-02, -8.0145e-02,  4.3614e-02, -7.4986e-02],\n",
       "           [ 5.7552e-02, -5.8037e-02, -6.1568e-02,  2.0372e-04, -1.9428e-02],\n",
       "           [-2.4204e-02,  9.7618e-04, -3.8117e-02,  7.1230e-02, -1.9276e-02],\n",
       "           [-6.7258e-02,  2.6663e-02,  3.9918e-02,  5.0730e-02, -1.2307e-02]],\n",
       " \n",
       "          [[ 3.3471e-02, -6.8595e-02,  7.7397e-02,  8.4646e-03,  3.8650e-02],\n",
       "           [-3.4734e-02, -5.0255e-02, -1.1214e-02,  2.8666e-03, -3.0272e-02],\n",
       "           [-4.6995e-02, -2.6153e-03,  3.1383e-02,  1.5763e-02,  4.6697e-02],\n",
       "           [-6.9201e-02, -5.5199e-02,  1.2543e-02,  3.0052e-02,  5.8291e-02],\n",
       "           [ 1.4334e-02, -5.4112e-02, -6.1652e-02, -2.4182e-02,  7.6926e-03]],\n",
       " \n",
       "          [[-4.8192e-02, -5.3107e-02, -2.2561e-03, -7.5626e-02, -3.8473e-02],\n",
       "           [-5.1541e-02,  7.4487e-02,  5.3515e-02, -4.3355e-02, -1.9506e-02],\n",
       "           [-2.0610e-02,  6.6560e-02, -1.4100e-02,  5.5815e-02, -2.2450e-02],\n",
       "           [ 1.3555e-02,  4.2519e-02,  3.9601e-02,  9.3303e-03,  7.5604e-02],\n",
       "           [-5.9320e-02, -5.7513e-02, -5.9315e-02, -3.0479e-02,  6.0533e-03]],\n",
       " \n",
       "          [[-7.9680e-02,  4.0711e-02,  1.3831e-02,  6.1817e-02, -5.7361e-02],\n",
       "           [-7.6343e-02,  7.5537e-02,  7.8418e-02, -4.6231e-02,  4.8829e-02],\n",
       "           [-5.6578e-02, -3.3983e-02, -6.3671e-02, -2.4172e-02, -7.7925e-03],\n",
       "           [ 6.1865e-02,  7.8793e-02, -2.6697e-02,  9.3555e-03, -3.6083e-02],\n",
       "           [-6.0255e-02,  5.9592e-02,  2.2275e-02, -5.6134e-02, -6.9669e-02]],\n",
       " \n",
       "          [[-2.8347e-02,  2.4332e-02,  7.5855e-03,  7.9429e-02, -5.2204e-02],\n",
       "           [-2.0824e-02,  5.5082e-02, -6.5928e-02, -6.7851e-02, -1.2693e-02],\n",
       "           [ 5.7326e-02,  2.8241e-02, -3.5538e-02, -3.6681e-02,  6.2454e-02],\n",
       "           [-9.7750e-03,  8.1008e-03, -1.0759e-02,  4.9840e-02, -5.5822e-02],\n",
       "           [ 3.8480e-02, -2.9265e-02, -7.1626e-02, -3.4090e-03, -6.6997e-03]],\n",
       " \n",
       "          [[ 6.7544e-02,  1.1766e-02, -7.5659e-03,  4.4814e-02, -1.9364e-02],\n",
       "           [ 5.5540e-02, -6.7947e-02,  6.1376e-03, -4.6949e-02,  3.6555e-02],\n",
       "           [ 7.3752e-02,  3.6862e-02, -1.7748e-02, -1.6458e-03, -2.5255e-02],\n",
       "           [ 6.7840e-02, -4.3334e-02,  7.2034e-02, -2.2403e-02,  6.8033e-02],\n",
       "           [ 3.1923e-03,  9.1359e-03, -5.5290e-02, -2.3995e-02, -1.6938e-02]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 3.7095e-02, -3.9195e-03,  7.2585e-02,  7.0282e-02, -2.2954e-02],\n",
       "           [-6.0018e-02,  3.6898e-02,  4.3309e-02,  5.1583e-03,  4.8504e-02],\n",
       "           [-7.0448e-02, -5.4733e-02,  4.2170e-03, -3.8814e-02, -5.1406e-02],\n",
       "           [ 4.0320e-02, -7.4103e-03,  1.7126e-02, -8.3964e-03,  4.7612e-02],\n",
       "           [-5.3613e-02, -2.0352e-02, -2.0106e-02, -6.0056e-02, -1.5837e-02]],\n",
       " \n",
       "          [[ 4.3097e-02, -8.2927e-03, -2.5167e-02, -4.9011e-02,  2.0916e-02],\n",
       "           [-4.1402e-02,  6.2778e-02,  1.8535e-02,  8.0200e-02,  1.7842e-02],\n",
       "           [-2.6940e-02, -7.0654e-02, -2.4827e-03,  6.3905e-03,  4.2115e-02],\n",
       "           [-8.0752e-02,  4.9092e-02,  6.2874e-02,  4.9122e-02, -2.1803e-02],\n",
       "           [-5.5760e-02,  7.5867e-02,  1.7064e-02,  4.0573e-02,  4.3100e-02]],\n",
       " \n",
       "          [[-5.4648e-02, -6.4865e-02, -1.8582e-03,  7.9305e-02, -3.6491e-02],\n",
       "           [ 7.1520e-02, -1.7866e-03,  4.2389e-02, -2.3683e-02,  9.1338e-03],\n",
       "           [-4.7414e-03,  6.2868e-02, -4.8812e-02,  5.5095e-02, -3.5531e-02],\n",
       "           [-2.0613e-03, -6.3697e-02, -6.9355e-02,  5.5135e-02,  6.7202e-02],\n",
       "           [-7.7779e-02,  2.6240e-02, -2.3243e-02, -4.8733e-02,  3.6764e-02]],\n",
       " \n",
       "          [[ 2.4604e-03, -3.8239e-02,  3.8496e-02,  4.1649e-02,  3.8609e-02],\n",
       "           [-3.9566e-02, -1.6001e-02,  2.0762e-02, -3.1910e-02, -5.2715e-02],\n",
       "           [ 7.9427e-02,  1.7450e-02,  5.6234e-02, -2.6552e-03,  2.9429e-02],\n",
       "           [ 1.3547e-02, -3.7781e-02, -2.4690e-02,  6.9210e-02, -2.4460e-03],\n",
       "           [-5.4146e-02,  4.2719e-02,  5.5982e-02, -4.6946e-02, -6.9923e-02]],\n",
       " \n",
       "          [[ 5.0990e-02,  2.0545e-02, -4.5967e-02, -6.9282e-02, -4.5550e-02],\n",
       "           [ 1.9809e-02,  4.9809e-02, -2.3358e-02,  1.9147e-02,  2.2225e-02],\n",
       "           [-7.4216e-02, -4.2503e-02, -6.7774e-02, -2.1540e-02,  7.1838e-02],\n",
       "           [-3.1818e-02,  6.8816e-02, -4.0682e-02, -5.2752e-02,  5.4835e-02],\n",
       "           [-3.4393e-02, -9.4656e-03,  2.3314e-02,  5.5949e-02, -6.6789e-02]],\n",
       " \n",
       "          [[ 1.6492e-03, -3.6178e-02, -3.5390e-02, -4.5955e-03, -2.6966e-03],\n",
       "           [-3.6236e-02, -1.8047e-02, -7.3612e-02,  3.1632e-02,  3.9971e-02],\n",
       "           [-2.4057e-02,  8.1424e-02,  1.3642e-02, -5.5013e-02,  3.0626e-02],\n",
       "           [ 2.3200e-02, -5.9292e-02, -6.2340e-02,  6.0444e-02,  2.4875e-02],\n",
       "           [-1.8129e-03,  5.0876e-02,  5.0614e-02, -7.0776e-02, -3.3864e-02]]],\n",
       " \n",
       " \n",
       "         [[[ 3.7414e-02,  1.2881e-02, -6.3100e-02,  4.5319e-02, -3.6203e-02],\n",
       "           [-7.1312e-02,  9.8818e-03, -4.7721e-02,  7.0508e-02,  3.0415e-02],\n",
       "           [ 6.9969e-02, -3.7430e-02, -7.3538e-02, -1.5401e-02,  5.4851e-02],\n",
       "           [-4.5493e-02,  1.9217e-02, -4.6270e-02,  5.7768e-02, -8.5481e-03],\n",
       "           [-5.2502e-02,  1.1708e-02, -3.2678e-02, -7.8740e-02,  5.1706e-02]],\n",
       " \n",
       "          [[ 6.3486e-02, -3.6339e-02, -2.1983e-02, -7.5965e-02,  1.8497e-02],\n",
       "           [ 1.5266e-02, -6.7417e-02,  9.5360e-03, -9.1598e-03, -2.4325e-02],\n",
       "           [ 2.6709e-02,  1.7887e-02,  2.0443e-02, -6.7305e-03,  3.3193e-02],\n",
       "           [-3.8014e-02,  5.5795e-02, -5.2315e-03,  6.5426e-02, -6.9926e-03],\n",
       "           [ 4.5133e-02, -9.1548e-03, -9.7709e-03, -3.5342e-03, -5.9698e-02]],\n",
       " \n",
       "          [[ 1.1657e-03,  2.5192e-02,  5.8350e-02,  2.0738e-02, -3.5549e-02],\n",
       "           [ 6.5684e-02,  5.5473e-03, -2.9098e-02, -5.3504e-02,  3.8579e-02],\n",
       "           [ 2.2734e-02,  2.6723e-02, -6.7955e-02,  7.1689e-02, -1.0267e-02],\n",
       "           [ 5.4788e-02, -4.9982e-02, -2.0628e-02, -4.9620e-03,  3.2436e-02],\n",
       "           [-4.9829e-02,  1.2038e-02, -1.0210e-02, -7.8823e-02, -1.3930e-02]],\n",
       " \n",
       "          [[ 5.8314e-02, -5.2237e-02,  7.4568e-02, -5.1601e-02,  2.4358e-02],\n",
       "           [ 1.7353e-02,  5.1129e-02, -2.2686e-02, -3.4530e-02,  7.4829e-02],\n",
       "           [ 3.0766e-02, -7.0904e-02,  4.7205e-02, -8.1308e-02, -6.0645e-02],\n",
       "           [ 4.6438e-02, -6.4056e-02, -9.4930e-03, -2.8130e-03, -3.2940e-02],\n",
       "           [-7.6566e-02,  6.3336e-02,  3.6560e-02, -6.1274e-02, -1.1675e-02]],\n",
       " \n",
       "          [[-3.8127e-02, -5.9177e-02, -7.5566e-02, -6.4652e-02,  1.1203e-02],\n",
       "           [-5.8080e-02,  6.2507e-02,  2.7822e-02,  7.5881e-03, -5.4057e-02],\n",
       "           [ 8.3495e-03,  2.4064e-02, -3.4975e-02,  6.8545e-02, -3.3119e-02],\n",
       "           [ 2.5354e-05,  4.9513e-02, -7.5449e-02, -7.4407e-02,  3.2686e-02],\n",
       "           [ 3.5329e-03, -7.0081e-02, -4.9317e-04, -6.8726e-02,  5.3524e-02]],\n",
       " \n",
       "          [[-1.0652e-02,  6.3445e-02,  1.2137e-02, -5.5119e-02,  1.9506e-02],\n",
       "           [ 3.7968e-02,  4.7883e-02, -7.1625e-03, -3.9359e-02,  2.6389e-02],\n",
       "           [ 3.7734e-02,  2.0040e-02, -7.6923e-02,  6.5820e-02, -1.8501e-02],\n",
       "           [-2.5213e-03,  2.9543e-02, -4.7244e-02, -5.8288e-02,  2.0112e-02],\n",
       "           [-3.1921e-02,  5.9616e-03, -6.3109e-02, -7.8998e-03, -2.9826e-02]]],\n",
       " \n",
       " \n",
       "         [[[-1.5586e-02,  9.7158e-03, -3.2899e-02, -2.1394e-02, -6.8420e-02],\n",
       "           [-4.8920e-02, -7.8211e-02,  4.9943e-02,  1.9944e-02,  5.6875e-02],\n",
       "           [ 2.5343e-02,  1.0869e-02, -5.5600e-02,  2.1019e-02,  5.9942e-02],\n",
       "           [ 4.9683e-03, -2.8630e-02,  5.4908e-02, -2.6421e-02, -5.5845e-02],\n",
       "           [-5.1159e-02, -7.7942e-02,  3.2797e-02,  6.2781e-02, -3.8674e-03]],\n",
       " \n",
       "          [[-5.7718e-02, -6.7545e-02, -6.1507e-02,  4.0952e-02, -1.5629e-03],\n",
       "           [-3.0391e-02, -5.5873e-02,  2.3602e-02,  5.9593e-02, -1.5919e-02],\n",
       "           [-3.0972e-02, -7.2495e-02, -1.0331e-02, -4.8011e-03,  1.8055e-02],\n",
       "           [-6.0354e-02,  6.5612e-02,  3.3337e-02,  2.8100e-03,  1.2548e-02],\n",
       "           [-8.0768e-02, -4.0152e-02,  4.1821e-02, -5.2233e-02,  1.2052e-02]],\n",
       " \n",
       "          [[-1.6062e-02, -6.9006e-02,  3.0811e-02,  3.8986e-02, -5.5654e-02],\n",
       "           [-2.4877e-02, -2.2401e-02,  1.2976e-02,  5.0400e-02,  3.4721e-02],\n",
       "           [-2.3733e-02, -8.9099e-03, -6.8110e-02, -3.5588e-02,  3.8125e-02],\n",
       "           [-2.0762e-02,  1.4859e-04, -6.3222e-02,  2.3597e-02,  7.0117e-02],\n",
       "           [ 1.2361e-02, -2.8902e-02, -6.2408e-02,  4.3874e-02, -5.3607e-02]],\n",
       " \n",
       "          [[ 5.0617e-02, -4.2509e-02,  2.9103e-02,  6.1931e-02,  7.3054e-02],\n",
       "           [-7.7728e-03, -5.8128e-03,  5.9876e-02,  7.8526e-02, -4.0943e-02],\n",
       "           [-8.1011e-02,  5.5279e-02, -6.0949e-03, -4.7161e-02,  1.7508e-02],\n",
       "           [ 5.2647e-02,  1.2909e-02,  7.6090e-02, -1.4098e-03,  7.5638e-02],\n",
       "           [-5.7416e-03,  4.6957e-02, -1.9534e-02, -4.1684e-02,  3.8649e-02]],\n",
       " \n",
       "          [[-7.4366e-02, -7.8987e-02,  6.9992e-02,  4.8400e-02,  3.7044e-02],\n",
       "           [-7.5537e-02,  5.4791e-02,  7.4210e-02,  4.1117e-02,  2.7682e-02],\n",
       "           [ 4.7824e-02, -4.3295e-02, -3.2171e-02,  5.1005e-02, -4.9930e-02],\n",
       "           [ 1.8830e-02, -4.8810e-02, -3.8692e-02, -3.7410e-02, -9.8546e-04],\n",
       "           [ 3.3013e-04, -7.8729e-03, -6.6667e-02,  4.0116e-02,  5.8778e-02]],\n",
       " \n",
       "          [[ 6.7163e-02, -1.1338e-04, -1.0602e-02, -5.8144e-03, -1.4862e-02],\n",
       "           [ 3.2116e-02,  1.8988e-02,  6.2680e-02, -4.0022e-02,  1.8524e-02],\n",
       "           [ 4.5304e-02,  2.4399e-02,  2.5070e-02,  6.0433e-02,  9.2520e-03],\n",
       "           [ 4.8284e-02, -7.5988e-02,  8.0253e-02,  2.5961e-02,  1.0616e-02],\n",
       "           [ 7.5550e-02,  2.5719e-02, -2.7719e-02, -6.2585e-02, -1.1157e-02]]]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0516, -0.0456,  0.0674, -0.0793,  0.0797, -0.0703, -0.0711,  0.0357,\n",
       "         -0.0403,  0.0372, -0.0284, -0.0595, -0.0107, -0.0525, -0.0276, -0.0020],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[[[ 0.0386, -0.0429,  0.0050, -0.0246, -0.0442],\n",
       "           [ 0.0375, -0.0406,  0.0262, -0.0282, -0.0141],\n",
       "           [ 0.0357, -0.0323,  0.0419, -0.0313, -0.0186],\n",
       "           [-0.0115,  0.0374, -0.0077, -0.0285, -0.0397],\n",
       "           [-0.0485, -0.0179, -0.0405, -0.0217, -0.0441]],\n",
       " \n",
       "          [[ 0.0376,  0.0166, -0.0007,  0.0303, -0.0494],\n",
       "           [-0.0237, -0.0224,  0.0146, -0.0323,  0.0416],\n",
       "           [ 0.0447,  0.0207, -0.0079,  0.0224,  0.0485],\n",
       "           [ 0.0030, -0.0485,  0.0013,  0.0127, -0.0451],\n",
       "           [-0.0253, -0.0008, -0.0395,  0.0489,  0.0035]],\n",
       " \n",
       "          [[ 0.0080,  0.0014,  0.0381,  0.0421, -0.0045],\n",
       "           [-0.0254,  0.0317,  0.0301,  0.0438,  0.0203],\n",
       "           [-0.0357, -0.0493,  0.0339,  0.0333,  0.0045],\n",
       "           [ 0.0473,  0.0433,  0.0469, -0.0115, -0.0214],\n",
       "           [-0.0175,  0.0137,  0.0313, -0.0165,  0.0471]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0425,  0.0231, -0.0180,  0.0157, -0.0353],\n",
       "           [ 0.0124, -0.0207,  0.0157, -0.0250, -0.0296],\n",
       "           [-0.0056, -0.0213, -0.0469,  0.0395, -0.0315],\n",
       "           [ 0.0257, -0.0480, -0.0157, -0.0229, -0.0087],\n",
       "           [ 0.0148, -0.0279, -0.0109,  0.0416, -0.0098]],\n",
       " \n",
       "          [[ 0.0309,  0.0436, -0.0081, -0.0275, -0.0183],\n",
       "           [ 0.0086,  0.0257, -0.0126,  0.0428, -0.0459],\n",
       "           [ 0.0236,  0.0225, -0.0390,  0.0082,  0.0304],\n",
       "           [-0.0120,  0.0018, -0.0343, -0.0446,  0.0048],\n",
       "           [ 0.0221,  0.0455,  0.0188, -0.0236, -0.0400]],\n",
       " \n",
       "          [[ 0.0098,  0.0380, -0.0450, -0.0282, -0.0491],\n",
       "           [ 0.0372, -0.0253,  0.0411,  0.0201, -0.0092],\n",
       "           [ 0.0468, -0.0242, -0.0311,  0.0276, -0.0044],\n",
       "           [-0.0387,  0.0357, -0.0097,  0.0423,  0.0363],\n",
       "           [-0.0458, -0.0016,  0.0050,  0.0169,  0.0317]]],\n",
       " \n",
       " \n",
       "         [[[-0.0399,  0.0176,  0.0118,  0.0389,  0.0456],\n",
       "           [ 0.0280, -0.0386,  0.0334, -0.0482, -0.0318],\n",
       "           [ 0.0181, -0.0033,  0.0081, -0.0165,  0.0291],\n",
       "           [ 0.0158,  0.0103,  0.0165, -0.0271,  0.0356],\n",
       "           [-0.0435, -0.0472, -0.0086,  0.0045,  0.0455]],\n",
       " \n",
       "          [[-0.0233,  0.0439, -0.0266, -0.0399, -0.0160],\n",
       "           [-0.0120, -0.0350,  0.0475, -0.0041, -0.0127],\n",
       "           [ 0.0379, -0.0096,  0.0476,  0.0407,  0.0029],\n",
       "           [-0.0086,  0.0263,  0.0017, -0.0042,  0.0431],\n",
       "           [-0.0410,  0.0394, -0.0166, -0.0092, -0.0434]],\n",
       " \n",
       "          [[-0.0034,  0.0114,  0.0168, -0.0137,  0.0328],\n",
       "           [-0.0498,  0.0220, -0.0373, -0.0259,  0.0029],\n",
       "           [ 0.0481, -0.0007, -0.0347, -0.0358,  0.0075],\n",
       "           [ 0.0073,  0.0042, -0.0026, -0.0169,  0.0318],\n",
       "           [ 0.0193, -0.0042, -0.0091, -0.0403, -0.0128]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0500,  0.0426,  0.0467, -0.0496,  0.0147],\n",
       "           [ 0.0213,  0.0404, -0.0260, -0.0063,  0.0354],\n",
       "           [-0.0475,  0.0023,  0.0137, -0.0087, -0.0453],\n",
       "           [-0.0280, -0.0485, -0.0316, -0.0008, -0.0470],\n",
       "           [ 0.0292,  0.0207,  0.0282,  0.0005, -0.0244]],\n",
       " \n",
       "          [[-0.0065, -0.0226, -0.0264, -0.0358,  0.0254],\n",
       "           [-0.0333,  0.0297,  0.0233,  0.0415, -0.0251],\n",
       "           [-0.0344, -0.0274, -0.0248, -0.0393,  0.0095],\n",
       "           [ 0.0304,  0.0272, -0.0078,  0.0398,  0.0274],\n",
       "           [-0.0048, -0.0148, -0.0212, -0.0473, -0.0153]],\n",
       " \n",
       "          [[-0.0266,  0.0202, -0.0495,  0.0313, -0.0023],\n",
       "           [-0.0250,  0.0380, -0.0362,  0.0274, -0.0312],\n",
       "           [ 0.0389,  0.0026,  0.0063, -0.0269,  0.0419],\n",
       "           [ 0.0221, -0.0499, -0.0220,  0.0465,  0.0326],\n",
       "           [-0.0337,  0.0268, -0.0026,  0.0416, -0.0184]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0143, -0.0206,  0.0462, -0.0184, -0.0320],\n",
       "           [ 0.0138, -0.0369, -0.0482, -0.0234,  0.0176],\n",
       "           [ 0.0383,  0.0472,  0.0416, -0.0165, -0.0087],\n",
       "           [-0.0271,  0.0423, -0.0156,  0.0068, -0.0099],\n",
       "           [-0.0403, -0.0421, -0.0008, -0.0125, -0.0416]],\n",
       " \n",
       "          [[-0.0168,  0.0404, -0.0207,  0.0369,  0.0359],\n",
       "           [ 0.0048,  0.0402, -0.0036,  0.0217,  0.0226],\n",
       "           [ 0.0134, -0.0444,  0.0114, -0.0282, -0.0451],\n",
       "           [ 0.0382, -0.0081,  0.0079, -0.0409, -0.0219],\n",
       "           [ 0.0231,  0.0183,  0.0291, -0.0486,  0.0242]],\n",
       " \n",
       "          [[ 0.0379, -0.0261, -0.0333,  0.0114,  0.0262],\n",
       "           [ 0.0198,  0.0300,  0.0065,  0.0445,  0.0344],\n",
       "           [-0.0125,  0.0040,  0.0230,  0.0437, -0.0322],\n",
       "           [ 0.0415,  0.0489,  0.0298,  0.0025, -0.0307],\n",
       "           [ 0.0135,  0.0177, -0.0444,  0.0064, -0.0223]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[ 0.0427,  0.0102,  0.0495, -0.0232,  0.0387],\n",
       "           [ 0.0353,  0.0385,  0.0006, -0.0350, -0.0197],\n",
       "           [ 0.0085,  0.0409,  0.0280, -0.0324,  0.0449],\n",
       "           [ 0.0044, -0.0476,  0.0291,  0.0494,  0.0037],\n",
       "           [ 0.0197,  0.0497,  0.0394, -0.0026,  0.0112]],\n",
       " \n",
       "          [[ 0.0209, -0.0403, -0.0291, -0.0258, -0.0451],\n",
       "           [-0.0007, -0.0271,  0.0086, -0.0223,  0.0380],\n",
       "           [-0.0122, -0.0227,  0.0011, -0.0015, -0.0074],\n",
       "           [-0.0492, -0.0114, -0.0266, -0.0133, -0.0364],\n",
       "           [-0.0252,  0.0052, -0.0129,  0.0214,  0.0427]],\n",
       " \n",
       "          [[-0.0382, -0.0316,  0.0454, -0.0331, -0.0139],\n",
       "           [ 0.0090, -0.0109, -0.0124, -0.0073, -0.0012],\n",
       "           [ 0.0427,  0.0114, -0.0422, -0.0447,  0.0019],\n",
       "           [ 0.0079, -0.0080, -0.0043,  0.0351, -0.0361],\n",
       "           [-0.0304, -0.0265, -0.0427,  0.0297,  0.0386]]],\n",
       " \n",
       " \n",
       "         ...,\n",
       " \n",
       " \n",
       "         [[[ 0.0109, -0.0046,  0.0352,  0.0482, -0.0487],\n",
       "           [ 0.0279, -0.0432, -0.0122, -0.0326,  0.0281],\n",
       "           [ 0.0101,  0.0446,  0.0449, -0.0212, -0.0372],\n",
       "           [ 0.0330, -0.0022, -0.0427, -0.0231,  0.0151],\n",
       "           [ 0.0469,  0.0305,  0.0286,  0.0274, -0.0363]],\n",
       " \n",
       "          [[-0.0049, -0.0213, -0.0201, -0.0175, -0.0293],\n",
       "           [-0.0159, -0.0064,  0.0113,  0.0486, -0.0491],\n",
       "           [ 0.0006, -0.0298,  0.0478,  0.0171,  0.0165],\n",
       "           [ 0.0094,  0.0076,  0.0113, -0.0214, -0.0420],\n",
       "           [ 0.0163,  0.0222,  0.0212, -0.0273,  0.0405]],\n",
       " \n",
       "          [[-0.0492, -0.0005,  0.0155, -0.0278,  0.0426],\n",
       "           [-0.0408, -0.0068, -0.0035, -0.0297,  0.0283],\n",
       "           [-0.0105,  0.0076,  0.0070,  0.0064, -0.0149],\n",
       "           [ 0.0097, -0.0128, -0.0440, -0.0079,  0.0382],\n",
       "           [ 0.0258, -0.0356,  0.0273, -0.0447,  0.0431]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0359, -0.0419, -0.0192,  0.0408,  0.0258],\n",
       "           [ 0.0253,  0.0009,  0.0086, -0.0330,  0.0040],\n",
       "           [-0.0042, -0.0493,  0.0273,  0.0065, -0.0204],\n",
       "           [ 0.0077,  0.0055, -0.0263,  0.0222,  0.0498],\n",
       "           [ 0.0351,  0.0161, -0.0241,  0.0307, -0.0483]],\n",
       " \n",
       "          [[ 0.0406, -0.0033, -0.0147, -0.0027, -0.0427],\n",
       "           [-0.0301,  0.0082, -0.0366, -0.0363, -0.0462],\n",
       "           [-0.0199,  0.0475,  0.0305,  0.0464,  0.0040],\n",
       "           [-0.0364, -0.0314,  0.0026,  0.0074,  0.0022],\n",
       "           [-0.0194,  0.0218, -0.0166,  0.0028, -0.0416]],\n",
       " \n",
       "          [[-0.0036,  0.0145, -0.0481, -0.0128,  0.0393],\n",
       "           [-0.0499, -0.0308, -0.0230, -0.0026,  0.0263],\n",
       "           [-0.0456,  0.0149, -0.0084,  0.0268,  0.0285],\n",
       "           [-0.0180, -0.0367,  0.0005, -0.0005, -0.0329],\n",
       "           [ 0.0017, -0.0345, -0.0184, -0.0169,  0.0288]]],\n",
       " \n",
       " \n",
       "         [[[ 0.0435,  0.0218,  0.0232,  0.0037, -0.0215],\n",
       "           [-0.0247,  0.0120, -0.0422, -0.0139, -0.0176],\n",
       "           [-0.0139,  0.0061, -0.0349,  0.0323, -0.0341],\n",
       "           [-0.0005,  0.0138,  0.0204,  0.0222, -0.0382],\n",
       "           [ 0.0176,  0.0204, -0.0412,  0.0357, -0.0464]],\n",
       " \n",
       "          [[ 0.0307, -0.0101, -0.0042,  0.0495, -0.0400],\n",
       "           [-0.0413,  0.0238, -0.0213, -0.0313, -0.0367],\n",
       "           [-0.0374,  0.0091, -0.0372,  0.0260,  0.0177],\n",
       "           [ 0.0338, -0.0029, -0.0187, -0.0015, -0.0311],\n",
       "           [ 0.0080, -0.0160, -0.0052,  0.0422, -0.0417]],\n",
       " \n",
       "          [[ 0.0087, -0.0384, -0.0274, -0.0377, -0.0023],\n",
       "           [-0.0251, -0.0468,  0.0129,  0.0103, -0.0214],\n",
       "           [-0.0280,  0.0232,  0.0467,  0.0439, -0.0420],\n",
       "           [-0.0133, -0.0359, -0.0119,  0.0157, -0.0056],\n",
       "           [ 0.0433,  0.0072,  0.0463, -0.0008, -0.0049]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0282,  0.0362,  0.0061, -0.0025, -0.0471],\n",
       "           [-0.0200, -0.0208,  0.0178,  0.0381, -0.0066],\n",
       "           [ 0.0422,  0.0088, -0.0056,  0.0301, -0.0090],\n",
       "           [-0.0301, -0.0124, -0.0205, -0.0313, -0.0184],\n",
       "           [ 0.0263,  0.0229, -0.0107, -0.0352,  0.0265]],\n",
       " \n",
       "          [[-0.0255,  0.0309,  0.0192, -0.0034,  0.0290],\n",
       "           [ 0.0292,  0.0038,  0.0434, -0.0087, -0.0083],\n",
       "           [ 0.0202,  0.0009, -0.0342,  0.0197, -0.0170],\n",
       "           [ 0.0129,  0.0113, -0.0302, -0.0313,  0.0474],\n",
       "           [ 0.0460,  0.0365,  0.0444, -0.0457,  0.0226]],\n",
       " \n",
       "          [[ 0.0072, -0.0424,  0.0419,  0.0290,  0.0184],\n",
       "           [ 0.0173,  0.0392,  0.0221,  0.0328, -0.0192],\n",
       "           [-0.0374,  0.0347,  0.0436, -0.0457, -0.0130],\n",
       "           [-0.0017, -0.0220, -0.0435,  0.0467, -0.0236],\n",
       "           [-0.0163,  0.0255,  0.0109, -0.0293,  0.0029]]],\n",
       " \n",
       " \n",
       "         [[[-0.0115,  0.0429, -0.0397,  0.0116, -0.0166],\n",
       "           [-0.0280, -0.0460,  0.0433,  0.0190, -0.0032],\n",
       "           [-0.0065, -0.0402, -0.0083,  0.0136, -0.0308],\n",
       "           [ 0.0363,  0.0071, -0.0271,  0.0359, -0.0425],\n",
       "           [ 0.0008,  0.0126,  0.0214, -0.0241, -0.0378]],\n",
       " \n",
       "          [[ 0.0323, -0.0063, -0.0349, -0.0423,  0.0122],\n",
       "           [-0.0335, -0.0051,  0.0268,  0.0185,  0.0064],\n",
       "           [ 0.0411, -0.0011,  0.0323,  0.0351, -0.0353],\n",
       "           [-0.0381,  0.0464, -0.0252,  0.0368, -0.0397],\n",
       "           [-0.0263,  0.0067, -0.0430,  0.0347, -0.0343]],\n",
       " \n",
       "          [[ 0.0400,  0.0372,  0.0300,  0.0180, -0.0195],\n",
       "           [-0.0111, -0.0436,  0.0106,  0.0187,  0.0169],\n",
       "           [-0.0359,  0.0200,  0.0098, -0.0293,  0.0438],\n",
       "           [-0.0463,  0.0137, -0.0241, -0.0176, -0.0052],\n",
       "           [ 0.0467,  0.0384, -0.0385,  0.0097,  0.0118]],\n",
       " \n",
       "          ...,\n",
       " \n",
       "          [[-0.0490, -0.0469, -0.0361,  0.0125,  0.0476],\n",
       "           [ 0.0247, -0.0483,  0.0177,  0.0363,  0.0211],\n",
       "           [-0.0212, -0.0147,  0.0011,  0.0170, -0.0492],\n",
       "           [-0.0482,  0.0459,  0.0387, -0.0431, -0.0315],\n",
       "           [ 0.0100, -0.0452, -0.0106,  0.0289,  0.0444]],\n",
       " \n",
       "          [[-0.0336,  0.0176, -0.0069,  0.0372, -0.0314],\n",
       "           [ 0.0375, -0.0344, -0.0456, -0.0354, -0.0063],\n",
       "           [ 0.0152,  0.0292,  0.0402,  0.0437,  0.0261],\n",
       "           [-0.0317,  0.0403, -0.0333, -0.0064,  0.0464],\n",
       "           [ 0.0030,  0.0371,  0.0078, -0.0134, -0.0420]],\n",
       " \n",
       "          [[-0.0313, -0.0406,  0.0295,  0.0284, -0.0329],\n",
       "           [ 0.0233, -0.0435,  0.0347,  0.0029,  0.0203],\n",
       "           [-0.0213,  0.0459,  0.0334, -0.0473,  0.0179],\n",
       "           [-0.0288, -0.0065,  0.0433,  0.0020,  0.0223],\n",
       "           [-0.0129,  0.0096,  0.0325, -0.0134, -0.0296]]]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-3.2200e-02,  3.5317e-02, -2.8276e-02,  3.1950e-02, -2.2232e-02,\n",
       "         -1.2601e-03, -3.6619e-02, -2.1011e-02,  8.9952e-03, -4.3091e-02,\n",
       "         -5.3190e-04,  4.2418e-02,  4.6510e-02,  2.2965e-02,  1.3480e-02,\n",
       "          1.9268e-02,  9.8581e-04,  3.2621e-03,  4.1968e-02,  3.3611e-02,\n",
       "         -2.0674e-02, -1.6230e-03,  4.6496e-02,  4.1169e-02, -2.3467e-02,\n",
       "         -6.6130e-03,  1.5186e-02,  2.3253e-02,  4.7093e-02,  6.2091e-03,\n",
       "         -2.4705e-02,  4.3485e-02, -4.6638e-02, -9.4817e-04, -3.6226e-02,\n",
       "         -2.9428e-02,  3.2115e-02,  3.7225e-02, -7.5227e-03,  3.8260e-02,\n",
       "         -1.3928e-02,  1.5464e-02, -5.4603e-03,  7.4447e-03, -4.7598e-03,\n",
       "          2.7465e-02, -4.1135e-02,  3.5674e-02,  2.0713e-02,  1.3627e-05,\n",
       "         -2.3645e-02,  2.5484e-02, -4.3468e-03,  1.8970e-02,  1.5752e-02,\n",
       "         -3.2365e-02,  3.2111e-02,  9.3181e-03,  4.3486e-02,  3.7426e-02,\n",
       "         -3.0962e-02, -4.4111e-02,  1.8226e-02,  3.2365e-03,  2.8741e-02,\n",
       "          4.6127e-02,  1.6278e-02,  8.8895e-03,  4.3468e-02,  1.1900e-02,\n",
       "         -1.0964e-02, -3.8060e-02, -3.6349e-02, -1.9179e-02, -2.9453e-02,\n",
       "         -1.0202e-02, -2.7850e-02, -2.5575e-02, -3.2024e-02,  4.9338e-02,\n",
       "         -4.5693e-02, -9.8633e-03,  3.7059e-02, -1.2213e-03, -4.1237e-02,\n",
       "         -2.0768e-02,  3.6323e-02,  4.0761e-02,  4.9003e-03,  3.2711e-02,\n",
       "         -1.2569e-02,  3.7795e-02, -8.4564e-03, -3.5772e-02,  3.4918e-02,\n",
       "          4.4863e-02,  4.9566e-02, -2.3159e-02,  3.8882e-02,  3.7744e-02,\n",
       "          8.5084e-03,  1.3909e-02,  3.7893e-02, -3.1525e-02,  4.4379e-02,\n",
       "          7.8651e-03, -2.5658e-02,  1.2233e-02, -2.8469e-02,  4.7920e-02,\n",
       "         -3.2230e-02, -3.4642e-02,  1.1115e-02, -4.8120e-02, -1.6892e-02,\n",
       "         -4.3106e-02,  6.6958e-04,  2.0816e-02,  3.3235e-02,  4.7851e-02],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0555, -0.0183, -0.0857,  ..., -0.0441,  0.0131,  0.0624],\n",
       "         [ 0.0404,  0.0620, -0.0499,  ..., -0.0654, -0.0035,  0.0014],\n",
       "         [ 0.0166, -0.0339,  0.0358,  ..., -0.0277, -0.0436,  0.0164],\n",
       "         ...,\n",
       "         [ 0.0003, -0.0823,  0.0074,  ...,  0.0688, -0.0624,  0.0908],\n",
       "         [-0.0584, -0.0242,  0.0907,  ..., -0.0019, -0.0298, -0.0470],\n",
       "         [-0.0904,  0.0648, -0.0446,  ...,  0.0760, -0.0387, -0.0595]],\n",
       "        requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([ 0.0757, -0.0151,  0.0006,  0.0135, -0.0516,  0.0161, -0.0046,  0.0862,\n",
       "          0.0543, -0.0122, -0.0750, -0.0171, -0.0616,  0.0696, -0.0325,  0.0585,\n",
       "          0.0246, -0.0376,  0.0196, -0.0730,  0.0279, -0.0871,  0.0206,  0.0243,\n",
       "          0.0108,  0.0016, -0.0885,  0.0706,  0.0429, -0.0037,  0.0481,  0.0455,\n",
       "         -0.0080, -0.0193, -0.0048, -0.0739, -0.0265,  0.0685, -0.0252,  0.0344,\n",
       "          0.0604, -0.0137, -0.0435, -0.0079, -0.0783,  0.0824,  0.0887,  0.0254,\n",
       "          0.0589,  0.0435, -0.0365,  0.0394, -0.0336, -0.0613, -0.0169, -0.0409,\n",
       "          0.0427,  0.0602, -0.0042,  0.0301, -0.0139,  0.0280, -0.0263, -0.0315,\n",
       "          0.0615, -0.0520, -0.0793,  0.0707, -0.0909,  0.0772,  0.0198,  0.0102,\n",
       "         -0.0393,  0.0227,  0.0109,  0.0511, -0.0799, -0.0569,  0.0237,  0.0674,\n",
       "         -0.0763, -0.0654, -0.0274, -0.0781], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([[-0.0879, -0.0490, -0.0995, -0.0394, -0.0771, -0.0110, -0.0544, -0.0255,\n",
       "           0.1006,  0.0944, -0.0940, -0.0481, -0.0196, -0.0359,  0.0877,  0.0736,\n",
       "          -0.0084, -0.0624,  0.0786, -0.0665,  0.0336, -0.0750, -0.0822,  0.0386,\n",
       "           0.0674,  0.0297, -0.0899,  0.0682, -0.0148, -0.0781, -0.1068, -0.0021,\n",
       "          -0.0756, -0.0385, -0.0877,  0.0634,  0.0074, -0.0772, -0.0111,  0.0726,\n",
       "           0.0379, -0.0691,  0.0732,  0.0352,  0.0685, -0.1037, -0.0761,  0.0736,\n",
       "          -0.0735, -0.0655,  0.0333,  0.0605,  0.0821, -0.0454,  0.0747, -0.0803,\n",
       "           0.0155,  0.0985,  0.0565,  0.0895,  0.0140, -0.0330, -0.0818,  0.1005,\n",
       "           0.0083,  0.0615,  0.0621, -0.1086,  0.0950, -0.0824, -0.0242, -0.0649,\n",
       "           0.0831,  0.0697,  0.0591,  0.0286, -0.0082,  0.0136,  0.0200, -0.0241,\n",
       "          -0.0870, -0.0138, -0.0803,  0.0424],\n",
       "         [ 0.0721, -0.0641, -0.0867, -0.0578,  0.0970,  0.0152, -0.0583,  0.0183,\n",
       "           0.0708, -0.0283, -0.0876,  0.0896,  0.0498,  0.0369, -0.0994, -0.0456,\n",
       "          -0.0782, -0.0716, -0.0523,  0.0500, -0.0841, -0.0709, -0.0271,  0.0677,\n",
       "          -0.0998, -0.0757,  0.0009, -0.0526,  0.0724, -0.0128,  0.1017, -0.0461,\n",
       "          -0.1083, -0.1061, -0.0716, -0.0384, -0.0512,  0.0823, -0.1051, -0.0103,\n",
       "           0.0375, -0.0026,  0.0340,  0.0497, -0.0041, -0.0963,  0.0943, -0.0182,\n",
       "           0.0114, -0.0812, -0.0946,  0.1047,  0.0738, -0.0089, -0.0633, -0.1083,\n",
       "           0.0046, -0.0822, -0.0159, -0.1040, -0.0032, -0.0866,  0.0347, -0.0427,\n",
       "          -0.1075, -0.0829, -0.0835, -0.0940, -0.0951, -0.0395,  0.0713,  0.0223,\n",
       "          -0.1010,  0.0469,  0.0741,  0.0193,  0.0522, -0.0495,  0.0979,  0.1038,\n",
       "           0.0379,  0.0754,  0.0719, -0.0225],\n",
       "         [ 0.0256, -0.0511,  0.0453, -0.0844, -0.0682,  0.0289,  0.0927,  0.0201,\n",
       "           0.0199, -0.0074,  0.0876,  0.0277,  0.0345,  0.0946,  0.0756, -0.0238,\n",
       "           0.0073,  0.0582, -0.0515, -0.0907,  0.0806,  0.0262, -0.0147, -0.0692,\n",
       "          -0.0647, -0.0157,  0.0657, -0.0656, -0.0401,  0.0195, -0.0470, -0.0548,\n",
       "          -0.0194,  0.0780, -0.1012,  0.0858, -0.0972,  0.0018, -0.0990,  0.0233,\n",
       "           0.0849, -0.0471, -0.0060,  0.0457, -0.0668,  0.0929, -0.0733, -0.0253,\n",
       "          -0.0568, -0.0037, -0.0700, -0.0058, -0.0938, -0.1086, -0.1090,  0.0427,\n",
       "           0.0574,  0.0241, -0.0263,  0.0816, -0.0658,  0.0893, -0.0036,  0.0867,\n",
       "           0.0551, -0.0447, -0.0771,  0.0331, -0.0933,  0.0233,  0.0025,  0.0308,\n",
       "          -0.0234,  0.0195,  0.0998,  0.0166,  0.0551, -0.0487, -0.0116,  0.0130,\n",
       "          -0.0542, -0.0992, -0.0420,  0.0960],\n",
       "         [-0.0143, -0.0349,  0.1075,  0.0844,  0.0495,  0.0532,  0.0312,  0.0294,\n",
       "           0.1004,  0.0773,  0.0248,  0.0419,  0.0687,  0.0977, -0.0110, -0.0809,\n",
       "           0.0350, -0.0714, -0.0580,  0.0270, -0.1084, -0.0900, -0.0839, -0.0051,\n",
       "           0.0377,  0.0845,  0.0932, -0.0430,  0.0513,  0.0295,  0.1072,  0.0376,\n",
       "          -0.0662, -0.0481, -0.0748,  0.0355,  0.0758,  0.0703, -0.0486,  0.0864,\n",
       "           0.0673, -0.0352, -0.0768, -0.0477, -0.0080,  0.0786, -0.0836, -0.0870,\n",
       "          -0.0481,  0.0142,  0.0176,  0.0856,  0.0842,  0.1054, -0.0817, -0.0849,\n",
       "           0.0323,  0.0280, -0.0381, -0.1083,  0.0415,  0.1016, -0.0460,  0.0830,\n",
       "           0.0897, -0.0689, -0.0680,  0.0385, -0.0799,  0.0192, -0.0976, -0.0931,\n",
       "          -0.0225,  0.1079,  0.0636, -0.0823, -0.0219,  0.0480, -0.0518, -0.0764,\n",
       "           0.0886, -0.0849, -0.0606,  0.0039],\n",
       "         [-0.0662, -0.0652, -0.0192,  0.1075,  0.0463,  0.1074,  0.0387, -0.0694,\n",
       "           0.0602, -0.0114, -0.0816,  0.0499,  0.0542, -0.0156,  0.0104,  0.0383,\n",
       "          -0.0739, -0.0350, -0.0165,  0.0551, -0.0236, -0.0807, -0.0218, -0.0719,\n",
       "          -0.0179, -0.0851,  0.0808, -0.0597,  0.0180,  0.0200, -0.0494,  0.0117,\n",
       "           0.0139,  0.0247, -0.0764,  0.0376, -0.0600,  0.0972,  0.0161,  0.0207,\n",
       "           0.0480,  0.0064, -0.0325, -0.0118, -0.0553,  0.0646,  0.0427, -0.0457,\n",
       "          -0.0329,  0.0699,  0.0056, -0.0710,  0.0870, -0.0514, -0.0327,  0.0377,\n",
       "          -0.0337, -0.0576,  0.0479, -0.0197, -0.0186, -0.0639,  0.0628, -0.0215,\n",
       "          -0.0709, -0.0585, -0.0109, -0.0191, -0.0945, -0.0800, -0.0307, -0.0719,\n",
       "          -0.0765, -0.0435, -0.0212,  0.0003,  0.0378, -0.0109,  0.0413, -0.0350,\n",
       "           0.0353, -0.0313,  0.1028,  0.1068],\n",
       "         [ 0.0929, -0.0376, -0.0249,  0.0448,  0.0068,  0.0782,  0.0282,  0.0749,\n",
       "          -0.0990,  0.1006,  0.0650,  0.0954, -0.0079, -0.0653,  0.0084,  0.0699,\n",
       "          -0.0922, -0.0231, -0.0276, -0.0480,  0.0356, -0.0666, -0.0520,  0.0786,\n",
       "          -0.0213, -0.0296,  0.0927,  0.1061,  0.0828, -0.0388,  0.0657, -0.0962,\n",
       "           0.0974,  0.0101,  0.0387, -0.0860,  0.0066,  0.0352, -0.0945,  0.0238,\n",
       "           0.0704,  0.0202, -0.0503,  0.0940,  0.0040, -0.0724, -0.0237, -0.0282,\n",
       "           0.0649,  0.0648, -0.0130,  0.0341, -0.1076, -0.0110, -0.0550, -0.0268,\n",
       "          -0.0956, -0.0370, -0.0504, -0.0835,  0.0950, -0.0665, -0.0503,  0.0120,\n",
       "          -0.0588,  0.0801, -0.0510, -0.0114, -0.0643, -0.0487,  0.1062,  0.0017,\n",
       "          -0.0301, -0.0117, -0.0541,  0.0771, -0.1053, -0.0728,  0.0933, -0.0962,\n",
       "          -0.0185, -0.0873, -0.0119,  0.0969],\n",
       "         [-0.0893,  0.0551, -0.0078,  0.0694, -0.0686, -0.0137, -0.0953, -0.0029,\n",
       "           0.0154, -0.0241, -0.0121, -0.0715, -0.0966,  0.1042, -0.0111,  0.0164,\n",
       "           0.0804,  0.0991,  0.0855, -0.0989, -0.0924, -0.0082, -0.0932,  0.0693,\n",
       "          -0.0965, -0.1074,  0.0312, -0.0871,  0.0140, -0.0090, -0.0557,  0.0876,\n",
       "           0.0704,  0.0548, -0.0298,  0.0722,  0.0468,  0.0350,  0.0480, -0.0976,\n",
       "          -0.1082, -0.0336,  0.0594,  0.0572,  0.0180,  0.0638,  0.0216,  0.0237,\n",
       "          -0.0270,  0.0742,  0.1026, -0.0183, -0.0116,  0.0104,  0.0891, -0.0701,\n",
       "          -0.0322,  0.0982, -0.0054,  0.0496,  0.0971,  0.0274,  0.0622, -0.0754,\n",
       "           0.0881, -0.0580,  0.1036, -0.0257, -0.0398,  0.0313, -0.0939, -0.0672,\n",
       "          -0.0156,  0.0911,  0.0052,  0.0037, -0.0776, -0.0615,  0.0987, -0.0676,\n",
       "           0.0349,  0.0027,  0.0831,  0.0004],\n",
       "         [-0.0786, -0.0084, -0.0702,  0.0774,  0.0382,  0.0852,  0.1027,  0.0034,\n",
       "          -0.0271, -0.0625, -0.0819,  0.0343,  0.0399, -0.0890,  0.0352,  0.0061,\n",
       "           0.0227, -0.0516, -0.0996,  0.0698,  0.0693, -0.0502,  0.0368,  0.0269,\n",
       "          -0.0612,  0.0215, -0.0574,  0.0745,  0.0759,  0.0974, -0.0091,  0.0015,\n",
       "           0.0768, -0.0908,  0.0326, -0.0149,  0.0630,  0.1053, -0.0024, -0.0277,\n",
       "          -0.0497, -0.0883,  0.0715, -0.0514,  0.0074,  0.0146, -0.0037, -0.0453,\n",
       "           0.0815,  0.0907,  0.0359,  0.0985,  0.0324,  0.0333,  0.0406, -0.1090,\n",
       "           0.0469,  0.0233, -0.0585, -0.0089, -0.0605, -0.0523,  0.0247, -0.0828,\n",
       "           0.0079,  0.0385, -0.0197, -0.0277,  0.0960, -0.0961,  0.0745, -0.1078,\n",
       "           0.0746, -0.0146,  0.0290,  0.0685, -0.1011, -0.0258,  0.0904,  0.0775,\n",
       "          -0.0794,  0.0118, -0.0237,  0.0367],\n",
       "         [ 0.0208,  0.0569,  0.0930,  0.0903,  0.1003,  0.0902,  0.0801,  0.1006,\n",
       "           0.0087, -0.0050,  0.1036,  0.0949, -0.1010,  0.0792, -0.0236,  0.0725,\n",
       "           0.0285, -0.0363, -0.0363, -0.0925,  0.0463, -0.0569,  0.0449,  0.0920,\n",
       "          -0.0425, -0.0991, -0.0632, -0.1006,  0.0354, -0.1013, -0.0481, -0.1058,\n",
       "           0.0831, -0.0650,  0.0381, -0.1080,  0.0393, -0.0387, -0.1038,  0.0746,\n",
       "          -0.0440, -0.0196,  0.0983,  0.0603,  0.0524, -0.0014, -0.0900,  0.1073,\n",
       "           0.0938, -0.0374, -0.0894,  0.0210,  0.0666,  0.1069, -0.0908, -0.0413,\n",
       "           0.1033,  0.0558, -0.0289, -0.0461, -0.0833,  0.0660,  0.0643, -0.0157,\n",
       "          -0.0969,  0.0438,  0.0559, -0.0342, -0.0414, -0.0668,  0.0047, -0.0645,\n",
       "          -0.0964,  0.0731, -0.0501,  0.1022,  0.0041, -0.0521,  0.0647, -0.0269,\n",
       "           0.0984, -0.0718, -0.0135, -0.0462],\n",
       "         [-0.0386,  0.0012,  0.0345,  0.0477,  0.0411, -0.0042,  0.0759, -0.0677,\n",
       "          -0.0826, -0.0156, -0.0803,  0.0085,  0.0489, -0.0389, -0.0736,  0.0384,\n",
       "          -0.1036,  0.1085, -0.0615, -0.0129, -0.0827, -0.0899, -0.0797,  0.0547,\n",
       "           0.0633, -0.0396,  0.1056, -0.0091, -0.0354, -0.0681, -0.0397, -0.0816,\n",
       "           0.0751,  0.0137,  0.0529, -0.0698,  0.0995,  0.1040,  0.0804,  0.0144,\n",
       "          -0.0928,  0.0689, -0.0829, -0.0882, -0.0013, -0.0872, -0.0952,  0.0001,\n",
       "          -0.0774, -0.0433,  0.0573, -0.0554,  0.0547,  0.0487, -0.0824, -0.0895,\n",
       "           0.0867, -0.0782,  0.0282,  0.0283, -0.0097, -0.0685, -0.0458,  0.0247,\n",
       "          -0.0480,  0.0629, -0.0112,  0.0443, -0.0896,  0.0459,  0.0574,  0.0678,\n",
       "          -0.1042,  0.0114,  0.0956, -0.1013, -0.0756, -0.0562, -0.0853, -0.0252,\n",
       "          -0.0559, -0.0355,  0.0945, -0.0142]], requires_grad=True),\n",
       " Parameter containing:\n",
       " tensor([-0.0835,  0.0079, -0.0852, -0.1076,  0.1041, -0.0338, -0.0978,  0.0215,\n",
       "          0.0389, -0.0286], requires_grad=True)]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#🧠 1. 아직 백지상태인 로봇의 뇌 열어보기\n",
    "\n",
    "list(model.parameters())    # 아직 학습 안 된 모델\n",
    "\n",
    "# model: 우리가 방금 조립한 르넷(LeNet) 로봇입니다.\n",
    "\n",
    "# .parameters(): 파이토치(PyTorch)의 내장 명령어입니다. 로봇의 뇌 속에 들어있는 **'모든 학습 가능한 부품(가중치와 편향)'**들을 전부 긁어오라는 뜻입니다.\n",
    "# 아까 만들었던 돋보기(conv1, conv2...)와 회의실(fc1, fc2...)에 들어있는 조절 나사들을 의미합니다.\n",
    "# list(...): 파이썬 명령어입니다. 긁어온 수많은 부품들을 화면에 보기 좋게 **'목록(리스트) 형태'**로 나열해 달라는 뜻입니다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fa17c479",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[출력 결과의 의미]\n",
    "화면 아래에 Parameter containing: tensor([[[[-0.0083, -0.0676... 처럼 끝도 없이 복잡하고 긴 소수점 숫자 무리가 쏟아져 나왔습니다.\n",
    "\n",
    "이 숫자들은 로봇이 처음 태어날 때 파이토치가 무작위로(랜덤하게) 넣어둔 **'초기 쓰레기 값'**입니다.\n",
    "아직 공부를 한 번도 안 했기 때문에 아무런 규칙도, 의미도 없는 숫자들입니다.\n",
    "\n",
    "숫자들 맨 끝에 **requires_grad=True**라는 문구가 적혀 있습니다.\n",
    "이것은 아주 중요한 파이토치의 약속으로,\n",
    "**\"이 숫자들은 나중에 로봇이 오답 노트를 쓸 때(학습할 때) 업데이트를 해야 하니까,\n",
    "계산 과정을 전부 추적하고 기억해라(기울기 계산 켜기)!\"**라는 뜻입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "3ca664ed",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-0.1175,  0.1233, -0.0755,  0.0385,  0.0102,  0.0807, -0.1546,  0.0421,\n",
       "         -0.1017,  0.0694]], grad_fn=<TanhBackward0>)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 🧪 2. 가짜 이미지를 넣어서 로봇 작동 테스트하기\n",
    "# 부품이 잘 돌아가는지 가짜 데이터를 넣어보는 실험입니다.\n",
    "\n",
    "model(torch.randn((1,1,32,32)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "05dc6c46",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "로봇이 가짜 이미지를 먹고, 0.0473부터 -0.0583까지 총 10개의 점수를 뱉어냈습니다!\n",
    "아까 fc2 회의실에서 out_features=10으로 설정했던 게 정확히 작동한 것입니다.\n",
    "(아직 뇌가 랜덤 상태라 점수도 제멋대로입니다.)\n",
    "\n",
    "grad_fn=<TanhBackward0>:\n",
    "파이토치가 \"아, 이 결과물이 나오기 직전의 마지막 단계가 tanh 함수였지?\n",
    "내가 오답 노트 쓸 때를 대비해서 그 흔적(기울기 계산용 꼬리표)을 달아놨어!\"\n",
    "라고 알려주는 표시입니다.\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "ec1a4e10",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#💻 3. 로봇의 두뇌를 슈퍼컴퓨터(GPU)로 옮기기\n",
    "# 딥러닝은 엄청난 계산을 해야 하므로, 일반 CPU보다 수천 배 빠른 GPU(그래픽 카드)를 써야 합니다.\n",
    "\n",
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "model.to(device)\n",
    "\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d03bd8be",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "torch.cuda.is_available(): 파이토치에게 \"혹시 이 컴퓨터에 엔비디아(NVIDIA)의 GPU(이름하여 'cuda')가 꽂혀 있고,\n",
    "쓸 수 있는 상태야?\"라고 물어보는 질문입니다.\n",
    "\n",
    "'cuda' if ... else 'cpu': 파이썬의 조건문입니다.\n",
    "\"만약 GPU를 쓸 수 있으면 device라는 변수에 'cuda'라는 이름을 저장하고,\n",
    "아니면 그냥 일반 뇌인 'cpu'를 저장해!\"라는 뜻입니다.\n",
    "(노트북 결과를 보니 'cuda'가 출력되었네요. 좋은 그래픽카드가 꽂혀있습니다!)\n",
    "\n",
    ".to(device): 로봇(model)과 그 뇌 속에 든 수많은 숫자들을,\n",
    "방금 지정한 device(즉, 초고속 GPU)로 '이사(이동)' 시키는 명령어입니다.\n",
    "이제부터 로봇은 눈부신 속도로 계산을 할 수 있습니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1335557",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "642badef",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1            [-1, 6, 28, 28]             156\n",
      "            Conv2d-2           [-1, 16, 10, 10]           2,416\n",
      "            Conv2d-3            [-1, 120, 1, 1]          48,120\n",
      "            Linear-4                   [-1, 84]          10,164\n",
      "            Linear-5                   [-1, 10]             850\n",
      "================================================================\n",
      "Total params: 61,706\n",
      "Trainable params: 61,706\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.05\n",
      "Params size (MB): 0.24\n",
      "Estimated Total Size (MB): 0.29\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "# torchsummary라는 라이브러리는 이미지 사이즈가 어떻게되는지 다 체크가 된다\n",
    "# 🩻 4. 로봇 엑스레이(Summary) 찍기\n",
    "# 내가 설계한 로봇이 단계별로 이미지를 어떻게 쪼물딱거리는지 확인하는 아주 유용한 도구입니다.\n",
    "\n",
    "from torchsummary import summary\n",
    "# from ... import ...: 외부에서 torchsummary라는 엑스레이 도구 상자를 가져와서,\n",
    "# 그중 핵심 기능인 summary만 꺼내 쓰겠다는 뜻입니다.\n",
    "\n",
    "\n",
    "summary(model, input_size=(1,32,32))\n",
    "# 엑스레이 기계(summary) 안에 우리 로봇(model)을 집어넣습니다.\n",
    "\n",
    "# input_size=(1,32,32): 엑스레이 기계에게\n",
    "# \"이 로봇한테는 앞으로 (1채널, 가로 32, 세로 32) 크기의 이미지가 들어갈 거야.\n",
    "# 그 기준으로 시뮬레이션을 돌려서 보여줘!\"라고 알려줍니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea0a5e4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "[출력 결과(엑스레이 사진) 완벽 해독]\n",
    "결과로 아주 멋진 표가 나왔습니다.\n",
    "\n",
    "Layer (type): 데이터가 통과하는 부품들의 이름입니다 (Conv2d, Linear 등).\n",
    "\n",
    "Output Shape: 부품을 통과하고 난 뒤 데이터의 모양입니다.\n",
    "\n",
    "예) [-1, 6, 28, 28]: -1은 '배치 크기(아무 숫자나 들어올 수 있음)'를 뜻하고, 6겹으로 나뉘었으며,\n",
    "크기는 28x28 픽셀로 살짝 깎여나갔다는 뜻입니다.\n",
    "\n",
    "Param #: 그 부품 안에 들어있는 나사(학습할 조절 변수)의 개수입니다.\n",
    "\n",
    "첫 번째 돋보기(Conv2d-1)에는 156개의 나사가 있고,\n",
    "첫 번째 회의실(Linear-4)에는 무려 10,164개의 나사가 있습니다.\n",
    "\n",
    "Total params: 61,706: 우리 로봇은 총 61,706개의 나사(가중치)를 돌려가며 똑똑해질 거라는 뜻입니다.\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "fb553e62",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'cuda'"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6caa3e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "epoch : 1 loss: 0.9228004217147827: 100%|██████████| 1875/1875 [00:36<00:00, 52.03it/s]\n",
      "epoch : 2 loss: 0.8317035436630249: 100%|██████████| 1875/1875 [00:35<00:00, 53.28it/s]\n",
      "epoch : 3 loss: 0.8357064723968506: 100%|██████████| 1875/1875 [00:32<00:00, 58.08it/s]\n",
      "epoch : 4 loss: 0.8033186197280884: 100%|██████████| 1875/1875 [00:31<00:00, 58.67it/s]\n",
      "epoch : 5 loss: 0.8494244813919067: 100%|██████████| 1875/1875 [00:32<00:00, 57.94it/s]\n",
      "epoch : 6 loss: 0.7986806631088257: 100%|██████████| 1875/1875 [00:32<00:00, 57.08it/s]\n",
      "epoch : 7 loss: 0.7971152067184448: 100%|██████████| 1875/1875 [00:31<00:00, 60.30it/s]\n",
      "epoch : 8 loss: 0.8231432437896729: 100%|██████████| 1875/1875 [00:33<00:00, 55.75it/s]\n",
      "epoch : 9 loss: 0.8028712868690491: 100%|██████████| 1875/1875 [00:32<00:00, 57.01it/s]\n",
      "epoch : 10 loss: 0.8299447298049927: 100%|██████████| 1875/1875 [00:34<00:00, 54.70it/s]\n"
     ]
    }
   ],
   "source": [
    "# 학습할준비\n",
    "# import tqdm: 훈련이 얼마나 진행됐는지(10%, 20%...) 시각적인 로딩 바를 띄워줄 파이썬 도구를 가져옵니다.\n",
    "import tqdm   # 라이브러리 진행률 확인\n",
    "\n",
    "# from ... import SummaryWriter: 파이토치의 텐서보드 도구 상자에서,\n",
    "# 학습 성적을 엑셀 차트처럼 예쁘게 그려줄 **'기록 보조원(SummaryWriter)'**을 모셔옵니다.\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "\n",
    "#writer = SummaryWriter():\n",
    "# 모셔온 기록 보조원을 writer라는 이름으로 내 작업실(메모리)에 고용합니다.\n",
    "# (이 코드를 치면 폴더에 runs라는 기록용 폴더가 자동으로 생깁니다.)\n",
    "writer = SummaryWriter()\n",
    "\n",
    "# optim: Optimizer(최적화 도구)의 약자로, 저는 이걸 **'1타 과외선생님'**이라고 부릅니다.\n",
    "# Adam(...): 가장 인기 있는 과외선생님 이름이 'Adam'입니다.\n",
    "# model.parameters(): 과외선생님에게 \"선생님이 가르치고 고쳐야 할 학생의 뇌 부품(6만여 개의 나사)은 이것들입니다!\"라고 명부를 넘겨줍니다.\n",
    "optim = Adam(model.parameters(), lr=1e-3)\n",
    "# lr=1e-3: lr은 Learning Rate(학습률)입니다.\n",
    "# 나사를 한 번에 얼만큼 꽉 조일지(보폭)를 정합니다.\n",
    "# 1e-3은 수학 기호로 $1 \\times 10^{-3}$, 즉 **0.001**을 뜻합니다.\n",
    "# 너무 크게(예: 1.0) 고치면 로봇이 혼란에 빠지고,\n",
    "# 너무 작게(예: 0.000001) 고치면 학습이 하루 종일 걸리기 때문에,\n",
    "# 0.001이라는 아주 신중하고 적절한 보폭을 정해준 것입니다.\n",
    "\n",
    "# criterion: 한국어로 '기준'이라는 뜻이며, 저는 이걸 **'채점관'**이라고 부릅니다.\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "# nn.CrossEntropyLoss(): 딥러닝에서 0~9처럼 **'여러 개 중 하나를 고르는 객관식 문제'**의\n",
    "# 오답률(Loss)을 계산할 때 쓰는 아주 강력하고 유명한 채점 공식입니다.\n",
    "\n",
    "epoch = 10\n",
    "# epoch: '에폭'이라고 읽습니다. 6만 장의 모의고사 문제집 전체를 처음부터 끝까지 1번 다 푸는 것을 1 Epoch이라고 합니다.\n",
    "# 즉, 문제집을 총 10회독 하겠다는 뜻입니다.\n",
    "\n",
    "count = 0\n",
    "# count = 0: 기록 보조원(writer)이 성적표 차트를 그릴 때,\n",
    "# X축(시간/순서)에 점을 찍기 위해 0부터 세기 시작할 **'카운터(숫자 세기)'**를 만든 것입니다.\n",
    "\n",
    "\n",
    "# 체크포인트 불러오기\n",
    "\n",
    "# 🏃‍♂️ 3. 대망의 훈련 루프 (문제 풀고 똑똑해지기)\n",
    "\n",
    "for epoch in range(10):\n",
    "    # 아까 만들어둔 32장씩 나오는 문제지 컨베이어 벨트(train_loader)에 tqdm.tqdm(...)을 씌워서, 화면에 쫘아악 차오르는 진행률 바가 나오도록 만듭니다.\n",
    "    train_tqdm = tqdm.tqdm(train_loader)\n",
    "    # for ... in ...:: 안쪽 반복문(Inner Loop)입니다. 6만 장의 사진이 끝날 때까지 컨베이어 벨트(train_tqdm)에서 계속 뽑아냅니다.\n",
    "    # data, label: 컨베이어 벨트에서 한 번 뽑을 때마다 두 덩어리가 나옵니다.\n",
    "    # 32장의 이미지 문제는 data에, 32개의 실제 정답지(0~9)는 label이라는 변수에 담습니다.\n",
    "    for data,label in train_tqdm:\n",
    "        # 학생(로봇)이 초고속 GPU(device='cuda') 교실에 있으니, 방금 뽑은 문제지(data)와 정답지(label)도 GPU 교실로 .to() 시켜서 보내줍니다.\n",
    "        data = data.to(device)\n",
    "        label = label.to(device)\n",
    "\n",
    "        # [🔥 딥러닝 핵심 5단계 시작] 이 5줄이 인공지능이 지능을 가지게 되는 핵심 수학/프로그래밍 과정입니다.\n",
    "        # 1단계 (기억 지우기): zero_grad()는 과외선생님(optim)의 오답 노트 칠판(기울기, gradient)을 깨끗하게 0(zero)으로 지우라는 뜻입니다.\n",
    "        # 이전 문제의 오답 내용이 남아있으면 지금 푸는 문제와 섞여버리기 때문에, 문제를 풀기 직전엔 항상 칠판을 지워야 합니다.\n",
    "        optim.zero_grad()\n",
    "\n",
    "        # 2단계 (문제 풀기): 이미지 문제지(data)를 학생 로봇(model)에게 줍니다.\n",
    "        # 학생이 머리를 굴려 각 이미지당 10개씩의 확률 점수를 뱉어내면,\n",
    "        # 그걸 pred(Prediction, 예측값)라는 변수에 저장합니다.\n",
    "        pred = model(data)\n",
    "\n",
    "        # 3단계 (채점하기): 채점관(criterion)이 학생이 찍은 답(pred)과 실제 정답(label)을 비교합니다.\n",
    "        # 정답과 멀수록 엄청나게 큰 **'오답 점수(loss)'**를 만들어냅니다.\n",
    "        # (목표는 이 loss를 0으로 만드는 것입니다!)\n",
    "        loss = criterion(pred,label)\n",
    "\n",
    "\n",
    "        writer.add_scalar(\"Loss.train\", loss, count)    # tensorboard에 그래프로 설정할 예정\n",
    "        # 기록하기: 기록 보조원(writer)에게 지시합니다.\n",
    "        # add_scalar: \"차트에 점 하나를 찍어라!\"\n",
    "        # \"Loss.train\": 차트의 제목은 이걸로 해라.\n",
    "        # loss, count: Y축에는 방금 계산한 오답 점수(loss)를, X축에는 현재 순서(count)를 넣어서 콕 찍어라.\n",
    "\n",
    "        count += 1\n",
    "        # 점을 하나 찍었으니, 다음 번엔 그 옆에 점을 찍도록 count 숫자를 1 올려줍니다(+= 1).\n",
    "\n",
    "        loss.backward()\n",
    "        # 4단계 (오답 원인 분석 - 역전파): .backward()는 딥러닝의 꽃입니다.\n",
    "        # 오답 점수(loss)에서부터 거꾸로(backward) 로봇의 뇌신경망을 타고 내려가며,\n",
    "        # 미분(미세하게 쪼개서 변화량 보기)을 통해 \"아까 6만 개의 나사 중 어떤 나사가 얼마나 잘못 풀려 있어서 이 오답이 나왔는지\"\n",
    "        # 모든 나사의 잘못된 정도(기울기)를 계산해 오답 노트 칠판에 빼곡히 적어줍니다.\n",
    "\n",
    "        optim.step()\n",
    "        # 5단계 (뇌 부품 업데이트): 과외선생님(optim)이 방금 칠판에 적힌 오답 노트를 보고,\n",
    "        # 드디어 드라이버를 꺼내 로봇의 나사들을 0.001 보폭만큼 실제로 조이고 풀어서(step) 로봇을 더 똑똑하게 고쳐놓습니다.\n",
    "\n",
    "        train_tqdm.set_description(f'epoch : {epoch+1} loss: {loss.item()}')      # 몇번째 epoch인지, 손실값은  어떤지\n",
    "\n",
    "        # set_description: 화면에 쫘아악 차오르는 로딩 바 바로 옆에 글씨를 적어주는 기능입니다.\n",
    "        # f'...': 파이썬의 f-string이라는 문법으로, 글씨 중간에 변수 값을 끼워 넣을 때 씁니다.\n",
    "        # {epoch+1}: 파이썬은 숫자를 0부터 셉니다 (0, 1, 2...). 그래서 사람 보기에 편하라고 +1을 해서 \"1회독 째\", \"2회독 째\"라고 표시합니다.\n",
    "        # {loss.item()}: 텐서 포장지에 싸인 채점 결과(loss)를 찢고 알맹이 숫자만 빼서 화면에 출력합니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc1b69c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "#runs 폴더 만들어지면서 기록돼있다\n",
    "# 터미널에서 아래 실행\n",
    "\n",
    "\"\"\"\n",
    " (jwdeep) C:\\jwdeep>tensorboard --logdir=runs  \n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "423a3ce1",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.eval()   # 모델을 테스트용으로 사용하겠다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d22ec5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():   # 기울기계산 하지마\n",
    "    total_corr = 0\n",
    "    for img,labels in test_loader:\n",
    "        img = img.to(device)\n",
    "        labels = labels.to(device)\n",
    "\n",
    "        preds = model(img)\n",
    "\n",
    "        _, pred = torch.max(preds,1)     # 가장 큰 값, 예측된 값의 데이터를 집어넣고 1\n",
    "        total_corr += ((pred==labels).sum().item())\n",
    "        # print(pred)\n",
    "\n",
    "\n",
    "    print(f'Acc {total_corr/len(test_data.targets)}')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "317b60ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2c135c95",
   "metadata": {},
   "outputs": [],
   "source": [
    "F.softmax(preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a368b54d",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(model.state_dict(), 'lenet_cnn.pth')\n",
    "\n",
    "#모델의 가중치만을 저장하는 가장 안정적인 방법"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1cdd4ef3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 불러올때는 여기있는 가중치의 파라미터를 포함하는 객체가 반드시 필요하다"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "43722190",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_new = Lenet()\n",
    "#르넷이라는 객체를 하나 만든다\n",
    "# 1단계: 빈 뼈대(객체) 만들기\n",
    "# 저장할 때 사용했던 것과 완벽히 똑같은 구조의 빈 LeNet 모델을 메모리에 생성합니다.\n",
    "# 이 시점에는 모델 안의 가중치들이 학습되지 않은 랜덤한 숫자들로 채워져 있습니다.\n",
    "\n",
    "model_new.load_state_dict(torch.load('lenet_cnn.pth'))\n",
    "# 2단계: 빈 뼈대에 저장된 가중치(살코기) 덮어씌우기\n",
    "# 'lenet_cnn.pth' 파일에서 똑똑하게 학습된 숫자들을 가져와서 빈 모델의 제자리에 딱 맞춰 넣습니다.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d13f9254",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 모델을 통째로 저장하는 두번째 방법 \n",
    "# 첫번째 방법은 가중치만을 저장하고, 뒤에 새로운 객체를 만들고 그 가중치를 원래모델 뼈대위에,\n",
    "# 가중치를 덮어씌우는 방식이었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cdc56da",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 두번째방법 (통째로 : 보안에 취약, 권장X)\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "torch.save(model, 'model_all.pth')\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7b86cd9a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 학습할때 한번 epoch 끝나고나서 저장한다\n",
    "# 체크포인트(중간중간 모델을 기록하는) 방식\n",
    "\n",
    "\"\"\"\n",
    "\n",
    "torch.save({\n",
    "    'epoch':epoch,\n",
    "    'model_state_dict':model.state_dict(),\n",
    "    'optimizer_state_dict':optim.state_dict(),\n",
    "    'loss':loss\n",
    "},'checkpoint.pth')\n",
    "\n",
    "checkpoint = torch.load('checkpoint.pth')\n",
    "model.load_state_dict(checkpoint['model_state_dict'])\n",
    "\n",
    "#학습\n",
    "optim.load_state_dict(checkpoint['optimizer_state_dick'])\n",
    "epoch = checkpoint['epoch']\n",
    "loss = checkpoint['loss']\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d1d1693",
   "metadata": {},
   "outputs": [],
   "source": [
    "#세가지 방식이 있는데 체크포인트 사용하는 세번째 방식이 가장 낫다\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "26288e3b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "\n",
    "img = Image.open('data/4.png')\n",
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "247b156e",
   "metadata": {},
   "outputs": [],
   "source": [
    "img.size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b80c4fa1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "img_np = np.array(img)\n",
    "img_np.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f1b875a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_transform = transforms.Compose(\n",
    "    [\n",
    "        transforms.ToTensor(),\n",
    "        transforms.Grayscale(),\n",
    "        transforms.Resize(32),\n",
    "        transforms.Normalize((0.5,),(1.0,))  # 간이 정규화\n",
    "        \n",
    "    ]\n",
    ")\n",
    "\n",
    "img = infer_transform(img)\n",
    "img.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1ffa4810",
   "metadata": {},
   "outputs": [],
   "source": [
    "img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b55c3272",
   "metadata": {},
   "outputs": [],
   "source": [
    "infer_transform(img_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fb622991",
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model(img.to(device))\n",
    "torch.max(pred,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "161c53c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(pred,1)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9c102255",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.max(pred,1)[1].item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7fc95216",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "jwdeep",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.14.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
